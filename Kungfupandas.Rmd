--- 
title: "Kungfu Pandas"
author: "Lê Huỳnh Đức"
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
output: bookdown::gitbook
documentclass: book
description: "Kungfu Pandas"
---


# Lời nói đầu {-}
## abc
## Giới thiệu cuốn sách {-}
## Giới thiệu tác giả {-}

<!--chapter:end:index.Rmd-->

# Cấu trúc và kiểu dữ liệu 

Mục tiêu của chương này nhằm giới thiệu về các cấu trúc cơ bản trong Pandas là `Series` và `DataFrame`. 
Trong chương này, bạn sẽ học cách khởi tạo các cấu trúc này cũng như một số thao tác cơ bản trên `Series`. 
Bạn cũng sẽ được biết về một số kiểu dữ liệu thường gặp trong pandas và cách để giảm thiểu bộ nhớ sử dụng khi khởi tạo dữ liệu.

## Series
Trong Pandas, `Series` là mảng 1 chiều bao gồm một danh sách giá trị, và một mảng chứa index 
của các giá trị. Trong dữ liệu dảng bảng, mỗi Series được xem như là một cột của bảng đó. 
Cách đơn giản để tạo Series như sau

```{python eval=FALSE}
s = pd.Series(data, index=None, name=None)
```

Trong đó `data` có thể  có dạng:

- `numpy.ndarray`, `List`

- Python `dict`

- `Scalar`

`index` có thể truyền hoặc không, tùy vào dạng của `data` mà `index` sẽ được định nghĩa khác nhau. 
`name` là tên của `Series`, giá trị này cũng không nhất thiết phải truyền vào.

### Các cách khởi tạo

**Khởi tạo Series bằng array**

Khi không truyền giá trị `index`, `Series` sẽ mặc định index của nó là 1 mảng số nguyên từ `0` đến `len(data) - 1` 

```{python eval=FALSE}
In [1]: pd.Series(data=[0, 1, 2], index=["a", "b", "c"], name="meow")
Out[1]:
a    0
b    1
c    2
Name: meow, dtype: int64
```

**Khởi tạo Series bằng dict**

```{python eval=FALSE}
In [1]: pd.Series({"b": 1, "a":0, "c": 2})
Out[1]: 
b    1
a    0
c    2
dtype: int64

```

```{block2, type='rmdnote'}
**_Lưu ý_:** 
Trong trường hợp bạn truyền biến `index` vào, `Series` sẽ đánh index dựa vào thứ tự trong `index`, và chỉ chứa các giá trị của dict có key nằm trong `index`. 
Với các giá trị trong biến `index` không có trong keys của dict, `Series` sẽ tạo ra các giá trị bị thiếu `NaN`.
```

```{python eval=FALSE}
In [1]: pd.Series({"a": 0, "b": 1, "c": 2, "e": 4}, index=["b", "c", "d", "a"])
Out[1]: 
b    1.0
c    2.0
d    NaN
a    0.0
dtype: float64
```

```{block2, type='rmdnote'}
**_Lưu ý_:** 
`NaN` là giá trị mặc định cho dữ liệu bị thiếu trong pandas và giá trị này có kiểu 
là `float64` nên kiểu dữ liệu của `Series` cũng là `float64` khác với `int64` ở ví dụ trước đó. 

```

**Khởi tạo Series bằng một giá trị (Scalar)**

```{python eval=FALSE}
In [1]: pd.Series(data=1, index=["a", "b", "c"])
Out[1]: 
a    1
b    1
c    1
dtype: int64
```

### Một số thao tác cơ bản

Thao tác trên `Series` cũng giống với thao tác trên `numpy.array`. Ngoài ra chúng ta còn có thể 
tác với Series dựa vào index

Ví dụ:

```{python eval=FALSE}
In [1]: s = pd.Series(data=[0, 1, 2, 3, 4, 5], index=["a", "b", "c", "d", "e", "f"])
```
**Hiển thị toàn bộ giá trị của Series**
Ta gọi thuộc tính `.values`

```{python eval=FALSE}
In [1]: s.values
Out[1]:
array([0, 1, 2, 3, 4, 5])
```

**Lấy theo indice**

```{python eval=FALSE}
In [2]: s[2]
Out[2]: 2
``` 

**Lấy theo index**

```{python eval=FALSE}
In [3]: s["c"]
Out[3]: 2 
```

**Slice indice**

```{python eval=FALSE}
In [4]: s[1:3]
Out[4]:
b    1
d    2
dtype: int64
```

**Slice index**

```{python eval=FALSE}
In [5]: s["b":"c"]
Out[5]: 
b    1
c    2
dtype: int64
``` 

**List indice**

```{python eval=FALSE}
In [6]: s[[1, 2, 4]]
Out[6]:
b    1
c    2
e    4
dtype: int64
```

**List index**

```{python eval=FALSE}
In [7]: s[["b", "c", "e"]]
Out[7]:
b    1
c    2
e    4
dtype: int64
```

**Điều kiện**

```{python eval=FALSE}
In [5]: s[s > s.mean()]
Out[5]:
d    3
e    4
f    5
dtype: int64
```

## DataFrame {#cach-khoi-tao-data-frame}

`DataFrame` là cấu trúc dữ liệu chính và cũng là đặc trưng của pandas. Cũng giống như SQL Table, 
`DataFrame` là một bảng gồm một hay nhiều cột dữ liệu. Hoặc có thể nói rõ hơn là DataFrame là tập 
hợp các Series lại với nhau.

Cách khởi tạo DataFrame như sau

```{python eval=FALSE}
df = pd.DataFrame(data=None, index=None, columns=None, dtype=None, copy=False)
``` 

Cũng giống như Series, `data` của DataFrame có nhiều cách khởi tạo khác nhau như:

- `dict` của Series, `dict` của `numpy.array`/`List`
- Mảng 2 chiều `numpy.ndarray`, `List` của `List`
- [Mảng có cấu trúc](https://numpy.org/doc/stable/user/basics.rec.html)
- Từ 1 `Series`
- Từ `DataFrame` khác

Tùy vào cấu trúc của `data` mà chúng ta có thể bỏ qua biến `index`. Biến `columns` thể hiện tên
của các `Series`. `dtype` sẽ định nghĩa các kiểu dữ liệu của dữ liệu, chúng ta sẽ thảo luận về nó 
ở phần kế tiếp của chương này. `copy` dùng để  tạo bản sao từ dữ liệu `data`, nó chỉ ảnh hưởng khi 
`data` là DataFrame khác hoặc numpy.ndarray, việc copy này sẽ tránh trường hợp 2 biến cùng trỏ về 
cùng 1 bộ nhớ.

### Các cách khởi tạo

**Khởi tạo DataFrame từ dict của Series**

Khi không truyền biến `index` vào, thì index của `DataFrame` sẽ là hợp giữa 2 index của `Series` và
chúng sẽ được sắp xếp theo thứ tự từ vựng. Nếu ta không truyền `columns` thì các cột của `DataFrame` sẽ
được sắp xếp theo thứ tự truyền vào các keys của dict. 

Khi truyền biến `index` vào, tương tự như Series, chỉ những index nằm trong `index` mới được chọn, còn 
những index bị thiếu sẽ được điền giá trị `NaN`

Khi truyền giá trị `columns`, DataFrame sẽ chọn những `Series` thuộc dict có key thuộc `columns`, giá trị
trong `columns` không có trong key của dict sẽ được gán `NaN`

```{python eval=FALSE}
In [1]: d = {
            "one": pd.Series([1, 2, 3], index=["c", "b", "a"]),
            "two": pd.Series([1, 2, 3, 4], index=["c", "a", "b", "d"])
        }
In [2]: pd.DataFrame(d)
Out[2]:
   one  two
a  3.0    2
b  2.0    3
c  1.0    1
d  NaN    4

In [3]: pd.DataFrame(d, index=["d", "b", "a"])
Out[3]: 
   one	two
d  NaN	  4
b  2.0	  3
a  3.0	  2

In [4]: pd.DataFrame(d, index=["d", "b", "a"], columns=["two", "three"])
Out[4]:
   two	three
d	 4	  NaN
b	 3	  NaN
a	 2	  NaN
```

**Khởi tạo DataFrame từ dict của numpy.ndarray/List**

Đối với việc khởi tạo này, bắt buộc các mảng phải có cùng độ dài. Khi không truyền `index` vào thì 
index của DataFrame sẽ được tạo từ `0` đến `len(n) - 1` trong đó `n` là độ dài của mảng. Khi truyền 
giá trị `columns`, DataFrame sẽ chọn những key thuộc dict và cũng thuộc `columns`, giá trị trong 
`columns` không có trong key của dict sẽ được gán `NaN`
```{python eval=FALSE}
In [1]: d = {
            "one": [1, 2, 3, 4],
            "two": [1, 2, 3, 4],
            "three": [1, 2, 3, 4]
        }
In [2]: pd.DataFrame(data=d,
                     index=["a", "b", "c", "d"],
                     columns=["one", "two", "four"])
Out[2]:
   one  two four
a    1    1   NaN
b    2    2   NaN
c    3    3   NaN
d    4    4   NaN
```
**Khởi tạo DataFrame từ Mảng 2 chiều/ 2-d numpy.ndarray**

Khi không truyền `index` vào thì index của `DataFrame` sẽ được tạo từ `0` đến `len(n) - 1` trong đó `n` 
là số lượng List con hoặc là số dòng hay `shape[0]` của `numpy.ndarray`. Khi không truyền `columns` 
thì tên columns sẽ được tạo từ `0` đến `len(n) - 1` với `n` là độ dài lớn nhất của List con hoặc `shape[1]`
của `numpy.ndarray` 

```{python eval=FALSE}
In [1]: pd.DataFrame(data=[[1, 2], [3, 4, 5]], 
                     index=["a", "b"], 
                     columns=['one','two','three'])
Out[1]: 
   one  two  three
a    1    2    NaN
b    3    4    5.0

In [2]: pd.DataFrame(data=np.random.rand(2,3), 
                     index=["a", "b"], 
                     columns=['one','two','three']))
Out[2]:
        one       two     three
a  0.662008  0.085735  0.331281
b  0.115360  0.358092  0.862477
```

**Khởi tạo DataFrame từ danh sách các dict**

Ở cách khởi tạo này, bạn hãy tưởng tượng rằng mỗi dict là một dòng của DataFrame với các key là tên 
cột và value là giá trị tại cột đó. Việc truyền thêm hoặc không truyền `index` cũng giống
như các trường hợp khởi tạo trên. 

```{block2, type='rmdnote'}
**_Lưu ý:_** Trong trường hợp này, nếu bạn truyền `columns` vào thì `columns` bắt buộc phải chứa tất cả
các key của dict 
``` 

Trong ví dụ dưới đây, `columns` phải chứa toàn bộ keys `["one", "two", "three"]`, nếu thiếu 1 trong 3
sẽ phát sinh lỗi.

```{python eval=FALSE}
In [1]: d = [{"one": 1, "two": 2}, {"one": 4, "two": 5, "three": 6}]
In [2]: pd.DataFrame(d, index=["a", "b"], columns=["one", "two", "three", "four"])
Out[2]:
   one  two  three  four
a    1    2    NaN   NaN
b    4    5    6.0   NaN
```

**Khởi tạo DataFrame từ Mảng có cấu trúc**

Mảng có cấu trúc là mảng mà các phần tử của nó là một cấu trúc, bao gồm các thành phần nhỏ hơn, các thành phần này được đặt tên và khai báo kiểu dữ liệu.
Dưới đây là một ví dụ Mảng có cấu trúc trong numpy

```{python eval=FALSE}
In [1]: data = np.array([('pikachu', 9, 27.0), ('mewtwo', 3, 81.0)],
                        dtype=[('name', 'U10'), ('age', 'i4'), ('weight', 'f4')])
In [2]: pd.DataFrame(data)
Out[2]: 
       name  age  weight
0   pikachu    9    27.0
1    mewtwo    3    81.0
```

**Khởi tạo DataFrame từ namedtuple**

Các trường trong `nametuple` sẽ được gán thành tên các columns trong `DataFrame`. Những giá trị của `namedtuple` sẽ được xem là 1 dòng trong `DataFrame`. 
Số lượng cột của `DataFrame` sẽ phụ thuộc vào số lượng giá trị của phần từ `namedtuple` đầu tiên. Nếu các phần tử phía sau có số lượng giá trị ít hơn thì 
sẽ được điền `NaN` và ngược lại sẽ trả ra lỗi nếu số lượng giá trị của `namedtuple` lớn hơn số lượng giá trị của phần tử  `namedtuple` đầu tiên.

Ví dụ về cách tạo namedtuple

```{python eval=FALSE}
from collections import namedtuple
Point2D = namedtuple("Point2D", "x y")
Point3D = namedtuple("Point3D", "x y z")
```

Tạo DataFrame từ namedtuple `Point2D`

```{python eval=FALSE}
In [1]: pd.DataFrame([Point2D(0, 0), Point2D(0, 1), Point2D(0, 2)])
Out[1]:
   x  y
0  0  0
1  0  1
2  0  2
```
Tạo DataFrame từ namedtuple cả `Point2D` và `Point3D`

```{python eval=FALSE}
In [1]: pd.DataFrame([Point3D(0, 0, 0), Point2D(0, 1), Point3D(0, 2, 3)])
Out[1]:    
   x  y    z
0  0  0  0.0
1  0  1  NaN
2  0  2  3.0
```
Như ta thấy, tại phần tử thứ 2 chỉ có 2 giá trị, trong khi phần tử thứ nhất có 3 giá trị, vậy nên phần tử bị thiếu tại cột `z` sẽ được gán `NaN`

**Khởi tạo DataFrame từ Series**

```{python eval=FALSE}
In [1]: s = pd.Series(data=[0, 1, 2], index=["a", "b", "c"], name="meow")
In [2]: pd.DataFrame(s)
Out[2]: 
   meow
a     0
b     1
c     2
```
`name` của Series sẽ là tên cột của DataFrame và `index` của Series sẽ là index của DataFrame nếu ta không truyền các biến `index`, `columns` khi khởi tạo `pd.DataFrame`

### Các hàm khởi tạo thay thế 

**DataFrame.from_dict**

Cách khởi tạo 

```{python eval=FALSE} 
pd.DataFrame.from_dict(data, orient='columns', dtype=None, columns=None)
```

`data` truyền vào là 1 dict, `orient` có 2 giá trị có thể đưa vào là `{"columns", "index"}`, `columns` là danh sách tên các cột của DataFrame.

```{block2, type='rmdnote'}
**_Lưu ý:_** Chỉ được truyền `columns` khi `orient="index"`. Khi `orient="columns"` sẽ báo lỗi. 
```

Ví dụ tạo DataFrame khi `orient="columns"`. Với cách khởi tạo này tên các cột của DataFrame sẽ là key của dict

```{python eval=FALSE}
In [1]: data = {"col_1": [3, 2, 1, 0], "col_2": ["a", "b", "c", "d"]}
In [2]: pd.DataFrame.from_dict(data)
Out[2]:
   col_1 col_2
0      3     a
1      2     b
2      1     c
3      0     d
```

Ví dụ tạo DataFrame khi `orient="index"`. Với cách khởi tạo này index của DataFrame sẽ là key của dict. 

```{python eval=FALSE}
In [1]: data = {"col_1": [3, 2, 1, 0], "col_2": ["a", "b", "c", "d"]}
In [2]: pd.DataFrame.from_dict(data, orient="index", 
                               columns=["one", "two", "three", "four"])
Out[2]:
   col_1 col_2
0      3     a
1      2     b
2      1     c
3      0     d
```

**DataFrame.from_records**

Cách khởi tạo 

```{python eval=FALSE}
pd.DataFrame.from_records(data)
```

`data` truyền vào có thể là một mảng có cấu trúc  

```{python eval=FALSE}
In [1]: data = np.array([('Rex', 9, 81.0), ('Fido', 3, 27.0)],
                        dtype=[('name', 'U10'), ('age', 'i4'), ('weight', 'f4')])
In [2]: pd.DataFrame.from_records(data, index=["a", "b"])
Out[2]: 
   name  age  weight
a   Rex    9    81.0
b  Fido    3    27.0
```

Dữ liệu có thể  một danh sách các namedtuple

```{python eval=FALSE}
from collections import namedtuple
Point2D = namedtuple("Point2D", "x y")
Point3D = namedtuple("Point3D", "x y z")
pd.DataFrame.from_records([Point3D(0, 0, 0), Point2D(0, 1), Point3D(0, 2, 3)],
                          columns=["x","y","z"], index=["a", "b", "c"])
```

```{python eval=FALSE}
   x  y    z
a  0  0  0.0
b  0  1  NaN
c  0  2  3.0
```

Hoặc 1 danh sách các dict 

```{python eval=FALSE}
In [1]: d = [{"one": 1, "two": 2}, {"one": 4, "two": 5, "three": 6}]
In [2]: pd.DataFrame.from_records(d, index=["a", "b"], columns=["one", "two", "three", "four"])
Out[2]:
   one  two  three  four
a    1    2    NaN   NaN
b    4    5    6.0   NaN
```


## Data type trong pandas 

Để kiểm tra kiểu dữ liệu của `Series` hay `DataFrame` bạn có thể gọi thuộc tính `dtypes` hoặc phương thức `.info()`. 
Các kiểu dữ liệu thường gặp của Pandas được mô tả theo bảng dưới đây:

--------------------------------------------------------
Các kiểu dữ liệu        Numpy/Pandas      Hiển thị        
phổ  biến               object         
--------------------    ----------------  --------------
Boolean                 np.bool           *bool*

Integer                 np.int,           *int*
                        np.uint           *uint*

Float                   np.float          *float*

Object                  np.object         *O, object*

Datetime                np.datetime64,    *datetime64*
                        pd.Timestamp 

Timedelta               np.timedelta64,   *timedelta64*
                        pd.Timedelta
                        
Category                pd.Categorical    *category*              
                     
Complex                 np.complex        *complex*
--------------------------------------------------------


Ví dụ:

```{python eval=FALSE}
In [1]: df = pd.DataFrame({
                   'col_1': [1, 0, 1, 0], 
                   'col_2': [1.0, 2.0, 3.0, 4.0], 
                   'col_3': ['1', '2', '3', '4'],
                   'col_4': ['1', 2, '3', 4],
                   'col_5': [True, False, True, False],
                   'col_6': ['2021-06-01', '2021-06-02', '2021-06-03', '2021-06-04']})
In [2]: df
Out[2]:
   col_1  col_2 col_3 col_4  col_5       col_6
0      1    1.0     1     1   True  2021-06-01
1      0    2.0     2     2  False  2021-06-02
2      1    3.0     3     3   True  2021-06-03
3      0    4.0     4     4  False  2021-06-04

In [3]: df.dtypes
Out[3]:
col_1      int64
col_2    float64
col_3     object
col_4     object
col_5       bool
col_6     object
dtype: object
```
```{block2, type='rmdnote'}
**_Lưu ý:_** 

- Nếu không khai báo kiểu dữ liệu khi khởi tạo, pandas sẽ mặc định kiểu dữ liệu là `int64`, `float64`, `object` và `bool`.
Pandas sẽ không biết kiểu dữ liệu `timestamp` nếu không khai báo.

- Chỉ có thể khai báo duy nhất 1 kiểu dữ liệu khi [khởi tạo pandas](#cach-khoi-tao-data-frame). 
Ví dụ như tất cả dữ liệu của bạn là `int` hoặc có thể được ép kiểu về  `int`thì có thể khai báo  `dtype=np.int`
``` 

Ở ví dụ phía dưới `col_1`, `col_2`, `col_4`, `col_5` có thể ép về kiểu `int`, còn  `col_3`, `col_6` thì không thể ép kiểu được.

```{python eval=FALSE}
In [1]: df = pd.DataFrame({
                   'col_1': [1, 0, 1, 0], 
                   'col_2': [1.0, 2.0, 3.0, 4.0], 
                   'col_3': ['1', '2', '3', '4'],
                   'col_4': ['1', 2, '3', 4],
                   'col_5': [True, False, True, False],
                   'col_6': ['2021-06-01', '2021-06-02', '2021-06-03', '2021-06-04']},
                   dtype=np.int)
In [2]: df
Out[2]:
   col_1  col_2  col_3  col_4  col_5       col_6
0      1      1      1      1      1  2021-06-01
1      0      2      2      2      0  2021-06-02
2      1      3      3      3      1  2021-06-03
3      0      4      4      4      0  2021-06-04

In [3]: df.dtypes
Out[3]:
col_1     int64
col_2     int64
col_3    object
col_4     int64
col_5     int64
col_6    object
dtype: object
```

```{block2, type='rmdtip'}
**_Mẹo:_**
Nếu dữ liệu có khoảng nhỏ thì thay vì khai báo kiểu `np.int`, ta có thể khai báo kiểu `integer` với số byte phù hợp để giảm bộ nhớ lưu trữ. 
Để xem bộ nhớ sử dụng của DataFrame, ta có thể dùng `.memory_usage()`.

Một số kiểu integer trong numpy như `np.int8`, `np.int16`, `np.int32`, `np.int64`, `np.uint8`, `np.uint16`, `np.uint32`, `np.uint64`
``` 
Theo ví dụ trên, khi `dtype=np.int`

```{python eval=FALSE}
In [1]:  df.memory_usage()
Out[1]: 
Index    128
col_1     32
col_2     32
col_3     32
col_4     32
col_5     32
col_6     32
dtype: int64
```

và sau khi thay bằng `dtype=np.int8`

```{python eval=FALSE}
In [1]:  df.memory_usage()
Out[1]: 
Index    128
col_1      4
col_2      4
col_3      4
col_4      4
col_5      4
col_6     32
dtype: int64
```
Phương thức ép kiểu này được áp dụng khi bạn khởi tạo DataFrame, ngoài ra còn có hàm ép kiểu khác đối với DataFrame cho trước, nội dung này sẽ được đề cập ở [Chương 3](#Chuong-3).

<!--chapter:end:posts/01-DataStructure_Datatype.Rmd-->

# Nhập xuất trong pandas
Ở Chương 1 chúng ta đã biết cách khởi tạo DataFrame từ các dữ liệu cho trước. 
Trong chương này sẽ hướng dẫn cách đọc dữ liệu từ file bằng pandas, một số kiểu file thường thấy cho dữ liệu dạng bảng là `.csv` và `.xlsx`.
Bạn cũng có thể đọc dữ liệu bán cấu trúc như `JSON` bằng cách load file bằng Python sau đó dùng các cách khởi tạo như ở Chương 1 hoặc có thể dùng
hàm phụ trợ của Pandas. 

Ở phần thứ hai của chương, bạn sẽ được hướng dẫn một số cách cấu hình cho Pandas như thay đổi số dòng, số cột hiển thị...

## Đọc và lưu file

### csv, tsv

#### Đọc file
Chúng ta có thể đọc file csv với pandas theo lệnh sau

```python
df = pd.read_csv(filepath, sep=',', names=NoDefault.no_default, index_col=None, usecols=None, dtype=None, skiprows=None, skipfooter=0, nrows=None)
```

Trong đó:

- `filepath` là đường dẫn đến file trong máy hoặc đường link URL

- `sep` dùng để nhận diện cách chia thành cột, nếu không truyền tham số này thì `pandas` tự hiểu là chia theo `','`, ngoài ra có thể chia theo `';'` đối với macOS và `'\t'` với file có định dạng `.tsv`

- `names` là tên các cột của bảng. Nếu bảng đã có tên cột thì nên bỏ qua tham số này, `pandas` sẽ lấy dòng đầu tiên của file làm tên cột.

- `index_col` dùng để chỉ định vị trí các cột dùng để làm index cho bảng.

- `usecols` dùng để chỉ định vị trí hoặc tên các cột cần đọc.

- `dtype` dùng để định dạng kiểu dữ liệu của các cột.

- `skiprows` được dùng khi muốn bỏ qua một số dòng đầu của bảng.

- `skipfooter` tương tự như `skiprows` nhưng sẽ bỏ qua các dòng cuối cùng của bảng. 

- `nrows` dùng để chỉ định số lượng dòng của bạn mà bạn sẽ đọc bằng `pandas`

**Ví dụ** 

Đọc file dữ liệu sale được cho tại [đây](https://raw.githubusercontent.com/lhduc94/kungfupandas/master/data/sales_subset.csv). Giả sử ta chỉ lấy các cột `date`, `weekly_sales` và `is_holiday` và lấy cột `date` làm `index` và chỉ lấy 6 dòng đầu
```python
In [1]: df = pd.read_csv('https://raw.githubusercontent.com/lhduc94/kungfupandas/master/data/sales_subset.csv', index_col=['date'], usecols=['date','weekly_sales','is_holiday'], nrows=6)
In [2]: df
Out[2]:
            weekly_sales  is_holiday
date                                
2010-02-05      24924.50       False
2010-03-05      21827.90       False
2010-04-02      57258.43       False
2010-05-07      17413.94       False
2010-06-04      17558.09       False
2010-07-02      16333.14       False
```

#### Xuất file
Để lưu `DataFrame` dưới dạng file ta có thể dùng câu lệnh `.to_csv()` theo cú pháp sau

```python
df.to_csv(filename, sep=',', columns=None, header=True, index=True)
```
Trong đó:

- `filename` là địa chỉ file mà bạn muốn lưu lại

- `sep` tương tự như lúc đọc file

- `columns` là tên các cột bạn muốn lưu xuống, nếu muốn lưu tất cả các cột thì 
bạn có thể bỏ qua tham số này.

- `header` mặc định là `True` nếu bạn muốn lưu tên cột

- `index` mặc định là `True` nếu bạn muốn lưu index của bảng.

Ví dụ

```python
df.to_csv('sales.csv', columns='weekly_sales', index=False)
```
### Excel
#### Đọc file Excel
Để đọc file Excel ta dùng cú pháp sau

```python
x = pd.ExcelFile(filename)
```

Với `filename` là đường dẫn đến file

Để xem tên các sheets của `x` ta có thể dùng `x.sheet_names`. Sau đó để đọc từng sheet của `x` ta có thể dùng `.parse()`
```python
df = x.parse(sheet_name, header=0, names=None, index_col=None, usecols=None, skiprows=None, skipfooter=0, nrows=None)
```
Trong đó `sheet_name` là tên sheet cần đọc, các thông số còn lại tương tự như phần đọc file `csv` và `tsv`. Một cách khác để đọc file excel là dùng hàm [pandas.read_excel](https://pandas.pydata.org/docs/reference/api/pandas.read_excel.html) với tham số `io` là tên file.

#### Xuất file Excel
Giả sử ta có các `DataFrame` df1, df2, df3 cần được lưu vào 1 file Excel duy nhất

```python
import pandas as pd

df1 = pd.DataFrame({'col_1': [1, 2, 3, 4]})
df2 = pd.DataFrame({'col_1': ['a', 'b', 'c', 'd']})
df3 = pd.DataFrame({'col_1': [True, True, False, False]})
```
Để ghi các bảng vào file Excel, bước đầu tiên là khởi tạo biến `writer` theo cú pháp

```python
writer = pd.ExcelWriter('pandas_multiple.xlsx', mode='w',  if_sheet_exists=None, engine=None)
```

Trong đó:

- `filename` là tên file excel

- `mode` là phương thức ghi file với `w` là viết file mới và `a` là viết thêm vào file. Mặc định là `w`

- `if_sheet_exists` là phương thức ghi file nếu file hoặc sheet đã tồn tại, bao gồm các phương thức dưới đây (mặc định là error)

    - `error`: hiện ValueError nếu đã tồn tại sheet

    - `new`: Tạo sheet mới với tên phụ thuộc vào `engine`

    - `replace`: Xóa nội dung của sheet trước khi viết.

    - `overlay`: Viết lên sheet đã tồn tại mà không xóa các sheet cũ

- `engine`: Một số kiểu hỗ trợ ghi file như `xlsxwriter`, `openpyxl`, `openpyxl`, `odswriter`

```{block2, type='rmdnote'}
**_Lưu ý_:** 
`mode='w'` không được sử dụng với engine `xlsxwriter`, khi khai báo engine này sẽ báo lỗi.

`if_sheet_exists` chỉ sử dụng với `mode='a'`

`overlay` chỉ hỗ trợ với phiên bản `1.4.0` trở lên.
```

Để ghi từng sheet bạn dùng lệnh `.to_excel()`. Sau khi ghi tất cả các sheet bạn kết thúc với `writer.save()` để lưu file

```python
writer = pd.ExcelWriter('mul_sheets.xlsx', mode='w', engine='openpyxl')
df1.to_excel(writer, sheet_name='Sheet1')
df2.to_excel(writer, sheet_name='Sheet2')
df3.to_excel(writer, sheet_name='Sheet3')
writer.save()
```

```{block2, type='rmdtip'}
**_Mẹo:_**
Có thể dùng `with` để mở file để tránh trường hợp quên gọi lệnh `.save()`, lệnh `with` sẽ tự động lưu file sau khi kết thúc các lệnh con trong nó
``` 

```python
import pandas as pd
df1 = pd.DataFrame({'col_1': [2, 3, 4, 5]})
df2 = pd.DataFrame({'col_1': ['a', 'b', 'c', 'd']})
df3 = pd.DataFrame({'col_1': [True, True, False, False]})
sheet_names = ['Sheet1','Sheet2', 'Sheet3']

with pd.ExcelWriter('mul_sheets.xlsx', mode='a', if_sheet_exists='new', engine='openpyxl') as writer:
    for df, sheet_name in zip([df1, df2, df3], sheet_names):
        df.to_excel(writer, sheet_name)
```

### JSON

#### Đọc file

`JSON` là 1 dạng dữ liệu khá phổ biến trong thực tế. `Pandas` hỗ trợ đọc file `JSON` theo phương thức sau

```python
pd.read_json(path_or_buf=None, orient=None,...)
```

Trong đó:

- `path_or_buf`: là đường dẫn đến file json hoặc Object cho trước

- `orient`:  Kiểu cấu trúc của json
    - `split`:  Dữ liệu có dạng dictionary theo cấu trúc `{index -> [index], columns - [columns], data -> [values]}`
    - `records`: Dữ liệu có dạng danh sách các dictionary theo cấu trúc ` [{column -> value}, ... , {column -> value}]`
    - `index`: Dữ liệu dạng dictionary theo cấu trúc `{"index" -> {"column" -> "value"}}`
    - `columns`: Dữ liệu dạng dictionary theo cấu trúc `{column -> {index -> value}}`
    - `values`: danh sách các giá trị
- Ngoài ra còn các tham số khác nữa như `chunksize`, `nrow`, các bạn có thể tham khảo tại [pd.read_json()](https://pandas.pydata.org/docs/reference/api/pandas.read_json.html)

Dưới đây là file `sample_pokemon.json` với các cấu trúc như sau

Cấu trúc `records`

```json
[{"name":"Bulbasaur","type":["Grass","Poison"],"height":"0.71 m","weight":"6.9 kg"},
 {"name":"Ivysaur","type":["Grass","Poison"],"height":"0.99 m","weight":"13.0 kg"},
 {"name":"Venusaur","type":["Grass","Poison"],"height":"2.01 m","weight":"100.0 kg"},
 {"name":"Charmander","type":["Fire"],"height":"0.61 m","weight":"8.5 kg"},
 {"name":"Charmeleon","type":["Fire"],"height":"1.09 m","weight":"19.0 kg"}]
 ```

 ta có thể gọi

 ```python
 df = pd.read_json('sample_pokemon.json', orient='records')
 df.head()
 ```

 ```
          name             type  height    weight
0   Bulbasaur  [Grass, Poison]  0.71 m    6.9 kg
1     Ivysaur  [Grass, Poison]  0.99 m   13.0 kg
2    Venusaur  [Grass, Poison]  2.01 m  100.0 kg
3  Charmander           [Fire]  0.61 m    8.5 kg
4  Charmeleon           [Fire]  1.09 m   19.0 kg
 ```

Tương tự với cấu trúc `split`

```json
{"index":   [0,1,2,3,4],
 "columns": ["name","type","height","weight"],
 "data":    [["Bulbasaur",["Grass","Poison"],"0.71 m","6.9 kg"],
             ["Ivysaur",["Grass","Poison"],"0.99 m","13.0 kg"],
             ["Venusaur",["Grass","Poison"],"2.01 m","100.0 kg"],
             ["Charmander",["Fire"],"0.61 m","8.5 kg"],
             ["Charmeleon",["Fire"],"1.09 m","19.0 kg"]]}
```

 ta có thể gọi

 ```python
 df = pd.read_json('sample_pokemon.json', orient='split')
 df.head()
 ```

Các cấu trúc còn lại

`index`

 ```json
 {"0":{"name":"Bulbasaur","type":["Grass","Poison"],"height":"0.71 m","weight":"6.9 kg"},
 "1":{"name":"Ivysaur","type":["Grass","Poison"],"height":"0.99 m","weight":"13.0 kg"},
 "2":{"name":"Venusaur","type":["Grass","Poison"],"height":"2.01 m","weight":"100.0 kg"},
 "3":{"name":"Charmander","type":["Fire"],"height":"0.61 m","weight":"8.5 kg"},
 "4":{"name":"Charmeleon","type":["Fire"],"height":"1.09 m","weight":"19.0 kg"}}
 ```

`columns`

```json
{"name":{"0":"Bulbasaur",
         "1":"Ivysaur",
         "2":"Venusaur",
         "3":"Charmander"
         "4":"Charmeleon"},
 "type":{"0":["Grass","Poison"],
         "1":["Grass","Poison"],
         "2":["Grass","Poison"],
         "3":["Fire"],
         "4":["Fire"]},
 "height":{"0":"0.71 m",
           "1":"0.99 m",
           "2":"2.01 m",
           "3":"0.61 m",
           "4":"1.09 m"},
 "weight":{"0":"6.9 kg",
           "1":"13.0 kg",
           "2":"100.0 kg",
           "3":"8.5 kg",
           "4":"19.0 kg"}}
```

`values`

```json
[["Bulbasaur",["Grass","Poison"],"0.71 m","6.9 kg"],
 ["Ivysaur",["Grass","Poison"],"0.99 m","13.0 kg"],
 ["Venusaur",["Grass","Poison"],"2.01 m","100.0 kg"],
 ["Charmander",["Fire"],"0.61 m","8.5 kg"],
 ["Charmeleon",["Fire"],"1.09 m","19.0 kg"]]
```
 

```{block2, type='rmdnote'}
**_Lưu ý_:** 

- `pd.read_json()` mặc định `orient='records'`. Các cấu trúc `records` và `index` là các cấu trúc JSON thường gặp.

- `values` không phải cấu trúc JSON.

- có thể truyền link file thay vì file được lưu ở máy.

```

### Pickle
#### Đọc file

#### Xuất file

## Cấu hình pandas 

<!--chapter:end:posts/02-IO.Rmd-->

# Một số hàm cơ bản {#Chuong-3}

```python
df = pd.read_csv('https://raw.githubusercontent.com/lhduc94/kungfupandas/master/data/sales_subset.csv',index_col=['Unnamed: 0'])
```

## `.head()` và `.tail()`

Phương thức `.head(n=5)` hiển thị `n` dòng đầu tiên của `DataFrame`, ngược lại phương thức `.tail(n=5)` hiển thị `n` dòng cuối cùng của `DataFrame`

```python
In [1]: df.head()
Out[1]:    
        store type  department        date  weekly_sales  is_holiday  \
0      1    A           1  2010-02-05      24924.50       False   
1      1    A           1  2010-03-05      21827.90       False   
2      1    A           1  2010-04-02      57258.43       False   
3      1    A           1  2010-05-07      17413.94       False   
4      1    A           1  2010-06-04      17558.09       False 

   temperature_c  fuel_price_usd_per_l  unemployment  
0       5.727778              0.679451         8.106  
1       8.055556              0.693452         8.106  
2      16.816667              0.718284         7.808  
3      22.527778              0.748928         7.808  
4      27.050000              0.714586         7.808  

In [2]: df.tail()
Out[2]:
       store type  department        date  weekly_sales  is_holiday  \
10769     39    A          99  2011-12-09        895.00       False   
10770     39    A          99  2012-02-03        350.00       False   
10771     39    A          99  2012-06-08        450.00       False   
10772     39    A          99  2012-07-13          0.06       False   
10773     39    A          99  2012-10-05        915.00       False   

       temperature_c  fuel_price_usd_per_l  unemployment  
10769       9.644444              0.834256         7.716  
10770      15.938889              0.887619         7.244  
10771      27.288889              0.911922         6.989  
10772      25.644444              0.860145         6.623  
10773      22.250000              0.955511         6.228 

```

## `.shape` và `.size`

Phương thức `.shape` cho biết số lượng dòng và cột của bảng

```python
In [3]: df.shape
Out[3]: (10774, 9)
```
 Trong dó `10774` là số lượng dòng của bảng và `9` là số lượng cột của bảng

 Phương thức `.size` cho biết số lượng phần từ của bảng

```python
 In [4]: df.size
 Out[4]: 96966
```

## `.info()`

 Phương thức `.info()` dùng để xem một số thông tin cơ bản như
 
 - Index của bảng
 - Tên các cột, số lượng các phần tử Null trong cột và kiểu dữ liệu của chúng
 - Số lượng các kiểu dữ liệu
 - Dung lượng của bảng

 Ví dụ

```python
In [5]: df.info()
Out[5]:
<class 'pandas.core.frame.DataFrame'>
Int64Index: 10774 entries, 0 to 10773
Data columns (total 9 columns):
 #   Column                Non-Null Count  Dtype  
---  ------                --------------  -----  
 0   store                 10774 non-null  int64  
 1   type                  10774 non-null  object 
 2   department            10774 non-null  int64  
 3   date                  10774 non-null  object 
 4   weekly_sales          10774 non-null  float64
 5   is_holiday            10774 non-null  bool   
 6   temperature_c         10774 non-null  float64
 7   fuel_price_usd_per_l  10774 non-null  float64
 8   unemployment          10774 non-null  float64
dtypes: bool(1), float64(4), int64(2), object(2)
memory usage: 768.1+ KB
```

```{block2, type='rmdtip'}
**_Mẹo:_**
Phương thức `.info()` có các tham số để tùy chỉnh các thông tin có thể xem. Bạn có thể giới hạn các thông tin theo các tham số dưới đây
`info(verbose=None, buf=None, max_cols=None, memory_usage=None, show_counts=None, null_counts=None)`
``` 

## `.describe()`

Phương thức `.describe()` đưa ra một số thống kê đơn giản như `count`, `mean`, `std`, `min`, `max` và `percentiles = [0.25, 0.5, 0.75]`. Phương thức này chỉ áp dụng cho các cột ở dạng `numerical`.

```python
In [6]: df.describe()
Out[6]: 
              store    department   weekly_sales  temperature_c  \
count  10774.000000  10774.000000   10774.000000   10774.000000   
mean      15.441897     45.218118   23843.950149      15.731978   
std       11.534511     29.867779   30220.387557       9.922446   
min        1.000000      1.000000   -1098.000000      -8.366667   
25%        4.000000     20.000000    3867.115000       7.583333   
50%       13.000000     40.000000   12049.065000      16.966667   
75%       20.000000     72.000000   32349.850000      24.166667   
max       39.000000     99.000000  293966.050000      33.827778   

       fuel_price_usd_per_l  unemployment  
count          10774.000000  10774.000000  
mean               0.749746      8.082009  
std                0.059494      0.624355  
min                0.664129      3.879000  
25%                0.708246      7.795000  
50%                0.743381      8.099000  
75%                0.781421      8.360000  
max                1.107674      9.765000  
```

```{block2, type='rmdtip'}
**_Mẹo:_**
Bạn có thể thay đổi thông số percentiles bằng cách truyền tham số này vào trong `.describe()`
```

**Ví dụ** 
```python
In [7]: df.describe(percentiles=[0.1, 0.99]))
Out[7]: 
              store    department   weekly_sales  temperature_c  \
count  10774.000000  10774.000000   10774.000000   10774.000000   
mean      15.441897     45.218118   23843.950149      15.731978   
std       11.534511     29.867779   30220.387557       9.922446   
min        1.000000      1.000000   -1098.000000      -8.366667   
10%        2.000000      8.000000     607.695000       2.577778   
50%       13.000000     40.000000   12049.065000      16.966667   
99%       39.000000     99.000000  142193.400300      32.388889   
max       39.000000     99.000000  293966.050000      33.827778   

       fuel_price_usd_per_l  unemployment  
count          10774.000000  10774.000000  
mean               0.749746      8.082009  
std                0.059494      0.624355  
min                0.664129      3.879000  
10%                0.687640      7.127000  
50%                0.743381      8.099000  
99%                0.978565      9.765000  
max                1.107674      9.765000   
``` 
```{block2, type='rmdnote'}
**_Lưu ý:_** 
`pandas` mặc định tính  thêm percentile tại `0.5` dù không truyền vào 
``` 

## `.index`
Thuộc tính `.index` để lấy index của `DataFrame` hoặc `Series`.

Ví dụ

```python
In [8]: df.index
Out[8]: 
Int64Index([    0,     1,     2,     3,     4,     5,     6,     7,     8,
                9,
            ...
            10764, 10765, 10766, 10767, 10768, 10769, 10770, 10771, 10772,
            10773],
           dtype='int64', length=10774)
```

## `.memory_usage()`

Phương thức `.memory_usage(index=True, deep=False)` giúp thông kê dung lượng của từng cột. Trong đó `index` trả về dung lượng của phần đánh index và `deep` nếu đặt giá trị `True` sẽ trả về cách tính toán sâu hơn về bộ nhớ cho kiểu `object`

Ví dụ

```python
In [9]: df.memory_usage(index=False)
Out[9]: 

store                   86192
type                    86192
department              86192
date                    86192
weekly_sales            86192
is_holiday              10774
temperature_c           86192
fuel_price_usd_per_l    86192
unemployment            86192
dtype: int64

In [10]: df.memory_usage(deep=True) 
Out[10]: 

Index                    86192
store                    86192
type                    624892
department               86192
date                    721858
weekly_sales             86192
is_holiday               10774
temperature_c            86192
fuel_price_usd_per_l     86192
unemployment             86192
dtype: int64
```
## Lấy Series trong pandas
Sử dụng `[<tên cột>]` để lấy 1 Series của bảng. Ví dụ để lấy Series của cột `department` ta làm như sau

```python
In [11]: df['department']
Out[11]: 
0         1
1         1
2         1
3         1
4         1
         ..
10769    99
10770    99
10771    99
10772    99
10773    99
Name: department, Length: 10774, dtype: int64
```
những Series này cũng có thế áp dụng các phương thức tương tự của `DataFrame` như `.head()`, `.tail()`....

## `.astype()`

Với phương thức `.astype()` ta có thể ép kiểu dữ liệu của cột về dạng khác. Việc ép kiểu này giúp thay đổi kiểu dữ liệu để tiện các thao tác như nối 2 cột có 2 kiểu `str` và `int`, ngoài ra việc ép kiểu cũng giúp giảm được dung lượng bộ nhớ dành cho bảng. 

Ở ví dụ trên, ta thấy cột `department` có giá trị max là `99` nhưng được mặc định là `int64` khá lãng phí, do đó ép kiểu về `int8`

**Trước khi ép kiểu**
```python
In [12]: df['department'].dtypes
Out[12]: dtype('int64')

In [13]: df['department'].memory_usage() - df['department'].index.memory_usage()
Out[13]: 
86192
```
**Sau khi ép kiểu**

```python
In [14]: df['department'].astype('int8').memory_usage() - df['department'].index.memory_usage()
Out[14]: 
10774
```
Ta thấy sau khi ép kiểu thì bộ nhớ lưu trữ của cột `department` giảm đi `8` lần.

```{block2, type='rmdnote'}
**_Lưu ý:_** 
`df['department'].memory_usage()` trả về dung lượng lưu trữ của cột `department` và dung lượng lưu trữ của `index`
``` 
## `.drop_duplicates()`

Phương thức này trả về `DataFrame` đã được loại bỏ các hàng trùng nhau.
Lệnh thực hiện

```python
DataFrame.drop_duplicates(subset=None, keep='first', inplace=False, ignore_index=False)
```
Trong đó:

- `subset`: tên cột hoặc danh sách các cột cần lọc giá trị trùng lặp, nếu không truyền vào sẽ mặc định chọn tất cả các cột

- `keep`: các kiểu lọc `duplicate` bao gồm các lựa chọn sau:
  - `'first'`: loại bỏ các dòng bản sao, chỉ giữ lại dòng đầu tiên
  - `'last'`: loại bỏ các dòng bản sao, chỉ giữ lại dòng cuối cùng
  - `False`: loại tất cả các dòng trùng lặp

- `inplace`: thao tác trực tiếp trên bảng nếu để giá trị `True` hoặc tạo 1 bản sao với giá trị `False`

- `ignore_index`: Nếu `True` trả về index đánh số lại từ `0` đến `n-1`

**Ví dụ**

```python
In [15]: df = pd.DataFrame({
    'action': ['view', 'view', 'add to cart', 'add to cart', 'add to cart',],
    'fruit': ['orange', 'orange', 'orange', 'apple', 'apple'],
    'times':   [ 1, 1, 3, 2, 4]
})
In [16]: df
Out[16]:
        action  fruit   times
0         view  orange      1
1         view  orange      1
2  add to cart  orange      3
3  add to cart   apple      2
4  add to cart   apple      4

In [17]: df.drop_duplicates()
Out[17]:
        action  fruit   times
0         view  orange      1
2  add to cart  orange      3
3  add to cart   apple      2
4  add to cart   apple      4

In [18]: df.drop_duplicates(subset=['action'])
Out[18]:
        action  fruit   times
0         view  orange      1
2  add to cart  orange      3

In [19]: df.drop_duplicates(subset=['action','fruit'], keep='last', ignore_index=True)
        action   fruit  times
0         view  orange      1
1  add to cart  orange      3
2  add to cart   apple      4

```

## `.value_counts()`

Phương thức này trả số lần xuất hiện của các phần tử trong `Series`. Kết quả trả về mặc định sẽ sắp xếp theo số lần xuất hiện giảm dần và mặc định bỏ qua các giá trị null

```python
Series.value_counts(normalize=False, sort=True, ascending=False, bins=None, dropna=True)
```
Trong đó:

- `normalize`: `True` sẽ trả về tỉ lệ xuất hiện của các phần tử

- `sort`: `True` sẽ trả về kết quả sắp xếp theo số lần xuất hiện, `False` sẽ trả về kết quả sắp xếp theo trình tự xuất hiện của phần tử

- `ascending`: `True` sẽ trả về kết quả sắp xếp theo số lần xuất hiện tăng dần.

- `bins`: gom nhóm các phần tử, tương tự `pd.cut`

- `dropna`: `False` sẽ đếm tất cả các phần tử kể cả null

**Ví dụ**

```python
In [19]: s = pd.Series([3, 1, 2, 3,  np.nan, 4, np.nan])
In [20]: s.value_counts()
Out[20]: 
3.0    2
1.0    1
2.0    1
4.0    1
dtype: int64

In [21]: s.value_counts(normalize=True, sort=False, dropna=False)
Out[21]:
3.0    0.285714
1.0    0.142857
2.0    0.142857
NaN    0.285714
4.0    0.142857
dtype: float64

In [22]: s.value_counts(bins=3)
Out[22]:
(0.996, 2.0]    2
(2.0, 3.0]      2
(3.0, 4.0]      1
dtype: int64
```

## `.unique()` và `.nunique()`

Phương thức `.unique()` trả về các giá trị khác nhau của `Series` và `.nunique()` trả về số lượng các giá trị khác nhau của `Series`. Kết quả trả về của `.unique()` là danh sách các phần tử được sắp xếp theo thứ tự đầu vào của bảng. Để loại bỏ giá trị `NA` trong lúc đếm có thể gọi `.nunique(dropna=False)`

Cách sử dụng

```python
In [23]: s = pd.Series([2, 3, 1 ,2, np.nan], name='col_0')
In [24]: s
Out[24]:
0    2.0
1    3.0
2    1.0
3    2.0
4    NaN
Name: col_0, dtype: float64

In [25]: s.unique()
Out[25]: array([ 2.,  3.,  1., nan])

In [26]: s.nunique(dropna=False)
Out[26]: 4
```
## `.drop()`

Phương thức `.drop()` dùng để loại bỏ các dòng hoặc cột theo chỉ định.
Cú pháp của `.drop()` như sau

```python
DataFrame.drop(labels=None, axis=0, index=None, columns=None, level=None, inplace=False, errors='raise')
```

Trong đó:

- `labels`: Tên cột hoặc dòng cần loại bỏ.

- `axis`: Mặc đinh giá trị `0` loại bỏ theo dòng và `1` loại bỏ theo cột.

- `index`: Chỉ định index của dòng cần loại bỏ, tương đương `labels, axis=0`

- `columns`: Chỉ định cột cần loại bỏ, tương đương `labels, axis=1`

- `level`: Dành cho MultiIndex, khi đó chỉ định cấp độ index cần loại bỏ

- `inplace`: Thực hiện trên chính bảng hay tạo ra một bảng sao

- `errors`: mặc định `raise` sẽ trả ra lỗi và `ignore` nếu muốn bỏ qua lỗi.


**Ví dụ**

```python
In [27]: df = pd.DataFrame(np.arange(16).reshape(4, 4),
                  columns=['A', 'B', 'C', 'D'],
                  index=['A', '1A', '2A', '3A'])
In [28]: df
Out[28]:
     A   B   C   D
A    0   1   2   3
1A   4   5   6   7
2A   8   9  10  11
3A  12  13  14  15

In [29]: df.drop('A')
Out[29]:
	A	B	C	D
1A	4	5	6	7
2A	8	9	10	11
3A	12	13	14	15

In [30]: df.drop(columns=['A', 'C'])
Out[30]: 
     B   D
A    1   3
1A   5   7
2A   9  11
3A  13  15

In [31]: df.drop(index=['A', '2A'])
Out[31]: 
     A   B   C   D
1A   4   5   6   7
3A  12  13  14  15
```

```{block2, type='rmdnote'}
**_Lưu ý:_** 
Thực tế hay dùng các params `columns` và `index` để chỉ định các dòng hay cột cần được loại bỏ hơn là dùng `labels` và `axis`
``` 

## `.rename()`

Phương thức `.rename()` dùng để đổi tên nhãn của cột hoặc dòng. Cú pháp như sau

```python
DataFrame.rename(mapper=None, *, index=None, columns=None, axis=None, copy=True, inplace=False, level=None, errors='ignore')[source]
```

Trong đó:

- `mapper`: là một danh sách dạng dictionary chứa key là tên cần đổi và value là tên mới.

- `axis`: Mặc đinh giá trị `0` thay đổi theo index và `1` thay đổi theo cột.

- `index`: Chỉ định index của dòng cần thay đổi, tương đương `mapper, axis=0`, thay thế bằng `index=mapper`

- `columns`: Chỉ định cột cần thay đổi, tương đương `mapper, axis=1`, thay thế bằng `columns=mapper`

- `copy`: `True`, mặc định sao chép dữ liệu

- `level`: Dành cho MultiIndex, khi đó chỉ định cấp độ index cần đổi tên

- `inplace`: Thực hiện trên chính bảng hay tạo ra một bảng sao

- `errors`: mặc định `raise` sẽ trả ra lỗi và `ignore` nếu muốn bỏ qua lỗi.


**Ví dụ**

```python
In [32]: df = pd.DataFrame(np.arange(16).reshape(4, 4),
                        columns=['A', 'B', 'C', 'D'],
                        index=['A', '1A', '2A', '3A'])
In [33]: df.rename(mapper={'A':'aA'})
Out[33: 
     A   B   C   D
aA   0   1   2   3
1A   4   5   6   7
2A   8   9  10  11
3A  12  13  14  15

In [34]: df.rename(mapper={'A':'aA'}, axis=1)
Out[34]:
    aA   B   C   D
A    0   1   2   3
1A   4   5   6   7
2A   8   9  10  11
3A  12  13  14  15

In [35]: df.rename(columns={'A':'aA', 'B':'Bb'}, index={'A': 'OA','3A':'3a'})
Out[35]:
    aA  Bb   C   D
OA   0   1   2   3
1A   4   5   6   7
2A   8   9  10  11
3a  12  13  14  15
```

```{block2, type='rmdnote'}
**_Lưu ý:_** 
Tương tự như `.drop()` thì `columns` và `index` thường được sử dụng hơn là `mapper` và `axis`.

Vẫn chưa rõ `copy` dùng để làm gì.
``` 

## `.set_index()`

Phương thức `.set_index()` dùng để chuyển đổi một cột của bảng thành index. Index này có thể thay thể index cũ hoặc thêm vào để thành `MultiIndex`. Cách sử dụng như sau:

```python
DataFrame.set_index(keys, drop=True, append=False, inplace=False, verify_integrity=False)
```

Trong đó:

- `keys`: Có thể truyền vào một cột duy nhất hoặc danh sách các cột. Ngoài ra còn có thể là 1 danh sách dạng `pd.Index`, `Series`, `np.array`, `iterator`

- `drop`: loại bỏ cột trong bảng nếu đã đưa vào index, mặc định là `True`

- `append`: mặc định là `False` ghi đè lên index đã có. Giá trị `True` sẽ thêm vào index sẵn có.

- `inplace`: Thực hiện trực tiếp trên bảng hoặc tạo ra một bản sao

- `verify_integrity`: Kiểm tra xem cột đánh index có chứa các phần tử trùng lặp hay không.


**Ví dụ**

```python
In [36]: df = pd.DataFrame(np.arange(16).reshape(4, 4),
                  columns=['A', 'B', 'C', 'D'],
                  index=['A', '1A', '2A', '3A'])
In [37]: df.index.name = 'index1'
In [38]: df
Out[38]:
         A   B   C   D
index1                
A        0   1   2   3
1A       4   5   6   7
2A       8   9  10  11
3A      12  13  14  15

In [39]: df.set_index('A')
Out[39]:
     B   C   D
A             
0    1   2   3
4    5   6   7
8    9  10  11
12  13  14  15

In [40]: df.set_index(['A', 'B'], append=True)
Out[40]: 
               C   D
index1 A  B         
A      0  1    2   3
1A     4  5    6   7
2A     8  9   10  11
3A     12 13  14  15

In [41]: df.set_index([pd.Index([1, 2, 3, 4], name='new_index')])
Out[41]: 
            A   B   C   D
new_index                
1           0   1   2   3
2           4   5   6   7
3           8   9  10  11
4          12  13  14  15
```

```{block2, type='rmdnote'}
**_Lưu ý:_** 
`keys` không áp dụng cho kiểu `list`, `tuple` nhưng Iterator của nó thì được.
``` 
**Ví dụ** khi đưa list vào sẽ báo lỗi

```python
In [42]: df.set_index([1, 2, 3, 4])
Out[42]:
---------------------------------------------------------------------------
KeyError                                  Traceback (most recent call last)
~\AppData\Local\Temp/ipykernel_1380/3577861036.py in <module>
----> 1 df.set_index([1, 2, 3, 4])

D:\Vendors\anaconda\lib\site-packages\pandas\util\_decorators.py in wrapper(*args, **kwargs)
    309                     stacklevel=stacklevel,
    310                 )
--> 311             return func(*args, **kwargs)
    312 
    313         return wrapper

D:\Vendors\anaconda\lib\site-packages\pandas\core\frame.py in set_index(self, keys, drop, append, inplace, verify_integrity)
   5492 
   5493         if missing:
-> 5494             raise KeyError(f"None of {missing} are in the columns")
   5495 
   5496         if inplace:

KeyError: 'None of [1, 2, 3, 4] are in the columns'
```

Trong khi đưa vào `Iterator` thì hoạt động.

```python
In [43]: df.set_index(iter([1, 2, 3, 4]))
Out[43]:
    A   B   C   D
1   0   1   2   3
2   4   5   6   7
3   8   9  10  11
4  12  13  14  15
```

## `.sort_values`

```python
DataFrame.sort_values(by, axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last', ignore_index=False, key=None)
```
Trong đó:

- `by`: nhãn hoặc danh sách các nhãn

- `axis`: Thực thi theo dòng {`0` hoặc `index`} hoặc cột {`1` hoặc `columns`}

- `ascending`: bool hoặc danh sách các bool thể hiện sắp xếp theo tăng dần hoặc giảm dần. Mặc định `True`

- `inplace`: Thực thi trên chính bảng hoặc tạo một bản sao.

- `kind`: Lựa chọn thuật toán sắp xếp

- `na_position`: Đưa `NaN` lên đầu hoặc cuối

- `ignor_index`: Nếu để giá trị `True` sẽ đánh index lại từ 0 -> n-1

- `key`: áp dụng hàm vào lúc sort

```python
In []: df = pd.DataFrame({
    'col1': ['A', 'A', 'B', np.nan, 'D', 'C'],
    'col2': [2, 1, 9, 8, 7, 4],
    'col3': [0, 1, 9, 4, 2, 3],
    'col4': ['a', 'B', 'c', 'D', 'e', 'F']})
In []: df
  col1  col2  col3 col4
0    A     2     0    a
1    A     1     1    B
2    B     9     9    c
3  NaN     8     4    D
4    D     7     2    e
5    C     4     3    F
```

Sắp xếp theo `col1`

```python
In []: df.sort_values(by=['col1'])
Out[]:
  col1  col2  col3 col4
0    A     2     0    a
1    A     1     1    B
2    B     9     9    c
5    C     4     3    F
4    D     7     2    e
3  NaN     8     4    D
```

Sắp xếp theo nhiều cột và chỉ định hướng sắp xếp

```python
In []: df.sort_values(by=['col1', 'col2'] , ascending=[False, True])
Out[]:
  col1  col2  col3 col4
4    D     7     2    e
5    C     4     3    F
2    B     9     9    c
1    A     1     1    B
0    A     2     0    a
3  NaN     8     4    D
```

Đặt `NaN` lên đầu
```python
In []: df.sort_values(by=['col1', 'col2'] , ascending=False, na_position='first')
Out[]:
  col1  col2  col3 col4
3  NaN     8     4    D
4    D     7     2    e
5    C     4     3    F
2    B     9     9    c
0    A     2     0    a
1    A     1     1    B
```

Sắp xếp với key function
```python
In []: df.sort_values(by='col4', key=lambda col: col.str.lower())
Out[]:
  col1  col2  col3 col4
0    A     2     0    a
1    A     1     1    B
2    B     9     9    c
3  NaN     8     4    D
4    D     7     2    e
5    C     4     3    F
```

<!--chapter:end:posts/03-Funda_Function.Rmd-->

# Selecting và Filtering

## Sử dụng `[]`
Cú pháp `[]` là cú pháp đơn giản nhất để lấy bảng con của 1 bảng cho trước.
Với 1 `df` là 1 `DataFrame` có index là `region` và dữ liệu như sau
```python
                         state  individuals  family_members  state_pop
region                                                                
East South Central     Alabama       2570.0           864.0    4887681
Pacific                 Alaska       1434.0           582.0     735139
Mountain               Arizona       7259.0          2606.0    7158024
West South Central    Arkansas       2280.0           432.0    3009733
Pacific             California     109008.0         20964.0   39461588
Mountain              Colorado       7607.0          3250.0    5691287
```
Để chọn 1 bảng con có 2 cột `['state', 'family_members']` ta làm như sau

```python
In [1]: df[['state', 'family_members']]
Out[1]:
                         state  family_members
region                                        
East South Central     Alabama           864.0
Pacific                 Alaska           582.0
Mountain               Arizona          2606.0
West South Central    Arkansas           432.0
Pacific             California         20964.0
Mountain              Colorado          3250.0
```
Để lấy theo dòng ta dùng tương tự `Series`

```python
In [2]: df[:3]
Out[2]: 
                      state  individuals  family_members  state_pop
region                                                             
East South Central  Alabama       2570.0           864.0    4887681
Pacific              Alaska       1434.0           582.0     735139
Mountain            Arizona       7259.0          2606.0    7158024

In [3]: df[2:5]
Out[3]:
                         state  individuals  family_members  state_pop
region                                                                
Mountain               Arizona       7259.0          2606.0    7158024
West South Central    Arkansas       2280.0           432.0    3009733
Pacific             California     109008.0         20964.0   39461588
```

```{block2, type='rmdnote'}
**_Lưu ý:_** 

- `df[['state']]` sẽ trả về `DataFrame` trong khi `df['state']` trả về `Series`.

- Đối với lấy theo dòng, `[]` không lấy được theo dòng riêng biệt.

- `[]` chỉ lấy dữ liệu theo dòng hoặc cột, không thực hiện được cùng lúc cả hai thao tác.
``` 
Ví dụ khi gọi `df[3]` hay `df[[1, 2, 3]]` sẽ báo lỗi `KeyError`


## .loc và .iloc
### .loc
Phương thức `.loc` dùng để lấy dữ liệu theo cột hoặc hàng dựa theo nhãn định sẵn (Tên hàng, tên cột), ngoài ra `.loc` còn nhận các giá trị boolean.

Đầu vào của `.loc` có thể gồm:

- Nhãn đơn: là 1 số `3` hoặc dạng chữ `a`, lưu ý rằng số này là nhãn của `index` chứ không phải vị trí của dòng.

- Danh sách các nhãn : `['a', 'b', 'c']`

- Đối tượng dạng slice ví dụ `'a':'e'`

- Danh sách kiểu `bool` có độ dài bằng với số lượng dòng

- `Series` dạng `bool`

- `pd.Index`



Sử dụng nhãn đơn, kết quả trả về là các dòng có nhãn giống như nhãn trong `.loc`

```python
In [4]: df.loc['Pacific']
Out[4]:          
              state  individuals  family_members  state_pop
region                                                     
Pacific      Alaska       1434.0           582.0     735139
Pacific  California     109008.0         20964.0   39461588
```
```{block2, type='rmdnote'}
**_Lưu ý:_** 

Khi kết quả là nhiều dòng thì dữ liệu trả về có kiểu `DataFrame`, trong khi nếu chỉ có 1 dòng duy nhất thì kết quả trả về sẽ theo kiểu `Series`
``` 

```python
In [5]: type(df.loc['Pacific'])
Out[5]: 
<class 'pandas.core.frame.DataFrame'>

In [6]: type(df.loc['West South Central'])
Out[6]: 
<class 'pandas.core.series.Series'>
```

Khi đưa danh sách các nhãn dùng `.loc[[]]` thì nhãn đưa vào là nhãn của `index`. Nếu đưa tên các cột sẽ bị báo lỗi `KeyError`

```python
In [7]: df.loc[['Pacific', 'Mountain']]
Out[7]:
               state  individuals  family_members  state_pop
region                                                      
Pacific       Alaska       1434.0           582.0     735139
Pacific   California     109008.0         20964.0   39461588
Mountain     Arizona       7259.0          2606.0    7158024
Mountain    Colorado       7607.0          3250.0    5691287
```

Để lấy nhãn đơn theo nhãn của `index` và tên `column` ta truyền vào phần nhãn của `index` trước và nhãn của `column` sau và phân biệt bởi dấu phẩy

```python
In [7]: df.loc['Pacific', 'state']
Out[7]:
region
Pacific        Alaska
Pacific    California
Name: state, dtype: object
```

Để lấy nhiều hơn 1 nhãn của `index` hoặc nhiều hơn 1 nhãn của `column` ta chỉ cần thay thế nhãn đơn của `index` thành danh sách hoặc slice, tương tự ta có thế thay thế nhãn đơn thành danh sách hoặc slice của `column`

```python
In [8]: df.loc['Pacific', ['individuals', 'family_members']])
Out[8]:
         individuals  family_members
region                              
Pacific       1434.0           582.0
Pacific     109008.0         20964.0
```

```python
In [9]: df.loc['Pacific', 'individuals':'state_pop']
Out[9]:
         individuals  family_members  state_pop
region                                         
Pacific       1434.0           582.0     735139
Pacific     109008.0         20964.0   39461588
```

```{block2, type='rmdnote'}
**_Lưu ý:_** 

- Dùng slice sẽ lấy theo thứ tự xuất hiện chứ không lấy theo thứ tự sắp xếp từ điển, như ví dụ trên thì mặc dù `family_members` > `individuals` nhưng vẫn xếp sau.

- Slice không áp dụng được cho `index` có nhãn trùng nhau, nếu dùng sẽ báo lỗi `KeyError: "Cannot get right slice bound for non-unique label:`
``` 

Danh sách dạng `boolean`, chỉ sử dụng cho `index`, không dùng cho `column`

```python
In [10]: df.loc[[False, True, False, True, False, False]]
Out[10]:
                       state  individuals  family_members  state_pop
region                                                              
Pacific               Alaska       1434.0           582.0     735139
West South Central  Arkansas       2280.0           432.0    3009733
```

Series boolean
```python
In [11]: s = pd.Series([False, True, False, True, False, False],
              index=['East South Central', 'Pacific', 'Mountain', 'West South Central', 'Pacific', 'Mountain'])
In [12]: df.loc[s]
Out[12]:
                       state  individuals  family_members  state_pop
region                                                              
Pacific               Alaska       1434.0           582.0     735139
West South Central  Arkansas       2280.0           432.0    3009733
```

`pd.Index`

```python
In [13]: df.loc[pd.Index(["Pacific", "East South Central"], name="meow")]
Out[13]:
                         state  individuals  family_members  state_pop
meow                                                                   
Pacific                 Alaska       1434.0           582.0     735139
Pacific             California     109008.0         20964.0   39461588
East South Central     Alabama       2570.0           864.0    4887681
```

**Select với `MultiIndex`**
```python
                     individuals  family_members  state_pop
region   state                                             
Mountain Arizona          7259.0          2606.0    7158024
         Colorado         7607.0          3250.0    5691287
         Idaho            1297.0           715.0    1750536
Pacific  Alaska           1434.0           582.0     735139
         California     109008.0         20964.0   39461588
         Hawaii           4131.0          2399.0    1420593
```
Với nhãn đơn
```python
In [14]: df.loc['Mountain']
Out[14]: 
          individuals  family_members  state_pop
state                                           
Arizona        7259.0          2606.0    7158024
Colorado       7607.0          3250.0    5691287
Idaho          1297.0           715.0    1750536
```
```{block2, type='rmdnote'}
**_Lưu ý:_** 
Với `MultiIndex`,các index sẽ xếp theo thứ tự từ level 0 đến n (`level 0` cao hơn `level 1` ...),  với nhãn đơn là nhãn của 1 `index` thì chỉ thực hiện được index level đầu tiên, các index level sau sẽ báo lỗi.
Theo như ví dụ trên thì `region` có level cao hơn 'state' nên chỉ gọi được `.loc['Mountain']` còn `.loc['Arizona']` sẽ báo lỗi
``` 

Để select nhiều index cùng lúc, ta truyền vào `tuple(label1, label2...)` theo thứ tự index có level từ cao đến thấp

```python
In [15]: df.loc[('Mountain', 'Colorado')]
Out[15]:
individuals          7607.0
family_members       3250.0
state_pop         5691287.0
Name: (Mountain, Colorado), dtype: float64
```

Tương tự ta cùng có select theo các column cho trước

```python
In [16]: df.loc[('Mountain', 'Colorado'), ['individuals', 'family_members']]
Out[16]:
individuals       7607.0
family_members    3250.0
Name: (Mountain, Colorado), dtype: float64
```

```{block2, type='rmdtip'}
**_Mẹo:_**
Có thể select `index` ở các level sau bằng cách dùng `slice`

```

```python
In [17]: df.loc[(slice(None), 'Arizona'), :]
Out[17]:
                  individuals  family_members  state_pop
region   state                                          
Mountain Arizona       7259.0          2606.0    7158024
```
Slice cho MultiIndex
Slice từ 1 tuple nhãn đến một nhãn đơn
```python
In [18]: df.loc[('Mountain', 'Colorado'):'Pacific']
Out[18]:
                     individuals  family_members  state_pop
region   state                                             
Mountain Colorado         7607.0          3250.0    5691287
         Idaho            1297.0           715.0    1750536
Pacific  Alaska           1434.0           582.0     735139
         California     109008.0         20964.0   39461588
         Hawaii           4131.0          2399.0    1420593
```
```{block2, type='rmdnote'}
**_Lưu ý:_** 
Nhãn đơn phía sau phải có cùng level với nhãn đầu tiên trong tuple. Trong ví dụ trên nếu thay `Pacific` thành `Hawaii` sẽ trả về rỗng. Nhưng khi truyền nhãn không nằm trong các nhãn của index thì vẫn có kết quả trả về
``` 
```python
In [19]: df.loc[('Mountain', 'Colorado'): 'meow']
Out[19]:
                     individuals  family_members  state_pop
region   state                                             
Mountain Colorado         7607.0          3250.0    5691287
         Idaho            1297.0           715.0    1750536
Pacific  Alaska           1434.0           582.0     735139
         California     109008.0         20964.0   39461588
         Hawaii           4131.0          2399.0    1420593
```
Slice từ 1 tuple nhãn đến một tuple nhãn
```python
In [20]: df.loc[('Mountain', 'Colorado'):('Pacific', 'California')]
Out[20]:
                     individuals  family_members  state_pop
region   state                                             
Mountain Colorado         7607.0          3250.0    5691287
         Idaho            1297.0           715.0    1750536
Pacific  Alaska           1434.0           582.0     735139
         California     109008.0         20964.0   39461588
```

### `.iloc`
Phương thức `.iloc` dùng để lấy dữ liệu theo cột hoặc hàng dựa theo index của nó, ngoài ra `.iloc` còn nhận các giá trị boolean.

Đầu vào của `.iloc` có thể gồm:

- Nhãn đơn: là 1 số `3`

- Danh sách các số : `[1, 2, 3]`

- Đối tượng dạng slice ví dụ `1:5`

- Danh sách kiểu `bool` có độ dài bằng với số lượng dòng

Ví dụ với DataFrame 

```python
                         state  individuals  family_members  state_pop
region                                                                
East South Central     Alabama       2570.0           864.0    4887681
Pacific                 Alaska       1434.0           582.0     735139
Mountain               Arizona       7259.0          2606.0    7158024
West South Central    Arkansas       2280.0           432.0    3009733
Pacific             California     109008.0         20964.0   39461588
Mountain              Colorado       7607.0          3250.0    5691287
```
Khi truyền 1 giá trị nguyên, `.iloc` trả về giá trị của dòng tại vị trí truyền vào với kiểu `Series`

```python
In [21]: df.iloc[0]
Out[21]:
state             Alabama
individuals        2570.0
family_members      864.0
state_pop         4887681
Name: East South Central, dtype: object
```
```{block2, type='rmdnote'}
**_Lưu ý:_** 
`Series` trả về không chứa nhãn của index, ở đây là nhãn `East South Central` của index `region`

``` 
Để lấy dữ liệu theo cột, ví dụ muốn lấy cột `family_members` thì sẽ truyền index cột là `2`
```python
In [22]: df.iloc[:, 2]
Out[22]:
region
East South Central      864.0
Pacific                 582.0
Mountain               2606.0
West South Central      432.0
Pacific               20964.0
Mountain               3250.0
Name: family_members, dtype: float64
```

```{block2, type='rmdtip'}
**_Mẹo:_**

- `.iloc` bắt buộc truyền vào vị trí của cột, không cho phép tên cột.

- Sử dụng `.columns.get_loc(<tên cột>)` để lấy vị trí của cột
```
```python
In [23]: df.iloc[:, df.columns.get_loc('family_members')]
Out[23]:
region
East South Central      864.0
Pacific                 582.0
Mountain               2606.0
West South Central      432.0
Pacific               20964.0
Mountain               3250.0
Name: family_members, dtype: float64
```

Select theo danh sách, mặc định đưa vào 1 danh sách `Pandas` sẽ hiểu là lấy theo các dòng
```python
In [24]: df.iloc[[1, 3 ,5]]
Out[24]:
                   individuals  family_members  state_pop
region   state                                           
Mountain Colorado       7607.0          3250.0    5691287
Pacific  Alaska         1434.0           582.0     735139
         Hawaii         4131.0          2399.0    1420593
```
```{block2, type='rmdtip'}
**_Mẹo:_**
Dòng lệnh trên cũng tương đương với `df.iloc[[1, 3 ,5], :]`, trong đó `:` dùng để lấy toàn bộ
```
Tương tự để lấy theo danh sách index các cột
```python
In [25]: df.iloc[:, [0, 2]]
Out[25]:
                     individuals  state_pop
region   state                             
Mountain Arizona          7259.0    7158024
         Colorado         7607.0    5691287
         Idaho            1297.0    1750536
Pacific  Alaska           1434.0     735139
         California     109008.0   39461588
         Hawaii           4131.0    1420593
```
Slice cả 2 chiều
```python
In [26]: df.iloc[2:4, 0:2]
Out[26]:
                 individuals  family_members
region   state                              
Mountain Idaho        1297.0           715.0
Pacific  Alaska       1434.0           582.0
```
Sử dụng danh sách các boolean

```python
# Theo dòng
In [27]: df.iloc[[True, False, True, False, False, True], :]
Out[27]:
                  individuals  family_members  state_pop
region   state                                          
Mountain Arizona       7259.0          2606.0    7158024
         Idaho         1297.0           715.0    1750536
Pacific  Hawaii        4131.0          2399.0    1420593

#Theo cột
In [28]: df.iloc[:, [False, True,False]]
Out[28]: 
                     family_members
region   state                     
Mountain Arizona             2606.0
         Colorado            3250.0
         Idaho                715.0
Pacific  Alaska               582.0
         California         20964.0
         Hawaii              2399.0
```
## Lọc theo điều kiện
Các phương thức `[]`, `.loc` hay `.iloc` ngoài việc lấy dữ liệu theo hàng và cột còn có thể lấy ra những bảng con theo các điều kiện cho trước. Bản chất các câu điều kiện sẽ trả về một danh sách dạng bolean và các hàm trên thực hiện lọc theo danh sách đó.

Trước hết ta cần biết câu điều kiện trong Pandas như thế nào. Ví dụ ta có 1 `DataFrame` như sau

```python
               state  individuals  family_members  state_pop
region                                                      
Mountain     Arizona       7259.0          2606.0    7158024
Mountain    Colorado       7607.0          3250.0    5691287
Mountain       Idaho       1297.0           715.0    1750536
Pacific       Alaska       1434.0           582.0     735139
Pacific   California     109008.0         20964.0   39461588
Pacific       Hawaii       4131.0          2399.0    1420593
```
### Toán tử điều kiện
Giả sử ta có một điều kiện rằng `df['individuals'] > 5000`. Kết quả trả về là 1 `Series`

```python
In [28]: df['individuals'] > 5000
Out[28]:
region
Mountain     True
Mountain     True
Mountain    False
Pacific     False
Pacific      True
Pacific     False
Name: individuals, dtype: bool
```
Để lọc theo điều kiện này ta có các cách như sau
```python
## Dùng []
In [29]: df[df['individuals'] > 5000]
Out[29]:
               state  individuals  family_members  state_pop
region                                                      
Mountain     Arizona       7259.0          2606.0    7158024
Mountain    Colorado       7607.0          3250.0    5691287
Pacific   California     109008.0         20964.0   39461588

## Dùng .loc
In [30]: df.loc[df['individuals'] > 5000]
Out[30]: 
               state  individuals  family_members  state_pop
region                                                      
Mountain     Arizona       7259.0          2606.0    7158024
Mountain    Colorado       7607.0          3250.0    5691287
Pacific   California     109008.0         20964.0   39461588
```

```{block2, type='rmdnote'}
**_Lưu ý:_** 
`.iloc` không nhận `Series` boolean nhưng `array` thì có thể. Do đó ta có thể dùng `.values` để lấy kết quả của Câu điều kiện

``` 
```python
## Dùng .iloc
In [31]: df.iloc[(df['individuals'] > 5000).values]
Out[31]:
               state  individuals  family_members  state_pop
region                                                      
Mountain     Arizona       7259.0          2606.0    7158024
Mountain    Colorado       7607.0          3250.0    5691287
Pacific   California     109008.0         20964.0   39461588
```
Ta cũng có thể áp nhiều điều kiện cùng lúc, mỗi điều kiện phải nằm trong dấu ngoặc đơn `()` và giữa các kiều kiện là toán tử `&` hoặc `|`
```python
## Nhiều câu điều kiện trên một cột
In [32]: df.loc[(df['individuals'] > 5000) & (df['individuals'] < 10000)]
Out[32]:
             state  individuals  family_members  state_pop
region                                                    
Mountain   Arizona       7259.0          2606.0    7158024
Mountain  Colorado       7607.0          3250.0    5691287

## Nhiều câu điều kiện ở nhiều cột
In [33]: df.loc[(df['individuals'] > 5000) & (df['family_members'] < 10000)
Out[33]:
             state  individuals  family_members  state_pop
region                                                    
Mountain   Arizona       7259.0          2606.0    7158024
Mountain  Colorado       7607.0          3250.0    5691287

## Một câu điều kiện trên nhiều cột
In [34]: df[df['individuals'] > 5 * df['family_members']]
Out[34]:
              state  individuals  family_members  state_pop
region                                                     
Pacific  California     109008.0         20964.0   39461588
```
```{block2, type='rmdtip'}
**_Mẹo:_** 
Bạn cũng có thể dùng `loc` để vừa lọc các dòng thỏa điều kiện, vừa chọn các cột muốn lấy 
``` 
```python
In []: df.loc[df['individuals'] > 5 * df['family_members'], ['individuals', 'family_members']]
Out[]:
         individuals  family_members
region                              
Pacific     109008.0         20964.0
```
Ngoài ra, `pandas` còn cho phép bạn lọc với cấu trúc câu truy vấn bằng `.query` theo cú pháp
```python
DataFrame.query(expr, inplace=False, **kwargs)
```
Trong đó:

- `expr`: là câu truy vấn

- `inplace`: thực hiện trên chính `DataFrame` đó hay tạo 1 bảng sao

- `**kwargs`: keyword arguments

Theo ví dụ trên, để thực hiện lọc theo điều kiện `df['individuals'] > 5000` và `df['family_members'] < 10000` ta có thể làm như sau
```python
In [34]: df.query('individuals > 500 and family_members < 10000')
Out[34]: 
             state  individuals  family_members  state_pop
region                                                    
Mountain   Arizona       7259.0          2606.0    7158024
Mountain  Colorado       7607.0          3250.0    5691287
```

### `.isin()`
Phương thức `.isin(values)` để kiểm tra các phần tử trong `DataFrame` hoặc `Series` có nằm trong values hay không.

Ví dụ:
```python
In [35]: df.isin(['Alaska', 'Oklahoma', 'Illinois', 'Arizona', 7259, 582, 300])
Out[35]:
          state  individuals  family_members  state_pop
region                                                 
Mountain   True         True           False      False
Mountain  False        False           False      False
Mountain  False        False           False      False
Pacific    True        False            True      False
Pacific   False        False           False      False
Pacific   False        False           False      False

In [36]: df['state'].isin(['Alaska', 'Oklahoma', 'Illinois', 'Arizona'])
Out[36]:
region
Mountain     True
Mountain    False
Mountain    False
Pacific      True
Pacific     False
Pacific     False
Name: state, dtype: bool
```
Ngoài ra bạn có thể truyền `values` là một `dictionary` để kiểm tra cho từng cột theo từng tập giá trị
```python
In [37]: df.isin({'state': ['Alaska', 'Oklahoma', 'Illinois', 'Arizona'], 
         'individuals': [7259, 582, 300]})
Out[37]:
          state  individuals  family_members  state_pop
region                                                 
Mountain   True         True           False      False
Mountain  False        False           False      False
Mountain  False        False           False      False
Pacific    True        False           False      False
Pacific   False        False           False      False
Pacific   False        False           False      False
```
Lọc với `.isin()`
```python
In [38]: df[df['state'].isin(['Alaska', 'Oklahoma', 'Illinois', 'Arizona'])]
Out[38]:
            state  individuals  family_members  state_pop
region                                                   
Mountain  Arizona       7259.0          2606.0    7158024
Pacific    Alaska       1434.0           582.0     735139
```
trong trường hợp sự dụng `.isin` với `DataFrame`, kết quả của lọc sẽ trả về một `DataFrame` với  giá trị các phần tử mà phép `isin` trả về `True`, các phần tử còn lại trả giá trị `NaN`
```python
In [39]: df[df.isin(['Alaska', 'Oklahoma', 'Illinois', 'Arizona', 7259, 582, 300])]
Out[39]:
            state  individuals  family_members  state_pop
region                                                   
Mountain  Arizona       7259.0             NaN        NaN
Mountain      NaN          NaN             NaN        NaN
Mountain      NaN          NaN             NaN        NaN
Pacific    Alaska          NaN           582.0        NaN
Pacific       NaN          NaN             NaN        NaN
Pacific       NaN          NaN             NaN        NaN
```
```{block2, type='rmdtip'}
**_Mẹo:_**

- Bạn có dùng `.any()` để tổng hợp điều kiện của 1 DataFrame với các phần tử `boolean`

- `.any(axis=1)` : Chỉ cần tồn tại 1 cột giá trị True, trả về giá trị True cho dòng

- `.any(axis=0)`: Chỉ cần tồn tại 1 dòng có giá trị True, trả về giá trị True cho cột.

- Phương thức `.any()` thường dùng để kiểm tra các dòng tồn tại 1 cột giá trị `NaN`
```

Lọc với `.isin()` và `any(axis=1)`
```python
In [40]: df.isin(['Alaska', 'Oklahoma', 'Illinois', 'Arizona', 7259, 582, 300]).any(axis=1)
Out[40]:
region
Mountain     True
Mountain    False
Mountain    False
Pacific      True
Pacific     False
Pacific     False
dtype: bool

In [41]: df[df.isin(['Alaska', 'Oklahoma', 'Illinois', 'Arizona', 7259, 582, 300]).any(axis=1)]
Out[41]: 
            state  individuals  family_members  state_pop
region                                                   
Mountain  Arizona       7259.0          2606.0    7158024
Pacific    Alaska       1434.0           582.0     735139
```

Lọc với `isin()` và `any(axis=0)`
```python
In [42]: df.isin(['Alaska', 'Oklahoma', 'Illinois', 'Arizona', 7259, 582, 300]).any(axis=0)
Out[42]:
state              True
individuals        True
family_members     True
state_pop         False
dtype: bool

In [43]: df.loc[:,df.isin(['Alaska', 'Oklahoma', 'Illinois', 'Arizona', 7259, 582, 300]).any(axis=0)]
Out[43]:
               state  individuals  family_members
region                                           
Mountain     Arizona       7259.0          2606.0
Mountain    Colorado       7607.0          3250.0
Mountain       Idaho       1297.0           715.0
Pacific       Alaska       1434.0           582.0
Pacific   California     109008.0         20964.0
Pacific       Hawaii       4131.0          2399.0
```
Lọc với `isin()` và `any(axis=0)` và `any(axis=1)`
```python
In []: bool_df = df.isin(['Alaska', 'Oklahoma', 'Illinois', 'Arizona', 7259, 582, 300])
In []: df.loc[bool_df.any(axis=1), bool_df.any(axis=0)]
Out[]:
            state  individuals  family_members
region                                        
Mountain  Arizona       7259.0          2606.0
Pacific    Alaska       1434.0           582.0
```

### Lọc missing value với `.dropna()`

Trong quá trình xử lý dữ liệu, chúng ta thường gặp những bảng có chứa giá trị missing value. Ví dụ bảng `missing_df`

```python
               state  individuals  family_members   state_pop
region                                                       
Mountain     Arizona       7259.0             NaN         NaN
Mountain    Colorado          NaN          3250.0   5691287.0
Mountain       Idaho       1297.0           715.0   1750536.0
Pacific       Alaska       1434.0             NaN    735139.0
Pacific   California     109008.0         20964.0  39461588.0
Pacific       Hawaii       4131.0          2399.0         NaN
```
Để lọc dữ liệu chứa `NaN` ta dùng phương thức `.dropna()`
```python
DataFrame.dropna(axis=0, how='any', thresh=None, subset=None, inplace=False)
```
Trong đó:

- `axis`: Nhận diện lọc theo dòng `0`, `index`, hay cột `1`, `column`

- `how`: Chỉ định cách lọc
    - `any`: Nếu có bất kì `NA`, loại bỏ dòng hoặc cột
    - `all`: Nếu tất cả là `NA`, loại bỏ dòng hoặc cột

- `thresh`: Số lượng `non-NA` yêu cầu

- `subset`: Chỉ định các cột cần lọc

- `inplace`: Thực hiện trên chính `DataFrame` hay tạo bản sao.


Lọc bỏ các hàng nếu ít nhất một phần tử `NA`
```python
In []: missing_df.dropna(axis=0)
Out[]:
               state  individuals  family_members   state_pop
region                                                       
Mountain       Idaho       1297.0           715.0   1750536.0
Pacific   California     109008.0         20964.0  39461588.0
```

Lọc bỏ các cột nếu ít nhất một phần tử `NA`
```python
In []: missing_df.dropna(axis='columns')
Out[]:
               state
region              
Mountain     Arizona
Mountain    Colorado
Mountain       Idaho
Pacific       Alaska
Pacific   California
Pacific       Hawaii
```
Lọc bỏ các dòng nếu tất cả phần tử trong các cột `['family_members', 'state_pop']` là `NA`
```python
In []: missing_df.dropna(axis='index', how='all', subset=['family_members', 'state_pop'])
Out[]:
               state  individuals  family_members   state_pop
region                                                       
Mountain    Colorado          NaN          3250.0   5691287.0
Mountain       Idaho       1297.0           715.0   1750536.0
Pacific       Alaska       1434.0             NaN    735139.0
Pacific   California     109008.0         20964.0  39461588.0
Pacific       Hawaii       4131.0          2399.0         NaN
```

Giữ lại các dòng có ít nhất `3` phần tử `non-NA`
```python
In []: missing_df.dropna(thresh=3)
Out[]: 
               state  individuals  family_members   state_pop
region                                                       
Mountain    Colorado          NaN          3250.0   5691287.0
Mountain       Idaho       1297.0           715.0   1750536.0
Pacific       Alaska       1434.0             NaN    735139.0
Pacific   California     109008.0         20964.0  39461588.0
Pacific       Hawaii       4131.0          2399.0         NaN
```

<!--chapter:end:posts/04-Select_Filter.Rmd-->

# Tính toán trên các phần tử trong Pandas 


```python
df = pd.read_csv('data/big_mart_sales.csv')
```
## Sử dụng Vectorization

Giả sử như muốn tạo cột `price`= `Item_Outlet_Sales` * `5%`
```python
In []: df['price'] = df['Item_Outlet_Sales'] * 0.05
In []: df[['Item_Outlet_Sales', 'price']]
Out[]:
      Item_Outlet_Sales      price
0             3735.1380  186.75690
1              443.4228   22.17114
2             2097.2700  104.86350
3              732.3800   36.61900
4              994.7052   49.73526
...                 ...        ...
8518          2778.3834  138.91917
8519           549.2850   27.46425
8520          1193.1136   59.65568
8521          1845.5976   92.27988
8522           765.6700   38.28350
```
Nối hai cột lại với nhau, Ví dụ 

- nối `Item_type` và `Item_Fat_Content` thành `Item_Type_Fat_Content`

- nối `Outlet_Identifier` và `Outlet_Establishment_Year` thành `Outlet_Identifier_Establishment_Year`. Trong trường hợp hợp này `Outlet_Establishment_Year` thuộc dạng số nên để nối dạng text và số ta ép kiểu dạng số về text sử dụng `astype()`

```python
df['Item_Type_Fat_Content'] = df['Item_Type'] + '_' + df['Item_Fat_Content']
df['Outlet_Identifier_Establishment_Year'] = df['Outlet_Identifier'] + '_' +df['Outlet_Establishment_Year'].astype('str')
df[['Item_Type_Fat_Content', 'Outlet_Identifier_Establishment_Year']]
```

```python
              Item_Type_Fat_Content Outlet_Identifier_Establishment_Year
0                     Dairy_Low Fat                          OUT049_1999
1               Soft Drinks_Regular                          OUT018_2009
2                      Meat_Low Fat                          OUT049_1999
3     Fruits and Vegetables_Regular                          OUT010_1998
4                 Household_Low Fat                          OUT013_1987
...                             ...                                  ...
8518            Snack Foods_Low Fat                          OUT013_1987
8519           Baking Goods_Regular                          OUT045_2002
8520     Health and Hygiene_Low Fat                          OUT035_2004
8521            Snack Foods_Regular                          OUT018_2009
8522            Soft Drinks_Low Fat                          OUT046_1997
```
## Sử dụng apply

Phương thức `apply` để thực thi một hàm theo dòng hoặc cột

**Đối với Series**

```python
Series.apply(func, convert_dtype=True, args=(), **kwargs)
```

Trong đó:

- `func`: là hàm cần thực thi

- `convert_dtype`: Giá trị kiểu boolean. Nếu nó được đặt thành True (mặc định), xử lý dữ liệu sẽ cố gắng tìm dtype tốt hơn cho các kết quả của hàm `func`. Nếu `False`, thì dtype sẽ là type(object)

- `args`: Các đối số của hàm 


Ví dụ, thao tác `Item_Outlet_Sales` * `5%`

Sử dụng lambda function

```python
In []: df['Item_Outlet_Sales'].apply(lambda x: x * 0.05)
Out[]:
0       186.75690
1        22.17114
2       104.86350
3        36.61900
4        49.73526
          ...    
8518    138.91917
8519     27.46425
8520     59.65568
8521     92.27988
8522     38.28350
Name: Item_Outlet_Sales, Length: 8523, dtype: float64
```
Sử dụng hàm tự định nghĩa

```python
def set_price(x, k=0.05):
    return x * k
```
```python
In []: df['Item_Outlet_Sales'].apply(set_price)
Out[]: 
0       186.75690
1        22.17114
2       104.86350
3        36.61900
4        49.73526
          ...    
8518    138.91917
8519     27.46425
8520     59.65568
8521     92.27988
8522     38.28350
Name: Item_Outlet_Sales, Length: 8523, dtype: float64
```
Có thể truyền tham số `k` vào hàm `set_price` bằng hai cách
```python
# Cách 1 - Dùng lambda
In []: df['Item_Outlet_Sales'].apply(lambda x: set_price(x, 0.1))

# Cách 2 - Dùng `arg`
In []: df['Item_Outlet_Sales'].apply(set_price, k=0.1)
```

**Đối với `DataFrame`**

Ta dùng cú pháp

```python
DataFrame.apply(func, axis=0, raw=False, result_type=None, args=(), **kwargs)
```
Trong đó:

- `func`: là hàm cần thực thi

- `axis`: thực thi theo dòng `0` hoặc cột `1`

- `raw`: Xác định xem dòng hoặc cột có thể chuyển về `Series` hoặc `ndarray`

- `result_type`: Chỉ áp dụng cho `axis=1` 

- `args`: Các đối số của hàm 

Ví dụ:

```python
In []: sample_df = sample_df = pd.DataFrame([[1, 2, 'A'], [3, 6, 'B'], [5, 10, 'C']], columns=['A', 'B', 'C'])
In []: sample_df
Out[]:
   A   B  C
0  1   2  A
1  3   6  B
2  5  10  C
```
Áp dụng trên toàn `DataFrame`

```python
In []: sample_df.apply(lambda x: x * 2)
Out[]:
     A	 B	 C
0	 2	 4	AA
1	 6	12	BB
2	10	20	CC
```
```{block2, type='rmdnote'}
**_Lưu ý:_** 

Khi áp dụng cho toàn `DataFrame` hãy cẩn thận hàm `func` truyền vào, nếu `func` không áp dụng được cho toàn bộ các phần tử sẽ báo lỗi.

Ví dụ ở trên với x * 2 vẫn áp dụng được cho cột `C` dạng `str`, nhưng khi thay bằng x ** 2 sẽ báo lỗi vì toán tử `**` không áp dụng cho `str` 
```

Áp dụng trên một số cột trong `DataFrame`
``` Python
## Theo cột
In []: sample_df[['A', 'B']].apply(np.sum, axis=1)
Out[]:
0    13
1    13
2    13
dtype: int64

## Theo dòng

In []: df[['A', 'B']].apply(lambda x: np.sum(x), axis=0)
Out[]:
A    12
B    27
dtype: int64
```
Một cách khác áp dụng trên một số cột trong `DataFrame`

Sử dụng lambda
```python
In []: sample_df.apply(lambda x: x['A'] + 2 * x['B'], axis=1)
Out[]: 
0     5
1    15
2    25
dtype: int64
```
Dùng hàm định nghĩa
```python 
def dsum(row):
    return row['A'] + 2 * row['B']
```
```python
In []: sample_df.apply(dsum, axis=1)
Out[]: 
0     5
1    15
2    25
dtype: int64
```
```{block2, type='rmdtip'}
**_Mẹo:_**

- Không nhất thiết giá trị trả về của hàm là giá trị đơn, giá trị trả về có thể dưới dạng list, tuple hoặc dict

- Dùng `result_type` để thay đổi cách trả về
```

Ví dụ ta có 1 hàm trả về nhiều giá trị cùng lúc như sau

```python
def dsum_2(row):
    return [row['A'] + 2 * row['B'],  row['A'] - 2 * row['B']]
```

```python
## Khi không sử dụng `result_type`
In []: sample_df.apply(dsum_2, axis=1)
Out[]: 
0      [5, -3]
1     [15, -9]
2    [25, -15]
dtype: object
```
Kết quả trả về của phương pháp trên là `Series` với các giá trị của nó là dạng list. Để chuyển `Series` này thành `DataFrame` với các cột chứa các giá trị của list theo thứ tự, ta dùng `result_type='expand'`

```python
In []: sample_df.apply(dsum_2, axis=1, result_type='expand')
    0   1
0   5  -3
1  15  -9
2  25 -15
```

```{block2, type='rmdtip'}
**_Mẹo:_** Có thể cấu trúc trả về dưới dạng `DataFrame` cho ví dụ trên mà không cần dùng `result_type` bằng cách sử dụng `pd.Series` của một `dictionary`. Lúc này các cột của `DataFrame` sẽ được đánh nhãn theo key của `dictionary`
```

```python
def dsum_3(row):
    return pd.Series({'X': row['A'] + 2 * row['B'],  'Y':row['A'] - 2 * row['B']})
```

```python
In []: sample_df.apply(dsum_3, axis=1)
Out[]:
	X	Y
0	5	-3
1	15	-9
2	25	-15
```
## Sử dụng iterator
```python
df = pd.read_csv('data/big_mart_sales.csv', usecols=['Item_Identifier', 'Item_Fat_Content', 'Item_Type', 'Outlet_Size', 'Item_Outlet_Sales', 'Outlet_Establishment_Year'])
```
### Iterrows
```python
DataFrame.iterrows()
```
```python
In []: row = next(df.iterrows())
Out[]: row
(0,
 Item_Identifier                 FDA15
 Item_Fat_Content              Low Fat
 Item_Type                       Dairy
 Outlet_Establishment_Year        1999
 Outlet_Size                    Medium
 Item_Outlet_Sales            3735.138
 Name: 0, dtype: object)
```
Kết quả trả về cho row là 1 tuple gồm index và Series chứa các giá trị tại index đó. 

**Cách dùng vòng lặp trong iterrows**

Để duyệt từng dòng ta dùng `for` như bình thường

```python
prices = []
for i, row in df.iterrows():
    prices.append(row['Item_Outlet_Sales'] * 0.5)
print(prices[:5])
```
```python
[1867.569, 221.7114, 1048.635, 366.19, 497.3526]
```

### Itertuple

```python
DataFrame.itertuples(index=True, name='Pandas')
```

Trong đó:

- `index`: `True` trả về kết quả kèm theo index và `False` lược bỏ index

- `name`: Quy định kiểu trả về
    - `Pandas`: trả về namedtuple
    - `None`: trả về tuple
    - `namedtuple`: trả về namedtuple

Trả về `namedtuple`   
```python
In []: next(df.itertuples(index=True))
Out[]:
Pandas(Index=0, Item_Identifier='FDA15', Item_Fat_Content='Low Fat', Item_Type='Dairy', Outlet_Establishment_Year=1999, Outlet_Size='Medium', Item_Outlet_Sales=3735.138)
```

Trả về `tuple`
```python
In []: next(df.itertuples(index=False, name=None))
Out[]:
('FDA15', 'Low Fat', 'Dairy', 1999, 'Medium', 3735.138)
```

**Cách dùng vòng lặp trong itertuples**

`name=default`
```python
prices = []
for row in df.itertuples():
    prices.append(row.Item_Outlet_Sales * 0.5)
print(prices[:5])
```

`name=None`

```python
prices = []
for row in df.itertuples(index=False, name=None):
    prices.append(row[5] * 0.5)
print(prices[:5])
```
## So sánh các phương pháp lặp

```python

def vectorizer(df):
    prices = df['Item_Outlet_Sales'] * 0.5

def applyer(df):
    prices = df['Item_Outlet_Sales'].apply(lambda x: x * 0.5)

def iterrows(df):
    prices = []
    for i, row in df.iterrows():
        prices.append(row['Item_Outlet_Sales'] * 0.5)

def itertuples1(df):
    prices = []
    for row in df.itertuples():
        prices.append(row.Item_Outlet_Sales * 0.5)

def itertuples2(df):
    prices = []
    for row in df.itertuples(index=False, name=None):
        prices.append(row[5] * 0.5)
```

```python
In []: %timeit -n 10 vectorizer(df)
Out[]:
80.1 µs ± 42.8 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)

In[ ]: %timeit -n 10 applyer(df)
Out[]:
1.37 ms ± 112 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)

In []: %timeit -n 10 iterrows(df)
Out[]:
256 ms ± 2.48 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)

In []: %timeit -n 10 itertuples1(df)
Out[]: 
6.61 ms ± 200 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)

In []: %timeit -n 10 itertuples2(df)
Out[]:
3.91 ms ± 132 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)
```
## Xử lý song song trong pandas

Xử lý song song là phương pháp tận dụng số lượng core của CPU để giải quyết vấn đề trong thời gian ngắn hơn.


### pandarallel
Để cài đặt pandarallel bằng `pip`
```python
pip install pandarallel
```
Cách sử dụng
```python
from pandarallel import pandarallel
pandarallel.initialize(progress_bar=True, n_workers=4)
```
Để thiết lập cho pandarallel ta dùng `.initialize`. Trong đó:

- `n_workers`: là số lượng cores của CPU

- `progress_bar`: show tiến trình

Để áp dụng pandarallel ta chỉ việc thay thế `.apply` bằng `.parallel_apply`

```python
# df.apply(func)
df.parallel_apply(func)
```

<!--chapter:end:posts/05-Loop.Rmd-->

# Các cách phối hợp nhiều bảng với nhau 
## Join
## Merge
## Concat

<!--chapter:end:posts/06-Merge_Join_Concat.Rmd-->

# Groupby

## Groupby
Phương thức `.groupby` sẽ gom các dòng hoặc các cột thành các nhóm khác nhau. Cú pháp cơ bản của `.groupby` như sau
```python
DataFrame.groupby(by=None, axis=0, dropna=True)
```
Trong đó

- `by`: có thể là dạng mapping, nhãn, danh sách nhãn hoặc một hàm trả về danh sách các index

- `axis`: Tùy chọn group theo dòng {`0` hoặc `index`} hoặc cột {`1` hoặc `columns`}, mặc định là dòng.

- `dropna`: Mặc định là `True` sẽ bỏ qua những dòng chứa `NA` và `False` sẽ thêm `NA` là một khóa trong nhóm, tương tự như `.value_counts()`

Ví dụ với dữ liệu [Big Mart Salses](https://www.kaggle.com/datasets/brijbhushannanda1979/bigmart-sales-data?select=Train.csv)

```python
In [1]: df.head()
Out[1]:
  Item_Identifier              Item_Type Outlet_Size  Item_Outlet_Sales
0           FDA15                  Dairy      Medium          3735.1380
1           DRC01            Soft Drinks      Medium           443.4228
2           FDN15                   Meat      Medium          2097.2700
3           FDX07  Fruits and Vegetables         NaN           732.3800
4           NCD19              Household        High           994.7052
```

```python
In [2]: grouped = df.groupby('Item_Type')
In [3]: type(grouped)
Out[3]:
pandas.core.groupby.generic.DataFrameGroupBy
```
Để xem từng nhóm trong group, ta có thể sử dụng `.get_groups()` và truyền key vào đó. Ví dụ với key `Dairy`

```python
In [4]: grouped.get_group('Dairy').head()
Out[4]:
   Item_Identifier Item_Type Outlet_Size  Item_Outlet_Sales
0            FDA15     Dairy      Medium          3735.1380
11           FDA03     Dairy       Small          2187.1530
19           FDU02     Dairy       Small          2748.4224
28           FDE51     Dairy         NaN           178.4344
30           FDV38     Dairy         NaN           163.7868
```

Khi chọn 1 column sau khi `.groupby` sẽ trả về kiểu `pandas.core.groupby.generic.SeriesGroupBy`

## Các hàm Filtering trong Groupby

**`.head(n=5)`**

Trả về `n` dòng đầu của mỗi group. 

```python
In [4]: df.groupby(['Item_Type']).head(n=2)
Out[4]:
    Item_Identifier              Item_Type Outlet_Size  Item_Outlet_Sales
0             FDA15                  Dairy      Medium          3735.1380
1             DRC01            Soft Drinks      Medium           443.4228
2             FDN15                   Meat      Medium          2097.2700
3             FDX07  Fruits and Vegetables         NaN           732.3800
4             NCD19              Household        High           994.7052
5             FDP36           Baking Goods      Medium           556.6088
6             FDO10            Snack Foods        High           343.5528
7             FDP10            Snack Foods      Medium          4022.7636
8             FDH17           Frozen Foods         NaN          1076.5986
9             FDU28           Frozen Foods         NaN          4710.5350
10            FDY07  Fruits and Vegetables      Medium          1516.0266
11            FDA03                  Dairy       Small          2187.1530
15            FDP49              Breakfast       Small          1547.3192
16            NCB42     Health and Hygiene      Medium          1621.8888
17            FDP49              Breakfast      Medium           718.3982
18            DRI11            Hard Drinks      Medium          2303.6680
21            FDW12           Baking Goods      Medium          4064.0432
22            NCB30              Household       Small          1587.2672
27            DRJ59            Hard Drinks        High           308.9312
29            FDC14                 Canned       Small           125.8362
31            NCS17     Health and Hygiene      Medium          2741.7644
33            FDO23                 Breads         NaN          2174.5028
34            DRH01            Soft Drinks       Small          2085.2856
41            FDK43                   Meat        High          2150.5340
43            FDC02                 Canned      Medium          6768.5228
72            FDH35          Starchy Foods         NaN          4604.6728
114           FDV11                 Breads         NaN          3151.8972
136           FDH35          Starchy Foods      Medium          5262.4832
139           NCN07                 Others         NaN           263.6568
142           NCO55                 Others         NaN          2143.8760
231           FDG33                Seafood      Medium          3435.5280
713           FDH21                Seafood      Medium          1267.6832
```
**`.tail(n=5)`**

Trả về `n` dòng cuối của mỗi group

```python
In [5]: df.groupby(['Item_Type']).tail(n=2)
Out[5]:
     Item_Identifier              Item_Type Outlet_Size  Item_Outlet_Sales
8317           FDN13              Breakfast         NaN          1306.9654
8335           FDO49              Breakfast      Medium           708.4112
8370           FDV23                 Breads       Small           871.5322
8413           FDW59                 Breads       Small          1691.1320
8423           FDJ57                Seafood      Medium          2600.6148
8426           FDA22          Starchy Foods       Small          4512.1266
8457           FDY50                  Dairy       Small          1516.6924
8463           FDG59          Starchy Foods      Medium           810.9444
8473           DRI47            Hard Drinks         NaN           431.4384
8483           DRI11            Hard Drinks         NaN          1612.5676
8488           NCN14                 Others      Medium          2756.4120
8489           FDV13                 Canned      Medium          2109.2544
8491           FDO03                   Meat      Medium          4809.7392
8496           FDJ57                Seafood         NaN          3715.1640
8499           NCK53     Health and Hygiene       Small          2976.1260
8502           NCH43              Household         NaN          3020.0688
8504           NCN18              Household      Medium          4138.6128
8506           DRF37            Soft Drinks      Medium          3944.8650
8508           FDW31  Fruits and Vegetables         NaN          2587.9646
8509           FDG45  Fruits and Vegetables         NaN           424.7804
8511           FDF05           Frozen Foods      Medium          4207.8560
8512           FDR26                  Dairy        High          2479.4392
8513           FDH31                   Meat       Small           595.2252
8514           FDA01                 Canned         NaN           468.7232
8515           FDH24           Baking Goods      Medium          1571.2880
8516           NCJ19                 Others      Medium           858.8820
8517           FDF53           Frozen Foods       Small          3608.6360
8518           FDF22            Snack Foods        High          2778.3834
8519           FDS36           Baking Goods         NaN           549.2850
8520           NCJ29     Health and Hygiene       Small          1193.1136
8521           FDN46            Snack Foods      Medium          1845.5976
8522           DRG01            Soft Drinks       Small           765.6700
```

```{block2, type='rmdnote'}
**_Lưu ý:_** 
`.head()` và `.tail()` trả về các dòng theo thứ tự index của chúng, không trả về theo thứ tự sắp xếp theo key
``` 

## Aggregate trong Groupby

**`.count()`**

Đếm số lượng phần tử cho từng cột trong từng nhóm, không đếm các phần tử NA
```python
In [6]: df.groupby(['Item_Type']).count() 
Out[6]:
                       Item_Identifier  Outlet_Size  Item_Outlet_Sales
Item_Type                                                             
Baking Goods                       648          463                648
Breads                             251          179                251
Breakfast                          110           79                110
Canned                             649          471                649
Dairy                              682          496                682
Frozen Foods                       856          615                856
Fruits and Vegetables             1232          883               1232
Hard Drinks                        214          148                214
Health and Hygiene                 520          367                520
Household                          910          649                910
Meat                               425          309                425
Others                             169          123                169
Seafood                             64           46                 64
Snack Foods                       1200          868               1200
Soft Drinks                        445          312                445
Starchy Foods                      148          105                148
```

**`.size()`**

Đếm số lượng dòng cho từng nhóm

```python
In [7]: df.groupby(['Item_Type']).size()
Out[7]:
Item_Type
Baking Goods              648
Breads                    251
Breakfast                 110
Canned                    649
Dairy                     682
Frozen Foods              856
Fruits and Vegetables    1232
Hard Drinks               214
Health and Hygiene        520
Household                 910
Meat                      425
Others                    169
Seafood                    64
Snack Foods              1200
Soft Drinks               445
Starchy Foods             148
dtype: int64
```
**`SeriesGroupBy.nlargest(n=5)`** 

Trả về `n` dòng lớn nhất của từng nhóm Series
```python
In []: df.groupby(['Item_Type'])['Item_Outlet_Sales'].nlargest(n=2)
Out[]:
Item_Type                  
Baking Goods           2776     7931.6754
                       809      7759.8990
Breads                 3757     8958.3390
                       7737     7158.6816
Breakfast              7343     8209.3140
                       7690     7943.6598
Canned                 6541    10306.5840
                       6886     8217.3036
Dairy                  4888    10256.6490
                       1009    10236.6750
Frozen Foods           7752     9678.0688
                       997      9275.9256
Fruits and Vegetables  5223    12117.5600
                       1450    11445.1020
Hard Drinks            3087     7843.1240
                       1043     7152.0236
Health and Hygiene     4289     9779.9362
                       4991     8508.9240
Household              7188    13086.9648
                       7191    10072.8882
Meat                   8201     9390.4432
                       7930     9227.9880
Others                 197      6008.8450
                       3529     5546.1140
Seafood                2528     6503.5344
                       5042     5992.2000
Snack Foods            4349    10993.6896
                       333      9267.9360
Soft Drinks            6606     9554.2300
                       5619     8868.4560
Starchy Foods          1254     8132.0812
                       661      7443.6440
Name: Item_Outlet_Sales, dtype: float64
```

**`SeriesGroupBy.nsmallest(n=5)`**

Trả về `n` dòng nhỏ nhất của từng nhóm Series

```python
In []: df.groupby(['Item_Type'])['Item_Outlet_Sales'].nsmallest(n=2)
Out[]: 
Item_Type                  
Baking Goods           2055     37.2848
                       430      38.6164
Breads                 7388     35.2874
                       417      83.8908
Breakfast              4350     39.9480
                       920      50.6008
Canned                 5670     37.9506
                       4297     41.9454
Dairy                  3940     40.6138
                       5427     44.6086
Frozen Foods           4265     36.6190
                       7612     36.6190
Fruits and Vegetables  8486     45.2744
                       540      56.5930
Hard Drinks            574      37.9506
                       8116     71.9064
Health and Hygiene     3053     34.6216
                       4280     37.9506
Household              6950     33.2900
                       7861     41.2796
Meat                   5374     47.9376
                       2407     71.9064
Others                 6139     39.9480
                       2394     55.2614
Seafood                6903    149.8050
                       4502    158.4604
Snack Foods            2571     33.9558
                       6871     42.6112
Soft Drinks            906      33.2900
                       1913     40.6138
Starchy Foods          828      58.5904
                       5445     97.2068
Name: Item_Outlet_Sales, dtype: float64
```


**aggregate**
```python
.aggregate(func=None, *args, engine=None, engine_kwargs=None)
```
Trong đó:

- `func`:
  - một hàm hoặc danh sách hàm

  - hàm dạng string

  - dictionary chứa nhãn và hàm cho từng nhãn

- `*args`: Đối số truyền vào hàm `func`

- `engine`: Engine tính toán có thể là `cython`, `numba`

Danh sách hàm

```python
In []: df.groupby('Item_Type').agg(['min','max'])
Out[]:
                      Item_Identifier        Item_Outlet_Sales            
                                  min    max               min         max
Item_Type                                                                 
Baking Goods                    FDA11  FDZ60           37.2848   7931.6754
Breads                          FDN23  FDZ35           35.2874   8958.3390
Breakfast                       FDK25  FDR37           39.9480   8209.3140
Canned                          FDA01  FDZ49           37.9506  10306.5840
Dairy                           DRC27  FDZ50           40.6138  10256.6490
Frozen Foods                    FDA04  FDZ52           36.6190   9678.0688
Fruits and Vegetables           FDA07  FDZ56           45.2744  12117.5600
Hard Drinks                     DRF23  DRQ35           37.9506   7843.1240
Health and Hygiene              NCA05  NCZ53           34.6216   9779.9362
Household                       NCA06  NCZ54           33.2900  13086.9648
Meat                            FDA39  FDZ51           47.9376   9390.4432
Others                          NCI31  NCQ43           39.9480   6008.8450
Seafood                         FDF33  FDK45          149.8050   6503.5344
Snack Foods                     FDA09  FDZ58           33.9558  10993.6896
Soft Drinks                     DRA12  DRZ24           33.2900   9554.2300
Starchy Foods                   FDA22  FDZ34           58.5904   8132.0812
```
```{block2, type='rmdnote'}
**_Lưu ý:_** 

`min`, `max` không áp dụng được cho các cột có NaN value. Lúc này pandas sẽ báo Warning `FutureWarning: ['Outlet_Size'] did not aggregate successfully.`
``` 

Dictionary chứa nhãn và hàm

```python
In []: df.groupby('Item_Type').agg({'Item_Identifier': np.max, 'Item_Outlet_Sales': [np.std, np.mean]})
Out[]:
                      Item_Identifier Item_Outlet_Sales             
                                 amax               std         mean
Item_Type                                                           
Baking Goods                    FDZ60       1546.788045  1952.971207
Breads                          FDZ35       1644.235914  2204.132226
Breakfast                       FDR37       1911.693586  2111.808651
Canned                          FDZ49       1645.235638  2225.194904
Dairy                           FDZ50       1884.404698  2232.542597
Frozen Foods                    FDZ52       1724.777720  2132.867744
Fruits and Vegetables           FDZ56       1799.503459  2289.009592
Hard Drinks                     DRQ35       1606.191587  2139.221622
Health and Hygiene              NCZ53       1553.633063  2010.000265
Household                       NCZ54       1692.245757  2258.784300
Meat                            FDZ51       1695.231081  2158.977911
Others                          NCQ43       1431.860471  1926.139702
Seafood                         FDK45       1842.988719  2326.065928
Snack Foods                     FDZ58       1705.121755  2277.321739
Soft Drinks                     DRZ24       1674.249752  2006.511735
Starchy Foods                   FDZ34       1773.945328  2374.332773
```

**Sử dụng hàm tự định nghĩa trong Aggregate**

Ta có 2 function sau

```python
def foo(item_outlet_sales, alpha=1):
    mean = np.mean(item_outlet_sales)
    return np.sum(item_outlet_sales[item_outlet_sales < alpha * mean])

def bar(item_identifier):
    return len(set(item_identifier))
```

```python
In []: df.groupby('Item_Type').agg({'Item_Identifier': [np.max, bar], 'Item_Outlet_Sales': [np.mean, foo]})
Out[]:
                      Item_Identifier      Item_Outlet_Sales             
                                 amax  bar              mean          foo
Item_Type                                                                
Baking Goods                    FDZ60  119       1952.971207  348230.7108
Breads                          FDZ35   45       2204.132226  152370.9932
Breakfast                       FDR37   20       2111.808651   64478.7352
Canned                          FDZ49  120       2225.194904  414387.2620
Dairy                           FDZ50  125       2232.542597  440485.2904
Frozen Foods                    FDZ52  155       2132.867744  514843.8318
Fruits and Vegetables           FDZ56  220       2289.009592  783023.4112
Hard Drinks                     DRQ35   40       2139.221622  126412.1170
Health and Hygiene              NCZ53   95       2010.000265  272449.3548
Household                       NCZ54  170       2258.784300  538634.1974
Meat                            FDZ51   80       2158.977911  263468.3786
Others                          NCQ43   30       1926.139702   81071.1370
Seafood                         FDK45   10       2326.065928   31677.4324
Snack Foods                     FDZ58  220       2277.321739  762663.2472
Soft Drinks                     DRZ24   80       2006.511735  257134.6232
Starchy Foods                   FDZ34   30       2374.332773   94087.5270
```
bạn có thể truyền vào tham số alpha bằng cách dùng lambda

```python
In []: df.groupby('Item_Type').agg({'Item_Outlet_Sales': [np.mean, lambda x: foo(x, alpha=0.1)]})
Out[]: 
                      Item_Outlet_Sales            
                                   mean  <lambda_0>
Item_Type                                          
Baking Goods                1952.971207   5035.4454
Breads                      2204.132226   1557.3062
Breakfast                   2111.808651   1440.7912
Canned                      2225.194904   5354.3636
Dairy                       2232.542597   5992.8658
Frozen Foods                2132.867744   7111.4098
Fruits and Vegetables       2289.009592  12268.0308
Hard Drinks                 2139.221622   1625.2178
Health and Hygiene          2010.000265   3723.8194
Household                   2258.784300   8425.0332
Meat                        2158.977911   4526.1084
Others                      1926.139702   1445.4518
Seafood                     2326.065928   1404.1722
Snack Foods                 2277.321739   9573.5382
Soft Drinks                 2006.511735   3207.1586
Starchy Foods               2374.332773   1151.1682
```

**Apply trên nhiều cột và sử dụng function tự định nghĩa**

Giả sử muốn lấy top_2 item có số lượng Outlet_Sales cao nhất và cao nhì trong từng nhóm. Ta định nghĩa function sau
```python
def get_top_ex1(g):
    top_1, top_2 = sorted(list(zip(g['Item_Identifier'], g['Item_Outlet_Sales'])), key=lambda x: -x[1])[:2]
    return pd.Series({'top_1_Item_Identifier': top_1[0],
                      'top_1_Item_Outlet_Sales': top_1[1], 
                      'top_2_Item_Identifier': top_2[0],
                      'top_2_Item_Outlet_Sales': top_2[1]})
```
Trong đó g là DataFrame của từng nhóm chia theo key của `groupby`

```python
In []: df.groupby('Item_Type').apply(get_top_ex1)
Out[]:
                      top_1_Item_Identifier  top_1_Item_Outlet_Sales  \
Item_Type                                                              
Baking Goods                          FDB37                7931.6754   
Breads                                FDR35                8958.3390   
Breakfast                             FDR37                8209.3140   
Canned                                FDI50               10306.5840   
Dairy                                 FDF39               10256.6490   
Frozen Foods                          FDC17                9678.0688   
Fruits and Vegetables                 FDQ19               12117.5600   
Hard Drinks                           DRK23                7843.1240   
Health and Hygiene                    NCM05                9779.9362   
Household                             NCE42               13086.9648   
Meat                                  FDO03                9390.4432   
Others                                NCN55                6008.8450   
Seafood                               FDI57                6503.5344   
Snack Foods                           FDP33               10993.6896   
Soft Drinks                           DRF36                9554.2300   
Starchy Foods                         FDG47                8132.0812   

                      top_2_Item_Identifier  top_2_Item_Outlet_Sales  
Item_Type                                                             
Baking Goods                          FDL24                7759.8990  
Breads                                FDS11                7158.6816  
Breakfast                             FDQ37                7943.6598  
Canned                                FDX13                8217.3036  
Dairy                                 FDU14               10236.6750  
Frozen Foods                          FDK28                9275.9256  
Fruits and Vegetables                 FDZ20               11445.1020  
Hard Drinks                           DRF23                7152.0236  
Health and Hygiene                    NCQ53                8508.9240  
Household                             NCH18               10072.8882  
Meat                                  FDP15                9227.9880  
Others                                NCM43                5546.1140  
Seafood                               FDI09                5992.2000  
Snack Foods                           FDN58                9267.9360  
Soft Drinks                           DRE48                8868.4560  
Starchy Foods                         FDA34                7443.6440  
```

<!--chapter:end:posts/07-Groupby_Aggregate.Rmd-->

# Làm việc với 1 số kiểu dữ liệu 
## Xử  lý dữ liệu dạng text 
## Xử lý dữ liệu dạng timestamp 
## Category trong pandas
## Xử lý Missing data

<!--chapter:end:posts/08-Process_data.Rmd-->

# Một số kiến thức nâng cao
## MultiIndex  
## Pivot và Merge
## Resample
## Window

<!--chapter:end:posts/09-Advance_Function.Rmd-->

# Anomaly Detection Project

<!--chapter:end:posts/10-AD.Rmd-->

# Visualize với Matplotlib

<!--chapter:end:posts/11-Visualize.Rmd-->

