[["index.html", "Kungfu Pandas Lời nói đầu", " Kungfu Pandas Lê Huỳnh Đức 2024-01-10 Lời nói đầu "],["cấu-trúc-và-kiểu-dữ-liệu.html", "Chương 1 Cấu trúc và kiểu dữ liệu 1.1 Series 1.2 DataFrame 1.3 Data type trong pandas", " Chương 1 Cấu trúc và kiểu dữ liệu Mục tiêu của chương này nhằm giới thiệu về các cấu trúc cơ bản trong Pandas là Series và DataFrame. Trong chương này, bạn sẽ học cách khởi tạo các cấu trúc này cũng như một số thao tác cơ bản trên Series. Bạn cũng sẽ được biết về một số kiểu dữ liệu thường gặp trong pandas và cách để giảm thiểu bộ nhớ sử dụng khi khởi tạo dữ liệu. 1.1 Series Trong Pandas, Series là mảng 1 chiều bao gồm một danh sách giá trị, và một mảng chứa index của các giá trị. Trong dữ liệu dảng bảng, mỗi Series được xem như là một cột của bảng đó. Cách đơn giản để tạo Series như sau s = pd.Series(data, index=None, name=None) Trong đó data có thể có dạng: numpy.ndarray, List Python dict Scalar index có thể truyền hoặc không, tùy vào dạng của data mà index sẽ được định nghĩa khác nhau. name là tên của Series, giá trị này cũng không nhất thiết phải truyền vào. 1.1.1 Các cách khởi tạo Khởi tạo Series bằng array Khi không truyền giá trị index, Series sẽ mặc định index của nó là 1 mảng số nguyên từ 0 đến len(data) - 1 pd.Series(data=[0, 1, 2], index=[&quot;a&quot;, &quot;b&quot;, &quot;c&quot;], name=&quot;meow&quot;) a 0 b 1 c 2 Name: meow, dtype: int64 Khởi tạo Series bằng dict pd.Series({&quot;b&quot;: 1, &quot;a&quot;:0, &quot;c&quot;: 2}) b 1 a 0 c 2 dtype: int64 Lưu ý: Trong trường hợp bạn truyền biến index vào, Series sẽ đánh index dựa vào thứ tự trong index, và chỉ chứa các giá trị của dict có key nằm trong index. Với các giá trị trong biến index không có trong keys của dict, Series sẽ tạo ra các giá trị bị thiếu NaN. pd.Series({&quot;a&quot;: 0, &quot;b&quot;: 1, &quot;c&quot;: 2, &quot;e&quot;: 4}, index=[&quot;b&quot;, &quot;c&quot;, &quot;d&quot;, &quot;a&quot;]) b 1.0 c 2.0 d NaN a 0.0 dtype: float64 Lưu ý: NaN là giá trị mặc định cho dữ liệu bị thiếu trong pandas và giá trị này có kiểu là float64 nên kiểu dữ liệu của Series cũng là float64 khác với int64 ở ví dụ trước đó. Khởi tạo Series bằng một giá trị (Scalar) pd.Series(data=1, index=[&quot;a&quot;, &quot;b&quot;, &quot;c&quot;]) a 1 b 1 c 1 dtype: int64 1.1.2 Một số thao tác cơ bản Thao tác trên Series cũng giống với thao tác trên numpy.array. Ngoài ra chúng ta còn có thể tác với Series dựa vào index Ví dụ: s = pd.Series(data=[0, 1, 2, 3, 4, 5], index=[&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;, &quot;e&quot;, &quot;f&quot;]) Hiển thị toàn bộ giá trị của Series Ta gọi thuộc tính .values s.values array([0, 1, 2, 3, 4, 5]) Lấy theo indice s[2] 2 Lấy theo index s[&quot;c&quot;] 2 Slice indice s[1:3] b 1 d 2 dtype: int64 Slice index s[&quot;b&quot;:&quot;c&quot;] b 1 c 2 dtype: int64 List indice s[[1, 2, 4]] b 1 c 2 e 4 dtype: int64 List index s[[&quot;b&quot;, &quot;c&quot;, &quot;e&quot;]] b 1 c 2 e 4 dtype: int64 Điều kiện s[s &gt; s.mean()] d 3 e 4 f 5 dtype: int64 1.2 DataFrame DataFrame là cấu trúc dữ liệu chính và cũng là đặc trưng của pandas. Cũng giống như SQL Table, DataFrame là một bảng gồm một hay nhiều cột dữ liệu. Hoặc có thể nói rõ hơn là DataFrame là tập hợp các Series lại với nhau. Cách khởi tạo DataFrame như sau df = pd.DataFrame(data=None, index=None, columns=None, dtype=None, copy=False) Cũng giống như Series, data của DataFrame có nhiều cách khởi tạo khác nhau như: dict của Series, dict của numpy.array/List Mảng 2 chiều numpy.ndarray, List của List Mảng có cấu trúc Từ 1 Series Từ DataFrame khác Tùy vào cấu trúc của data mà chúng ta có thể bỏ qua biến index. Biến columns thể hiện tên của các Series. dtype sẽ định nghĩa các kiểu dữ liệu của dữ liệu, chúng ta sẽ thảo luận về nó ở phần kế tiếp của chương này. copy dùng để tạo bản sao từ dữ liệu data, nó chỉ ảnh hưởng khi data là DataFrame khác hoặc numpy.ndarray, việc copy này sẽ tránh trường hợp 2 biến cùng trỏ về cùng 1 bộ nhớ. 1.2.1 Các cách khởi tạo Khởi tạo DataFrame từ dict của Series Khi không truyền biến index vào, thì index của DataFrame sẽ là hợp giữa 2 index của Series và chúng sẽ được sắp xếp theo thứ tự từ vựng. Nếu ta không truyền columns thì các cột của DataFrame sẽ được sắp xếp theo thứ tự truyền vào các keys của dict. Khi truyền biến index vào, tương tự như Series, chỉ những index nằm trong index mới được chọn, còn những index bị thiếu sẽ được điền giá trị NaN Khi truyền giá trị columns, DataFrame sẽ chọn những Series thuộc dict có key thuộc columns, giá trị trong columns không có trong key của dict sẽ được gán NaN d = { &quot;one&quot;: pd.Series([1, 2, 3], index=[&quot;c&quot;, &quot;b&quot;, &quot;a&quot;]), &quot;two&quot;: pd.Series([1, 2, 3, 4], index=[&quot;c&quot;, &quot;a&quot;, &quot;b&quot;, &quot;d&quot;]) } pd.DataFrame(d) one two a 3.0 2 b 2.0 3 c 1.0 1 d NaN 4 pd.DataFrame(d, index=[&quot;d&quot;, &quot;b&quot;, &quot;a&quot;]) one two d NaN 4 b 2.0 3 a 3.0 2 pd.DataFrame(d, index=[&quot;d&quot;, &quot;b&quot;, &quot;a&quot;], columns=[&quot;two&quot;, &quot;three&quot;]) two three d 4 NaN b 3 NaN a 2 NaN Khởi tạo DataFrame từ dict của numpy.ndarray/List Đối với việc khởi tạo này, bắt buộc các mảng phải có cùng độ dài. Khi không truyền index vào thì index của DataFrame sẽ được tạo từ 0 đến len(n) - 1 trong đó n là độ dài của mảng. Khi truyền giá trị columns, DataFrame sẽ chọn những key thuộc dict và cũng thuộc columns, giá trị trong columns không có trong key của dict sẽ được gán NaN d = { &quot;one&quot;: [1, 2, 3, 4], &quot;two&quot;: [1, 2, 3, 4], &quot;three&quot;: [1, 2, 3, 4] } pd.DataFrame(data=d, index=[&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;], columns=[&quot;one&quot;, &quot;two&quot;, &quot;four&quot;]) one two four a 1 1 NaN b 2 2 NaN c 3 3 NaN d 4 4 NaN Khởi tạo DataFrame từ Mảng 2 chiều/ 2-d numpy.ndarray Khi không truyền index vào thì index của DataFrame sẽ được tạo từ 0 đến len(n) - 1 trong đó n là số lượng List con hoặc là số dòng hay shape[0] của numpy.ndarray. Khi không truyền columns thì tên columns sẽ được tạo từ 0 đến len(n) - 1 với n là độ dài lớn nhất của List con hoặc shape[1] của numpy.ndarray pd.DataFrame(data=[[1, 2], [3, 4, 5]], index=[&quot;a&quot;, &quot;b&quot;], columns=[&#39;one&#39;,&#39;two&#39;,&#39;three&#39;]) one two three a 1 2 NaN b 3 4 5.0 pd.DataFrame(data=np.random.rand(2,3), index=[&quot;a&quot;, &quot;b&quot;], columns=[&#39;one&#39;,&#39;two&#39;,&#39;three&#39;])) one two three a 0.662008 0.085735 0.331281 b 0.115360 0.358092 0.862477 Khởi tạo DataFrame từ danh sách các dict Ở cách khởi tạo này, bạn hãy tưởng tượng rằng mỗi dict là một dòng của DataFrame với các key là tên cột và value là giá trị tại cột đó. Việc truyền thêm hoặc không truyền index cũng giống như các trường hợp khởi tạo trên. Lưu ý: Trong trường hợp này, nếu bạn truyền columns vào thì columns bắt buộc phải chứa tất cả các key của dict Trong ví dụ dưới đây, columns phải chứa toàn bộ keys [\"one\", \"two\", \"three\"], nếu thiếu 1 trong 3 sẽ phát sinh lỗi. d = [{&quot;one&quot;: 1, &quot;two&quot;: 2}, {&quot;one&quot;: 4, &quot;two&quot;: 5, &quot;three&quot;: 6}] pd.DataFrame(d, index=[&quot;a&quot;, &quot;b&quot;], columns=[&quot;one&quot;, &quot;two&quot;, &quot;three&quot;, &quot;four&quot;]) one two three four a 1 2 NaN NaN b 4 5 6.0 NaN Khởi tạo DataFrame từ Mảng có cấu trúc Mảng có cấu trúc là mảng mà các phần tử của nó là một cấu trúc, bao gồm các thành phần nhỏ hơn, các thành phần này được đặt tên và khai báo kiểu dữ liệu. Dưới đây là một ví dụ Mảng có cấu trúc trong numpy data = np.array([(&#39;pikachu&#39;, 9, 27.0), (&#39;mewtwo&#39;, 3, 81.0)], dtype=[(&#39;name&#39;, &#39;U10&#39;), (&#39;age&#39;, &#39;i4&#39;), (&#39;weight&#39;, &#39;f4&#39;)]) pd.DataFrame(data) name age weight 0 pikachu 9 27.0 1 mewtwo 3 81.0 Khởi tạo DataFrame từ namedtuple Các trường trong nametuple sẽ được gán thành tên các columns trong DataFrame. Những giá trị của namedtuple sẽ được xem là 1 dòng trong DataFrame. Số lượng cột của DataFrame sẽ phụ thuộc vào số lượng giá trị của phần từ namedtuple đầu tiên. Nếu các phần tử phía sau có số lượng giá trị ít hơn thì sẽ được điền NaN và ngược lại sẽ trả ra lỗi nếu số lượng giá trị của namedtuple lớn hơn số lượng giá trị của phần tử namedtuple đầu tiên. Ví dụ về cách tạo namedtuple from collections import namedtuple Point2D = namedtuple(&quot;Point2D&quot;, &quot;x y&quot;) Point3D = namedtuple(&quot;Point3D&quot;, &quot;x y z&quot;) Tạo DataFrame từ namedtuple Point2D pd.DataFrame([Point2D(0, 0), Point2D(0, 1), Point2D(0, 2)]) x y 0 0 0 1 0 1 2 0 2 Tạo DataFrame từ namedtuple cả Point2D và Point3D pd.DataFrame([Point3D(0, 0, 0), Point2D(0, 1), Point3D(0, 2, 3)]) x y z 0 0 0 0.0 1 0 1 NaN 2 0 2 3.0 Như ta thấy, tại phần tử thứ 2 chỉ có 2 giá trị, trong khi phần tử thứ nhất có 3 giá trị, vậy nên phần tử bị thiếu tại cột z sẽ được gán NaN Khởi tạo DataFrame từ Series s = pd.Series(data=[0, 1, 2], index=[&quot;a&quot;, &quot;b&quot;, &quot;c&quot;], name=&quot;meow&quot;) pd.DataFrame(s) meow a 0 b 1 c 2 name của Series sẽ là tên cột của DataFrame và index của Series sẽ là index của DataFrame nếu ta không truyền các biến index, columns khi khởi tạo pd.DataFrame 1.2.2 Các hàm khởi tạo thay thế DataFrame.from_dict Cách khởi tạo pd.DataFrame.from_dict(data, orient=&#39;columns&#39;, dtype=None, columns=None) data truyền vào là 1 dict, orient có 2 giá trị có thể đưa vào là {\"columns\", \"index\"}, columns là danh sách tên các cột của DataFrame. Lưu ý: Chỉ được truyền columns khi orient=\"index\". Khi orient=\"columns\" sẽ báo lỗi. Ví dụ tạo DataFrame khi orient=\"columns\". Với cách khởi tạo này tên các cột của DataFrame sẽ là key của dict data = {&quot;col_1&quot;: [3, 2, 1, 0], &quot;col_2&quot;: [&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;]} pd.DataFrame.from_dict(data) col_1 col_2 0 3 a 1 2 b 2 1 c 3 0 d Ví dụ tạo DataFrame khi orient=\"index\". Với cách khởi tạo này index của DataFrame sẽ là key của dict. data = {&quot;col_1&quot;: [3, 2, 1, 0], &quot;col_2&quot;: [&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;]} pd.DataFrame.from_dict(data, orient=&quot;index&quot;, columns=[&quot;one&quot;, &quot;two&quot;, &quot;three&quot;, &quot;four&quot;]) col_1 col_2 0 3 a 1 2 b 2 1 c 3 0 d DataFrame.from_records Cách khởi tạo pd.DataFrame.from_records(data) data truyền vào có thể là một mảng có cấu trúc data = np.array([(&#39;Rex&#39;, 9, 81.0), (&#39;Fido&#39;, 3, 27.0)], dtype=[(&#39;name&#39;, &#39;U10&#39;), (&#39;age&#39;, &#39;i4&#39;), (&#39;weight&#39;, &#39;f4&#39;)]) pd.DataFrame.from_records(data, index=[&quot;a&quot;, &quot;b&quot;]) name age weight a Rex 9 81.0 b Fido 3 27.0 Dữ liệu có thể một danh sách các namedtuple from collections import namedtuple Point2D = namedtuple(&quot;Point2D&quot;, &quot;x y&quot;) Point3D = namedtuple(&quot;Point3D&quot;, &quot;x y z&quot;) pd.DataFrame.from_records([Point3D(0, 0, 0), Point2D(0, 1), Point3D(0, 2, 3)], columns=[&quot;x&quot;,&quot;y&quot;,&quot;z&quot;], index=[&quot;a&quot;, &quot;b&quot;, &quot;c&quot;]) x y z a 0 0 0.0 b 0 1 NaN c 0 2 3.0 Hoặc 1 danh sách các dict d = [{&quot;one&quot;: 1, &quot;two&quot;: 2}, {&quot;one&quot;: 4, &quot;two&quot;: 5, &quot;three&quot;: 6}] pd.DataFrame.from_records(d, index=[&quot;a&quot;, &quot;b&quot;], columns=[&quot;one&quot;, &quot;two&quot;, &quot;three&quot;, &quot;four&quot;]) one two three four a 1 2 NaN NaN b 4 5 6.0 NaN 1.3 Data type trong pandas Để kiểm tra kiểu dữ liệu của Series hay DataFrame bạn có thể gọi thuộc tính dtypes hoặc phương thức .info(). Các kiểu dữ liệu thường gặp của Pandas được mô tả theo bảng dưới đây: Các kiểu dữ liệu phổ biến Numpy/Pandas object Hiển thị Boolean np.bool bool Integer np.int, np.uint int uint Float np.float float Object np.object O, object Datetime np.datetime64, pd.Timestamp datetime64 Timedelta np.timedelta64, pd.Timedelta timedelta64 Category pd.Categorical category Complex np.complex complex Ví dụ: df = pd.DataFrame({ &#39;col_1&#39;: [1, 0, 1, 0], &#39;col_2&#39;: [1.0, 2.0, 3.0, 4.0], &#39;col_3&#39;: [&#39;1&#39;, &#39;2&#39;, &#39;3&#39;, &#39;4&#39;], &#39;col_4&#39;: [&#39;1&#39;, 2, &#39;3&#39;, 4], &#39;col_5&#39;: [True, False, True, False], &#39;col_6&#39;: [&#39;2021-06-01&#39;, &#39;2021-06-02&#39;, &#39;2021-06-03&#39;, &#39;2021-06-04&#39;]}) df col_1 col_2 col_3 col_4 col_5 col_6 0 1 1.0 1 1 True 2021-06-01 1 0 2.0 2 2 False 2021-06-02 2 1 3.0 3 3 True 2021-06-03 3 0 4.0 4 4 False 2021-06-04 df.dtypes col_1 int64 col_2 float64 col_3 object col_4 object col_5 bool col_6 object dtype: object Lưu ý: Nếu không khai báo kiểu dữ liệu khi khởi tạo, pandas sẽ mặc định kiểu dữ liệu là int64, float64, object và bool. Pandas sẽ không biết kiểu dữ liệu timestamp nếu không khai báo. Chỉ có thể khai báo duy nhất 1 kiểu dữ liệu khi khởi tạo pandas. Ví dụ như tất cả dữ liệu của bạn là int hoặc có thể được ép kiểu về intthì có thể khai báo dtype=np.int Ở ví dụ phía dưới col_1, col_2, col_3, col_4, col_5 có thể ép về kiểu int, còn col_6 thì không thể ép kiểu được. df = pd.DataFrame({ &#39;col_1&#39;: [1, 0, 1, 0], &#39;col_2&#39;: [1.0, 2.0, 3.0, 4.0], &#39;col_3&#39;: [&#39;1&#39;, &#39;2&#39;, &#39;3&#39;, &#39;4&#39;], &#39;col_4&#39;: [&#39;1&#39;, 2, &#39;3&#39;, 4], &#39;col_5&#39;: [True, False, True, False], &#39;col_6&#39;: [&#39;2021-06-01&#39;, &#39;2021-06-02&#39;, &#39;2021-06-03&#39;, &#39;2021-06-04&#39;]}, dtype=np.int) df col_1 col_2 col_3 col_4 col_5 col_6 0 1 1 1 1 1 2021-06-01 1 0 2 2 2 0 2021-06-02 2 1 3 3 3 1 2021-06-03 3 0 4 4 4 0 2021-06-04 df.dtypes col_1 int64 col_2 int64 col_3 object col_4 int64 col_5 int64 col_6 int64 dtype: object Mẹo: Nếu dữ liệu có khoảng nhỏ thì thay vì khai báo kiểu np.int, ta có thể khai báo kiểu integer với số byte phù hợp để giảm bộ nhớ lưu trữ. Để xem bộ nhớ sử dụng của DataFrame, ta có thể dùng .memory_usage(). Một số kiểu integer trong numpy như np.int8, np.int16, np.int32, np.int64, np.uint8, np.uint16, np.uint32, np.uint64 Theo ví dụ trên, khi dtype=np.int df.memory_usage() Index 128 col_1 32 col_2 32 col_3 32 col_4 32 col_5 32 col_6 32 dtype: int64 và sau khi thay bằng dtype=np.int8 df.memory_usage() Index 128 col_1 4 col_2 4 col_3 4 col_4 4 col_5 4 col_6 32 dtype: int64 Phương thức ép kiểu này được áp dụng khi bạn khởi tạo DataFrame, ngoài ra còn có hàm ép kiểu khác đối với DataFrame cho trước, nội dung này sẽ được đề cập ở Chương 3. "],["nhập-xuất-trong-pandas.html", "Chương 2 Nhập xuất trong pandas 2.1 Đọc và lưu file 2.2 Cấu hình pandas", " Chương 2 Nhập xuất trong pandas Ở Chương 1 chúng ta đã biết cách khởi tạo DataFrame từ các dữ liệu cho trước. Trong chương này sẽ hướng dẫn cách đọc dữ liệu từ file bằng pandas, một số kiểu file thường thấy cho dữ liệu dạng bảng là .csv và .xlsx. Bạn cũng có thể đọc dữ liệu bán cấu trúc như JSON bằng cách load file bằng Python sau đó dùng các cách khởi tạo như ở Chương 1 hoặc có thể dùng hàm phụ trợ của Pandas. Ở phần thứ hai của chương, bạn sẽ được hướng dẫn một số cách cấu hình cho Pandas như thay đổi số dòng, số cột hiển thị… 2.1 Đọc và lưu file 2.1.1 csv, tsv 2.1.1.1 Đọc file Chúng ta có thể đọc file csv với pandas theo lệnh sau df = pd.read_csv(filepath, sep=&#39;,&#39;, names=NoDefault.no_default, index_col=None, usecols=None, dtype=None, skiprows=None, skipfooter=0, nrows=None) Trong đó: filepath là đường dẫn đến file trong máy hoặc đường link URL sep dùng để nhận diện cách chia thành cột, nếu không truyền tham số này thì pandas tự hiểu là chia theo ',', ngoài ra có thể chia theo ';' đối với macOS và '\\t' với file có định dạng .tsv names là tên các cột của bảng. Nếu bảng đã có tên cột thì nên bỏ qua tham số này, pandas sẽ lấy dòng đầu tiên của file làm tên cột. index_col dùng để chỉ định vị trí các cột dùng để làm index cho bảng. usecols dùng để chỉ định vị trí hoặc tên các cột cần đọc. dtype dùng để định dạng kiểu dữ liệu của các cột. skiprows được dùng khi muốn bỏ qua một số dòng đầu của bảng. skipfooter tương tự như skiprows nhưng sẽ bỏ qua các dòng cuối cùng của bảng. nrows dùng để chỉ định số lượng dòng của bạn mà bạn sẽ đọc bằng pandas Ví dụ Đọc file dữ liệu sale được cho tại đây. Giả sử ta chỉ lấy các cột date, weekly_sales và is_holiday và lấy cột date làm index và chỉ lấy 6 dòng đầu df = pd.read_csv(&#39;https://raw.githubusercontent.com/lhduc94/kungfupandas/master/data/sales_subset.csv&#39;, index_col=[&#39;date&#39;], usecols=[&#39;date&#39;,&#39;weekly_sales&#39;,&#39;is_holiday&#39;], nrows=6) df weekly_sales is_holiday date 2010-02-05 24924.50 False 2010-03-05 21827.90 False 2010-04-02 57258.43 False 2010-05-07 17413.94 False 2010-06-04 17558.09 False 2010-07-02 16333.14 False 2.1.1.2 Xuất file Để lưu DataFrame dưới dạng file ta có thể dùng câu lệnh .to_csv() theo cú pháp sau df.to_csv(filename, sep=&#39;,&#39;, columns=None, header=True, index=True) Trong đó: filename là địa chỉ file mà bạn muốn lưu lại sep tương tự như lúc đọc file columns là tên các cột bạn muốn lưu xuống, nếu muốn lưu tất cả các cột thì bạn có thể bỏ qua tham số này. header mặc định là True nếu bạn muốn lưu tên cột index mặc định là True nếu bạn muốn lưu index của bảng. Ví dụ df.to_csv(&#39;sales.csv&#39;, columns=&#39;weekly_sales&#39;, index=False) 2.1.2 Excel 2.1.2.1 Đọc file Excel Để đọc file Excel ta dùng cú pháp sau x = pd.ExcelFile(filename) Với filename là đường dẫn đến file Để xem tên các sheets của x ta có thể dùng x.sheet_names. Sau đó để đọc từng sheet của x ta có thể dùng .parse() df = x.parse(sheet_name, header=0, names=None, index_col=None, usecols=None, skiprows=None, skipfooter=0, nrows=None) Trong đó sheet_name là tên sheet cần đọc, các thông số còn lại tương tự như phần đọc file csv và tsv. Một cách khác để đọc file excel là dùng hàm pandas.read_excel với tham số io là tên file. 2.1.2.2 Xuất file Excel Giả sử ta có các DataFrame df1, df2, df3 cần được lưu vào 1 file Excel duy nhất import pandas as pd df1 = pd.DataFrame({&#39;col_1&#39;: [1, 2, 3, 4]}) df2 = pd.DataFrame({&#39;col_1&#39;: [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;]}) df3 = pd.DataFrame({&#39;col_1&#39;: [True, True, False, False]}) Để ghi các bảng vào file Excel, bước đầu tiên là khởi tạo biến writer theo cú pháp writer = pd.ExcelWriter(&#39;pandas_multiple.xlsx&#39;, mode=&#39;w&#39;, if_sheet_exists=None, engine=None) Trong đó: filename là tên file excel mode là phương thức ghi file với w là viết file mới và a là viết thêm vào file. Mặc định là w if_sheet_exists là phương thức ghi file nếu file hoặc sheet đã tồn tại, bao gồm các phương thức dưới đây (mặc định là error) error: hiện ValueError nếu đã tồn tại sheet new: Tạo sheet mới với tên phụ thuộc vào engine replace: Xóa nội dung của sheet trước khi viết. overlay: Viết lên sheet đã tồn tại mà không xóa các sheet cũ engine: Một số kiểu hỗ trợ ghi file như xlsxwriter, openpyxl, openpyxl, odswriter Lưu ý: mode='w' không được sử dụng với engine xlsxwriter, khi khai báo engine này sẽ báo lỗi. if_sheet_exists chỉ sử dụng với mode='a' overlay chỉ hỗ trợ với phiên bản 1.4.0 trở lên. Để ghi từng sheet bạn dùng lệnh .to_excel(). Sau khi ghi tất cả các sheet bạn kết thúc với writer.save() để lưu file writer = pd.ExcelWriter(&#39;mul_sheets.xlsx&#39;, mode=&#39;w&#39;, engine=&#39;openpyxl&#39;) df1.to_excel(writer, sheet_name=&#39;Sheet1&#39;) df2.to_excel(writer, sheet_name=&#39;Sheet2&#39;) df3.to_excel(writer, sheet_name=&#39;Sheet3&#39;) writer.save() Mẹo: Có thể dùng with để mở file để tránh trường hợp quên gọi lệnh .save(), lệnh with sẽ tự động lưu file sau khi kết thúc các lệnh con trong nó import pandas as pd df1 = pd.DataFrame({&#39;col_1&#39;: [2, 3, 4, 5]}) df2 = pd.DataFrame({&#39;col_1&#39;: [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;]}) df3 = pd.DataFrame({&#39;col_1&#39;: [True, True, False, False]}) sheet_names = [&#39;Sheet1&#39;,&#39;Sheet2&#39;, &#39;Sheet3&#39;] with pd.ExcelWriter(&#39;mul_sheets.xlsx&#39;, mode=&#39;a&#39;, if_sheet_exists=&#39;new&#39;, engine=&#39;openpyxl&#39;) as writer: for df, sheet_name in zip([df1, df2, df3], sheet_names): df.to_excel(writer, sheet_name) 2.1.3 JSON 2.1.3.1 Đọc file JSON là 1 dạng dữ liệu khá phổ biến trong thực tế. Pandas hỗ trợ đọc file JSON theo phương thức sau pd.read_json(path_or_buf=None, orient=None,...) Trong đó: path_or_buf: là đường dẫn đến file json hoặc Object cho trước orient: Kiểu cấu trúc của json split: Dữ liệu có dạng dictionary theo cấu trúc {index -&gt; [index], columns - [columns], data -&gt; [values]} records: Dữ liệu có dạng danh sách các dictionary theo cấu trúc [{column -&gt; value}, ... , {column -&gt; value}] index: Dữ liệu dạng dictionary theo cấu trúc {\"index\" -&gt; {\"column\" -&gt; \"value\"}} columns: Dữ liệu dạng dictionary theo cấu trúc {column -&gt; {index -&gt; value}} values: danh sách các giá trị Ngoài ra còn các tham số khác nữa như chunksize, nrow, các bạn có thể tham khảo tại pd.read_json() Dưới đây là file sample_pokemon.json với các cấu trúc như sau Cấu trúc records [{&quot;name&quot;:&quot;Bulbasaur&quot;,&quot;type&quot;:[&quot;Grass&quot;,&quot;Poison&quot;],&quot;height&quot;:&quot;0.71 m&quot;,&quot;weight&quot;:&quot;6.9 kg&quot;}, {&quot;name&quot;:&quot;Ivysaur&quot;,&quot;type&quot;:[&quot;Grass&quot;,&quot;Poison&quot;],&quot;height&quot;:&quot;0.99 m&quot;,&quot;weight&quot;:&quot;13.0 kg&quot;}, {&quot;name&quot;:&quot;Venusaur&quot;,&quot;type&quot;:[&quot;Grass&quot;,&quot;Poison&quot;],&quot;height&quot;:&quot;2.01 m&quot;,&quot;weight&quot;:&quot;100.0 kg&quot;}, {&quot;name&quot;:&quot;Charmander&quot;,&quot;type&quot;:[&quot;Fire&quot;],&quot;height&quot;:&quot;0.61 m&quot;,&quot;weight&quot;:&quot;8.5 kg&quot;}, {&quot;name&quot;:&quot;Charmeleon&quot;,&quot;type&quot;:[&quot;Fire&quot;],&quot;height&quot;:&quot;1.09 m&quot;,&quot;weight&quot;:&quot;19.0 kg&quot;}] ta có thể gọi df = pd.read_json(&#39;sample_pokemon.json&#39;, orient=&#39;records&#39;) df.head() name type height weight 0 Bulbasaur [Grass, Poison] 0.71 m 6.9 kg 1 Ivysaur [Grass, Poison] 0.99 m 13.0 kg 2 Venusaur [Grass, Poison] 2.01 m 100.0 kg 3 Charmander [Fire] 0.61 m 8.5 kg 4 Charmeleon [Fire] 1.09 m 19.0 kg Tương tự với cấu trúc split {&quot;index&quot;: [0,1,2,3,4], &quot;columns&quot;: [&quot;name&quot;,&quot;type&quot;,&quot;height&quot;,&quot;weight&quot;], &quot;data&quot;: [[&quot;Bulbasaur&quot;,[&quot;Grass&quot;,&quot;Poison&quot;],&quot;0.71 m&quot;,&quot;6.9 kg&quot;], [&quot;Ivysaur&quot;,[&quot;Grass&quot;,&quot;Poison&quot;],&quot;0.99 m&quot;,&quot;13.0 kg&quot;], [&quot;Venusaur&quot;,[&quot;Grass&quot;,&quot;Poison&quot;],&quot;2.01 m&quot;,&quot;100.0 kg&quot;], [&quot;Charmander&quot;,[&quot;Fire&quot;],&quot;0.61 m&quot;,&quot;8.5 kg&quot;], [&quot;Charmeleon&quot;,[&quot;Fire&quot;],&quot;1.09 m&quot;,&quot;19.0 kg&quot;]]} ta có thể gọi df = pd.read_json(&#39;sample_pokemon.json&#39;, orient=&#39;split&#39;) df.head() Các cấu trúc còn lại index {&quot;0&quot;:{&quot;name&quot;:&quot;Bulbasaur&quot;,&quot;type&quot;:[&quot;Grass&quot;,&quot;Poison&quot;],&quot;height&quot;:&quot;0.71 m&quot;,&quot;weight&quot;:&quot;6.9 kg&quot;}, &quot;1&quot;:{&quot;name&quot;:&quot;Ivysaur&quot;,&quot;type&quot;:[&quot;Grass&quot;,&quot;Poison&quot;],&quot;height&quot;:&quot;0.99 m&quot;,&quot;weight&quot;:&quot;13.0 kg&quot;}, &quot;2&quot;:{&quot;name&quot;:&quot;Venusaur&quot;,&quot;type&quot;:[&quot;Grass&quot;,&quot;Poison&quot;],&quot;height&quot;:&quot;2.01 m&quot;,&quot;weight&quot;:&quot;100.0 kg&quot;}, &quot;3&quot;:{&quot;name&quot;:&quot;Charmander&quot;,&quot;type&quot;:[&quot;Fire&quot;],&quot;height&quot;:&quot;0.61 m&quot;,&quot;weight&quot;:&quot;8.5 kg&quot;}, &quot;4&quot;:{&quot;name&quot;:&quot;Charmeleon&quot;,&quot;type&quot;:[&quot;Fire&quot;],&quot;height&quot;:&quot;1.09 m&quot;,&quot;weight&quot;:&quot;19.0 kg&quot;}} columns {&quot;name&quot;:{&quot;0&quot;:&quot;Bulbasaur&quot;, &quot;1&quot;:&quot;Ivysaur&quot;, &quot;2&quot;:&quot;Venusaur&quot;, &quot;3&quot;:&quot;Charmander&quot; &quot;4&quot;:&quot;Charmeleon&quot;}, &quot;type&quot;:{&quot;0&quot;:[&quot;Grass&quot;,&quot;Poison&quot;], &quot;1&quot;:[&quot;Grass&quot;,&quot;Poison&quot;], &quot;2&quot;:[&quot;Grass&quot;,&quot;Poison&quot;], &quot;3&quot;:[&quot;Fire&quot;], &quot;4&quot;:[&quot;Fire&quot;]}, &quot;height&quot;:{&quot;0&quot;:&quot;0.71 m&quot;, &quot;1&quot;:&quot;0.99 m&quot;, &quot;2&quot;:&quot;2.01 m&quot;, &quot;3&quot;:&quot;0.61 m&quot;, &quot;4&quot;:&quot;1.09 m&quot;}, &quot;weight&quot;:{&quot;0&quot;:&quot;6.9 kg&quot;, &quot;1&quot;:&quot;13.0 kg&quot;, &quot;2&quot;:&quot;100.0 kg&quot;, &quot;3&quot;:&quot;8.5 kg&quot;, &quot;4&quot;:&quot;19.0 kg&quot;}} values [[&quot;Bulbasaur&quot;,[&quot;Grass&quot;,&quot;Poison&quot;],&quot;0.71 m&quot;,&quot;6.9 kg&quot;], [&quot;Ivysaur&quot;,[&quot;Grass&quot;,&quot;Poison&quot;],&quot;0.99 m&quot;,&quot;13.0 kg&quot;], [&quot;Venusaur&quot;,[&quot;Grass&quot;,&quot;Poison&quot;],&quot;2.01 m&quot;,&quot;100.0 kg&quot;], [&quot;Charmander&quot;,[&quot;Fire&quot;],&quot;0.61 m&quot;,&quot;8.5 kg&quot;], [&quot;Charmeleon&quot;,[&quot;Fire&quot;],&quot;1.09 m&quot;,&quot;19.0 kg&quot;]] Lưu ý: pd.read_json() mặc định orient='records'. Các cấu trúc records và index là các cấu trúc JSON thường gặp. values không phải cấu trúc JSON. có thể truyền link file thay vì file được lưu ở máy. 2.1.4 Pickle 2.1.4.1 Đọc file 2.1.4.2 Xuất file 2.2 Cấu hình pandas "],["Chuong-3.html", "Chương 3 Một số hàm cơ bản 3.1 .head() và .tail() 3.2 .shape và .size 3.3 .info() 3.4 .describe() 3.5 .index 3.6 .memory_usage() 3.7 Lấy Series trong pandas 3.8 .astype() 3.9 .drop_duplicates() 3.10 .value_counts() 3.11 .unique() và .nunique() 3.12 .drop() 3.13 .rename() 3.14 .set_index() 3.15 .sort_index 3.16 .sort_values", " Chương 3 Một số hàm cơ bản df = pd.read_csv(&#39;https://raw.githubusercontent.com/lhduc94/kungfupandas/master/data/sales_subset.csv&#39;,index_col=[&#39;Unnamed: 0&#39;]) 3.1 .head() và .tail() Phương thức .head(n=5) hiển thị n dòng đầu tiên của DataFrame, ngược lại phương thức .tail(n=5) hiển thị n dòng cuối cùng của DataFrame df.head() store type department date weekly_sales is_holiday \\ 0 1 A 1 2010-02-05 24924.50 False 1 1 A 1 2010-03-05 21827.90 False 2 1 A 1 2010-04-02 57258.43 False 3 1 A 1 2010-05-07 17413.94 False 4 1 A 1 2010-06-04 17558.09 False temperature_c fuel_price_usd_per_l unemployment 0 5.727778 0.679451 8.106 1 8.055556 0.693452 8.106 2 16.816667 0.718284 7.808 3 22.527778 0.748928 7.808 4 27.050000 0.714586 7.808 df.tail() store type department date weekly_sales is_holiday \\ 10769 39 A 99 2011-12-09 895.00 False 10770 39 A 99 2012-02-03 350.00 False 10771 39 A 99 2012-06-08 450.00 False 10772 39 A 99 2012-07-13 0.06 False 10773 39 A 99 2012-10-05 915.00 False temperature_c fuel_price_usd_per_l unemployment 10769 9.644444 0.834256 7.716 10770 15.938889 0.887619 7.244 10771 27.288889 0.911922 6.989 10772 25.644444 0.860145 6.623 10773 22.250000 0.955511 6.228 3.2 .shape và .size Phương thức .shape cho biết số lượng dòng và cột của bảng df.shape (10774, 9) Trong dó 10774 là số lượng dòng của bảng và 9 là số lượng cột của bảng Phương thức .size cho biết số lượng phần từ của bảng df.size 96966 3.3 .info() Phương thức .info() dùng để xem một số thông tin cơ bản như Index của bảng Tên các cột, số lượng các phần tử Null trong cột và kiểu dữ liệu của chúng Số lượng các kiểu dữ liệu Dung lượng của bảng Ví dụ df.info() &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; Int64Index: 10774 entries, 0 to 10773 Data columns (total 9 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 store 10774 non-null int64 1 type 10774 non-null object 2 department 10774 non-null int64 3 date 10774 non-null object 4 weekly_sales 10774 non-null float64 5 is_holiday 10774 non-null bool 6 temperature_c 10774 non-null float64 7 fuel_price_usd_per_l 10774 non-null float64 8 unemployment 10774 non-null float64 dtypes: bool(1), float64(4), int64(2), object(2) memory usage: 768.1+ KB Mẹo: Phương thức .info() có các tham số để tùy chỉnh các thông tin có thể xem. Bạn có thể giới hạn các thông tin theo các tham số dưới đây info(verbose=None, buf=None, max_cols=None, memory_usage=None, show_counts=None, null_counts=None) 3.4 .describe() Phương thức .describe() đưa ra một số thống kê đơn giản như count, mean, std, min, max và percentiles = [0.25, 0.5, 0.75]. Phương thức này chỉ áp dụng cho các cột ở dạng numerical. df.describe() store department weekly_sales temperature_c \\ count 10774.000000 10774.000000 10774.000000 10774.000000 mean 15.441897 45.218118 23843.950149 15.731978 std 11.534511 29.867779 30220.387557 9.922446 min 1.000000 1.000000 -1098.000000 -8.366667 25% 4.000000 20.000000 3867.115000 7.583333 50% 13.000000 40.000000 12049.065000 16.966667 75% 20.000000 72.000000 32349.850000 24.166667 max 39.000000 99.000000 293966.050000 33.827778 fuel_price_usd_per_l unemployment count 10774.000000 10774.000000 mean 0.749746 8.082009 std 0.059494 0.624355 min 0.664129 3.879000 25% 0.708246 7.795000 50% 0.743381 8.099000 75% 0.781421 8.360000 max 1.107674 9.765000 Mẹo: Bạn có thể thay đổi thông số percentiles bằng cách truyền tham số này vào trong .describe() Ví dụ df.describe(percentiles=[0.1, 0.99]) store department weekly_sales temperature_c \\ count 10774.000000 10774.000000 10774.000000 10774.000000 mean 15.441897 45.218118 23843.950149 15.731978 std 11.534511 29.867779 30220.387557 9.922446 min 1.000000 1.000000 -1098.000000 -8.366667 10% 2.000000 8.000000 607.695000 2.577778 50% 13.000000 40.000000 12049.065000 16.966667 99% 39.000000 99.000000 142193.400300 32.388889 max 39.000000 99.000000 293966.050000 33.827778 fuel_price_usd_per_l unemployment count 10774.000000 10774.000000 mean 0.749746 8.082009 std 0.059494 0.624355 min 0.664129 3.879000 10% 0.687640 7.127000 50% 0.743381 8.099000 99% 0.978565 9.765000 max 1.107674 9.765000 Lưu ý: pandas mặc định tính thêm percentile tại 0.5 dù không truyền vào 3.5 .index Thuộc tính .index để lấy index của DataFrame hoặc Series. Ví dụ df.index Int64Index([ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, ... 10764, 10765, 10766, 10767, 10768, 10769, 10770, 10771, 10772, 10773], dtype=&#39;int64&#39;, length=10774) 3.6 .memory_usage() Phương thức .memory_usage(index=True, deep=False) giúp thông kê dung lượng của từng cột. Trong đó index trả về dung lượng của phần đánh index và deep nếu đặt giá trị True sẽ trả về cách tính toán sâu hơn về bộ nhớ cho kiểu object Ví dụ df.memory_usage(index=False) store 86192 type 86192 department 86192 date 86192 weekly_sales 86192 is_holiday 10774 temperature_c 86192 fuel_price_usd_per_l 86192 unemployment 86192 dtype: int64 df.memory_usage(deep=True) Index 86192 store 86192 type 624892 department 86192 date 721858 weekly_sales 86192 is_holiday 10774 temperature_c 86192 fuel_price_usd_per_l 86192 unemployment 86192 dtype: int64 3.7 Lấy Series trong pandas Sử dụng [&lt;tên cột&gt;] để lấy 1 Series của bảng. Ví dụ để lấy Series của cột department ta làm như sau df[&#39;department&#39;] 0 1 1 1 2 1 3 1 4 1 .. 10769 99 10770 99 10771 99 10772 99 10773 99 Name: department, Length: 10774, dtype: int64 những Series này cũng có thế áp dụng các phương thức tương tự của DataFrame như .head(), .tail()…. 3.8 .astype() Với phương thức .astype() ta có thể ép kiểu dữ liệu của cột về dạng khác. Việc ép kiểu này giúp thay đổi kiểu dữ liệu để tiện các thao tác như nối 2 cột có 2 kiểu str và int, ngoài ra việc ép kiểu cũng giúp giảm được dung lượng bộ nhớ dành cho bảng. Ở ví dụ trên, ta thấy cột department có giá trị max là 99 nhưng được mặc định là int64 khá lãng phí, do đó ép kiểu về int8 Trước khi ép kiểu df[&#39;department&#39;].dtypes dtype(&#39;int64&#39;) df[&#39;department&#39;].memory_usage() - df[&#39;department&#39;].index.memory_usage() 86192 Sau khi ép kiểu df[&#39;department&#39;].astype(&#39;int8&#39;).memory_usage() - df[&#39;department&#39;].index.memory_usage() 10774 Ta thấy sau khi ép kiểu thì bộ nhớ lưu trữ của cột department giảm đi 8 lần. Lưu ý: df['department'].memory_usage() trả về dung lượng lưu trữ của cột department và dung lượng lưu trữ của index 3.9 .drop_duplicates() Phương thức này trả về DataFrame đã được loại bỏ các hàng trùng nhau. Lệnh thực hiện DataFrame.drop_duplicates(subset=None, keep=&#39;first&#39;, inplace=False, ignore_index=False) Trong đó: subset: tên cột hoặc danh sách các cột cần lọc giá trị trùng lặp, nếu không truyền vào sẽ mặc định chọn tất cả các cột keep: các kiểu lọc duplicate bao gồm các lựa chọn sau: 'first': loại bỏ các dòng bản sao, chỉ giữ lại dòng đầu tiên 'last': loại bỏ các dòng bản sao, chỉ giữ lại dòng cuối cùng False: loại tất cả các dòng trùng lặp inplace: thao tác trực tiếp trên bảng nếu để giá trị True hoặc tạo 1 bản sao với giá trị False ignore_index: Nếu True trả về index đánh số lại từ 0 đến n-1 Ví dụ df = pd.DataFrame({ &#39;action&#39;: [&#39;view&#39;, &#39;view&#39;, &#39;add to cart&#39;, &#39;add to cart&#39;, &#39;add to cart&#39;,], &#39;fruit&#39;: [&#39;orange&#39;, &#39;orange&#39;, &#39;orange&#39;, &#39;apple&#39;, &#39;apple&#39;], &#39;times&#39;: [ 1, 1, 3, 2, 4] }) df action fruit times 0 view orange 1 1 view orange 1 2 add to cart orange 3 3 add to cart apple 2 4 add to cart apple 4 df.drop_duplicates() action fruit times 0 view orange 1 2 add to cart orange 3 3 add to cart apple 2 4 add to cart apple 4 df.drop_duplicates(subset=[&#39;action&#39;]) action fruit times 0 view orange 1 2 add to cart orange 3 df.drop_duplicates(subset=[&#39;action&#39;,&#39;fruit&#39;], keep=&#39;last&#39;, ignore_index=True) action fruit times 0 view orange 1 1 add to cart orange 3 2 add to cart apple 4 3.10 .value_counts() Phương thức này trả số lần xuất hiện của các phần tử trong Series. Kết quả trả về mặc định sẽ sắp xếp theo số lần xuất hiện giảm dần và mặc định bỏ qua các giá trị null Series.value_counts(normalize=False, sort=True, ascending=False, bins=None, dropna=True) Trong đó: normalize: True sẽ trả về tỉ lệ xuất hiện của các phần tử sort: True sẽ trả về kết quả sắp xếp theo số lần xuất hiện, False sẽ trả về kết quả sắp xếp theo trình tự xuất hiện của phần tử ascending: True sẽ trả về kết quả sắp xếp theo số lần xuất hiện tăng dần. bins: gom nhóm các phần tử, tương tự pd.cut dropna: False sẽ đếm tất cả các phần tử kể cả null Ví dụ s = pd.Series([3, 1, 2, 3, np.nan, 4, np.nan]) s.value_counts() 3.0 2 1.0 1 2.0 1 4.0 1 dtype: int64 s.value_counts(normalize=True, sort=False, dropna=False) 3.0 0.285714 1.0 0.142857 2.0 0.142857 NaN 0.285714 4.0 0.142857 dtype: float64 s.value_counts(bins=3) (0.996, 2.0] 2 (2.0, 3.0] 2 (3.0, 4.0] 1 dtype: int64 3.11 .unique() và .nunique() Phương thức .unique() trả về các giá trị khác nhau của Series và .nunique() trả về số lượng các giá trị khác nhau của Series. Kết quả trả về của .unique() là danh sách các phần tử được sắp xếp theo thứ tự đầu vào của bảng. Để loại bỏ giá trị NA trong lúc đếm có thể gọi .nunique(dropna=False) Cách sử dụng s = pd.Series([2, 3, 1 ,2, np.nan], name=&#39;col_0&#39;) s 0 2.0 1 3.0 2 1.0 3 2.0 4 NaN Name: col_0, dtype: float64 s.unique() array([ 2., 3., 1., nan]) s.nunique(dropna=False) 4 3.12 .drop() Phương thức .drop() dùng để loại bỏ các dòng hoặc cột theo chỉ định. Cú pháp của .drop() như sau DataFrame.drop(labels=None, axis=0, index=None, columns=None, level=None, inplace=False, errors=&#39;raise&#39;) Trong đó: labels: Tên cột hoặc dòng cần loại bỏ. axis: Mặc đinh giá trị 0 loại bỏ theo dòng và 1 loại bỏ theo cột. index: Chỉ định index của dòng cần loại bỏ, tương đương labels, axis=0 columns: Chỉ định cột cần loại bỏ, tương đương labels, axis=1 level: Dành cho MultiIndex, khi đó chỉ định cấp độ index cần loại bỏ inplace: Thực hiện trên chính bảng hay tạo ra một bảng sao errors: mặc định raise sẽ trả ra lỗi và ignore nếu muốn bỏ qua lỗi. Ví dụ df = pd.DataFrame(np.arange(16).reshape(4, 4), columns=[&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;], index=[&#39;A&#39;, &#39;1A&#39;, &#39;2A&#39;, &#39;3A&#39;]) df A B C D A 0 1 2 3 1A 4 5 6 7 2A 8 9 10 11 3A 12 13 14 15 df.drop(&#39;A&#39;) A B C D 1A 4 5 6 7 2A 8 9 10 11 3A 12 13 14 15 df.drop(columns=[&#39;A&#39;, &#39;C&#39;]) B D A 1 3 1A 5 7 2A 9 11 3A 13 15 df.drop(index=[&#39;A&#39;, &#39;2A&#39;]) A B C D 1A 4 5 6 7 3A 12 13 14 15 Lưu ý: Thực tế hay dùng các params columns và index để chỉ định các dòng hay cột cần được loại bỏ hơn là dùng labels và axis 3.13 .rename() Phương thức .rename() dùng để đổi tên nhãn của cột hoặc dòng. Cú pháp như sau DataFrame.rename(mapper=None, *, index=None, columns=None, axis=None, copy=True, inplace=False, level=None, errors=&#39;ignore&#39;)[source] Trong đó: mapper: là một danh sách dạng dictionary chứa key là tên cần đổi và value là tên mới. axis: Mặc đinh giá trị 0 thay đổi theo index và 1 thay đổi theo cột. index: Chỉ định index của dòng cần thay đổi, tương đương mapper, axis=0, thay thế bằng index=mapper columns: Chỉ định cột cần thay đổi, tương đương mapper, axis=1, thay thế bằng columns=mapper copy: True, mặc định sao chép dữ liệu level: Dành cho MultiIndex, khi đó chỉ định cấp độ index cần đổi tên inplace: Thực hiện trên chính bảng hay tạo ra một bảng sao errors: mặc định raise sẽ trả ra lỗi và ignore nếu muốn bỏ qua lỗi. Ví dụ df = pd.DataFrame(np.arange(16).reshape(4, 4), columns=[&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;], index=[&#39;A&#39;, &#39;1A&#39;, &#39;2A&#39;, &#39;3A&#39;]) df.rename(mapper={&#39;A&#39;:&#39;aA&#39;}) A B C D aA 0 1 2 3 1A 4 5 6 7 2A 8 9 10 11 3A 12 13 14 15 df.rename(mapper={&#39;A&#39;:&#39;aA&#39;}, axis=1) aA B C D A 0 1 2 3 1A 4 5 6 7 2A 8 9 10 11 3A 12 13 14 15 df.rename(columns={&#39;A&#39;:&#39;aA&#39;, &#39;B&#39;:&#39;Bb&#39;}, index={&#39;A&#39;: &#39;OA&#39;,&#39;3A&#39;:&#39;3a&#39;}) aA Bb C D OA 0 1 2 3 1A 4 5 6 7 2A 8 9 10 11 3a 12 13 14 15 Lưu ý: Tương tự như .drop() thì columns và index thường được sử dụng hơn là mapper và axis. Vẫn chưa rõ copy dùng để làm gì. 3.14 .set_index() Phương thức .set_index() dùng để chuyển đổi một cột của bảng thành index. Index này có thể thay thể index cũ hoặc thêm vào để thành MultiIndex. Cách sử dụng như sau: DataFrame.set_index(keys, drop=True, append=False, inplace=False, verify_integrity=False) Trong đó: keys: Có thể truyền vào một cột duy nhất hoặc danh sách các cột. Ngoài ra còn có thể là 1 danh sách dạng pd.Index, Series, np.array, iterator drop: loại bỏ cột trong bảng nếu đã đưa vào index, mặc định là True append: mặc định là False ghi đè lên index đã có. Giá trị True sẽ thêm vào index sẵn có. inplace: Thực hiện trực tiếp trên bảng hoặc tạo ra một bản sao verify_integrity: Kiểm tra xem cột đánh index có chứa các phần tử trùng lặp hay không. Ví dụ df = pd.DataFrame(np.arange(16).reshape(4, 4), columns=[&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;], index=[&#39;A&#39;, &#39;1A&#39;, &#39;2A&#39;, &#39;3A&#39;]) df.index.name = &#39;index1&#39; df A B C D index1 A 0 1 2 3 1A 4 5 6 7 2A 8 9 10 11 3A 12 13 14 15 df.set_index(&#39;A&#39;) B C D A 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 df.set_index([&#39;A&#39;, &#39;B&#39;], append=True) C D index1 A B A 0 1 2 3 1A 4 5 6 7 2A 8 9 10 11 3A 12 13 14 15 df.set_index([pd.Index([1, 2, 3, 4], name=&#39;new_index&#39;)]) A B C D new_index 1 0 1 2 3 2 4 5 6 7 3 8 9 10 11 4 12 13 14 15 Lưu ý: keys không áp dụng cho kiểu list, tuple nhưng Iterator của nó thì được. Ví dụ khi đưa list vào sẽ báo lỗi df.set_index([1, 2, 3, 4]) --------------------------------------------------------------------------- KeyError Traceback (most recent call last) ~\\AppData\\Local\\Temp/ipykernel_1380/3577861036.py in &lt;module&gt; ----&gt; 1 df.set_index([1, 2, 3, 4]) D:\\Vendors\\anaconda\\lib\\site-packages\\pandas\\util\\_decorators.py in wrapper(*args, **kwargs) 309 stacklevel=stacklevel, 310 ) --&gt; 311 return func(*args, **kwargs) 312 313 return wrapper D:\\Vendors\\anaconda\\lib\\site-packages\\pandas\\core\\frame.py in set_index(self, keys, drop, append, inplace, verify_integrity) 5492 5493 if missing: -&gt; 5494 raise KeyError(f&quot;None of {missing} are in the columns&quot;) 5495 5496 if inplace: KeyError: &#39;None of [1, 2, 3, 4] are in the columns&#39; Trong khi đưa vào Iterator thì hoạt động. df.set_index(iter([1, 2, 3, 4])) A B C D 1 0 1 2 3 2 4 5 6 7 3 8 9 10 11 4 12 13 14 15 3.15 .sort_index 3.16 .sort_values Phương thức .sort_values dùng để sắp xếp dữ liệu trong DataFrame hoặc Series DataFrame.sort_values(by, axis=0, ascending=True, inplace=False, kind=&#39;quicksort&#39;, na_position=&#39;last&#39;, ignore_index=False, key=None) Trong đó: by : nhãn hoặc danh sách nhãn cần sắp xếp axis: chỉ định chiều sắp xếp {0 hoặc index, 1 hoặc columns} ascending: Sắp xếp tăng dần hoặc giảm dần, có thể là một giá trị hoặc danh sách các giá trị boolean inplace: Thực hiện trên chính bảng đó hoặc tạo ra một bản sao kind: Thuật toán sắp xếp na_postion: chỉ định các giá trị NA được xếp đầu hoặc cuôi ignore_index: Nếu để giá trị True sẽ thực hiện đánh index lại từ 0 key: key function df = pd.DataFrame({ &#39;col1&#39;: [&#39;A&#39;, &#39;A&#39;, &#39;B&#39;, np.nan, &#39;D&#39;, &#39;C&#39;], &#39;col2&#39;: [2, 1, 9, 8, 2, 4], &#39;col3&#39;: [0, 1, 9, 4, 2, 3], &#39;col4&#39;: [&#39;a&#39;, &#39;B&#39;, &#39;c&#39;, &#39;D&#39;, &#39;e&#39;, &#39;F&#39;] }) df col1 col2 col3 col4 0 A 2 0 a 1 A 1 1 B 2 B 9 9 c 3 NaN 8 4 D 4 D 2 2 e 5 C 4 3 F Sắp xếp theo col1 df.sort_values(by=[&#39;col1&#39;]) col1 col2 col3 col4 0 A 2 0 a 1 A 1 1 B 2 B 9 9 c 5 C 4 3 F 4 D 2 2 e 3 NaN 8 4 D Sắp xếp theo nhiều cột df.sort_values(by=[&#39;col1&#39;, &#39;col2&#39;]) col1 col2 col3 col4 1 A 1 1 B 0 A 2 0 a 2 B 9 9 c 5 C 4 3 F 4 D 7 2 e 3 NaN 8 4 D Sắp xếp theo tăng giảm df.sort_values(by=[&#39;col1&#39;, &#39;col2&#39;], ascending=[False, True]) col1 col2 col3 col4 4 D 2 2 e 5 C 4 3 F 2 B 9 9 c 1 A 1 1 B 0 A 2 0 a 3 NaN 8 4 D Thay đổi vị trí của NaN df.sort_values(by=&#39;col1&#39;, ascending=False, na_position=&#39;first&#39;) col1 col2 col3 col4 3 NaN 8 4 D 4 D 2 2 e 5 C 4 3 F 2 B 9 9 c 0 A 2 0 a 1 A 1 1 B Sắp xếp với key function df.sort_values(by=&#39;col4&#39;, key=lambda col: col.str.lower()) col1 col2 col3 col4 0 A 2 0 a 1 A 1 1 B 2 B 9 9 c 3 NaN 8 4 D 4 D 2 2 e 5 C 4 3 F "],["selecting-và-filtering.html", "Chương 4 Selecting và Filtering 4.1 Sử dụng [] 4.2 .loc và .iloc 4.3 Lọc theo điều kiện", " Chương 4 Selecting và Filtering 4.1 Sử dụng [] Cú pháp [] là cú pháp đơn giản nhất để lấy bảng con của 1 bảng cho trước. Với 1 df là 1 DataFrame có index là region và dữ liệu như sau state individuals family_members state_pop region East South Central Alabama 2570.0 864.0 4887681 Pacific Alaska 1434.0 582.0 735139 Mountain Arizona 7259.0 2606.0 7158024 West South Central Arkansas 2280.0 432.0 3009733 Pacific California 109008.0 20964.0 39461588 Mountain Colorado 7607.0 3250.0 5691287 Để chọn 1 bảng con có 2 cột ['state', 'family_members'] ta làm như sau In [1]: df[[&#39;state&#39;, &#39;family_members&#39;]] Out[1]: state family_members region East South Central Alabama 864.0 Pacific Alaska 582.0 Mountain Arizona 2606.0 West South Central Arkansas 432.0 Pacific California 20964.0 Mountain Colorado 3250.0 Để lấy theo dòng ta dùng tương tự Series In [2]: df[:3] Out[2]: state individuals family_members state_pop region East South Central Alabama 2570.0 864.0 4887681 Pacific Alaska 1434.0 582.0 735139 Mountain Arizona 7259.0 2606.0 7158024 In [3]: df[2:5] Out[3]: state individuals family_members state_pop region Mountain Arizona 7259.0 2606.0 7158024 West South Central Arkansas 2280.0 432.0 3009733 Pacific California 109008.0 20964.0 39461588 Lưu ý: df[['state']] sẽ trả về DataFrame trong khi df['state'] trả về Series. Đối với lấy theo dòng, [] không lấy được theo dòng riêng biệt. [] chỉ lấy dữ liệu theo dòng hoặc cột, không thực hiện được cùng lúc cả hai thao tác. Ví dụ khi gọi df[3] hay df[[1, 2, 3]] sẽ báo lỗi KeyError 4.2 .loc và .iloc 4.2.1 .loc Phương thức .loc dùng để lấy dữ liệu theo cột hoặc hàng dựa theo nhãn định sẵn (Tên hàng, tên cột), ngoài ra .loc còn nhận các giá trị boolean. Đầu vào của .loc có thể gồm: Nhãn đơn: là 1 số 3 hoặc dạng chữ a, lưu ý rằng số này là nhãn của index chứ không phải vị trí của dòng. Danh sách các nhãn : ['a', 'b', 'c'] Đối tượng dạng slice ví dụ 'a':'e' Danh sách kiểu bool có độ dài bằng với số lượng dòng Series dạng bool pd.Index Sử dụng nhãn đơn, kết quả trả về là các dòng có nhãn giống như nhãn trong .loc In [4]: df.loc[&#39;Pacific&#39;] Out[4]: state individuals family_members state_pop region Pacific Alaska 1434.0 582.0 735139 Pacific California 109008.0 20964.0 39461588 Lưu ý: Khi kết quả là nhiều dòng thì dữ liệu trả về có kiểu DataFrame, trong khi nếu chỉ có 1 dòng duy nhất thì kết quả trả về sẽ theo kiểu Series In [5]: type(df.loc[&#39;Pacific&#39;]) Out[5]: &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; In [6]: type(df.loc[&#39;West South Central&#39;]) Out[6]: &lt;class &#39;pandas.core.series.Series&#39;&gt; Khi đưa danh sách các nhãn dùng .loc[[]] thì nhãn đưa vào là nhãn của index. Nếu đưa tên các cột sẽ bị báo lỗi KeyError In [7]: df.loc[[&#39;Pacific&#39;, &#39;Mountain&#39;]] Out[7]: state individuals family_members state_pop region Pacific Alaska 1434.0 582.0 735139 Pacific California 109008.0 20964.0 39461588 Mountain Arizona 7259.0 2606.0 7158024 Mountain Colorado 7607.0 3250.0 5691287 Để lấy nhãn đơn theo nhãn của index và tên column ta truyền vào phần nhãn của index trước và nhãn của column sau và phân biệt bởi dấu phẩy In [7]: df.loc[&#39;Pacific&#39;, &#39;state&#39;] Out[7]: region Pacific Alaska Pacific California Name: state, dtype: object Để lấy nhiều hơn 1 nhãn của index hoặc nhiều hơn 1 nhãn của column ta chỉ cần thay thế nhãn đơn của index thành danh sách hoặc slice, tương tự ta có thế thay thế nhãn đơn thành danh sách hoặc slice của column In [8]: df.loc[&#39;Pacific&#39;, [&#39;individuals&#39;, &#39;family_members&#39;]]) Out[8]: individuals family_members region Pacific 1434.0 582.0 Pacific 109008.0 20964.0 In [9]: df.loc[&#39;Pacific&#39;, &#39;individuals&#39;:&#39;state_pop&#39;] Out[9]: individuals family_members state_pop region Pacific 1434.0 582.0 735139 Pacific 109008.0 20964.0 39461588 Lưu ý: Dùng slice sẽ lấy theo thứ tự xuất hiện chứ không lấy theo thứ tự sắp xếp từ điển, như ví dụ trên thì mặc dù family_members &gt; individuals nhưng vẫn xếp sau. Slice không áp dụng được cho index có nhãn trùng nhau, nếu dùng sẽ báo lỗi KeyError: \"Cannot get right slice bound for non-unique label: Danh sách dạng boolean, chỉ sử dụng cho index, không dùng cho column In [10]: df.loc[[False, True, False, True, False, False]] Out[10]: state individuals family_members state_pop region Pacific Alaska 1434.0 582.0 735139 West South Central Arkansas 2280.0 432.0 3009733 Series boolean In [11]: s = pd.Series([False, True, False, True, False, False], index=[&#39;East South Central&#39;, &#39;Pacific&#39;, &#39;Mountain&#39;, &#39;West South Central&#39;, &#39;Pacific&#39;, &#39;Mountain&#39;]) In [12]: df.loc[s] Out[12]: state individuals family_members state_pop region Pacific Alaska 1434.0 582.0 735139 West South Central Arkansas 2280.0 432.0 3009733 pd.Index In [13]: df.loc[pd.Index([&quot;Pacific&quot;, &quot;East South Central&quot;], name=&quot;meow&quot;)] Out[13]: state individuals family_members state_pop meow Pacific Alaska 1434.0 582.0 735139 Pacific California 109008.0 20964.0 39461588 East South Central Alabama 2570.0 864.0 4887681 Select với MultiIndex individuals family_members state_pop region state Mountain Arizona 7259.0 2606.0 7158024 Colorado 7607.0 3250.0 5691287 Idaho 1297.0 715.0 1750536 Pacific Alaska 1434.0 582.0 735139 California 109008.0 20964.0 39461588 Hawaii 4131.0 2399.0 1420593 Với nhãn đơn In [14]: df.loc[&#39;Mountain&#39;] Out[14]: individuals family_members state_pop state Arizona 7259.0 2606.0 7158024 Colorado 7607.0 3250.0 5691287 Idaho 1297.0 715.0 1750536 Lưu ý: Với MultiIndex,các index sẽ xếp theo thứ tự từ level 0 đến n (level 0 cao hơn level 1 …), với nhãn đơn là nhãn của 1 index thì chỉ thực hiện được index level đầu tiên, các index level sau sẽ báo lỗi. Theo như ví dụ trên thì region có level cao hơn ‘state’ nên chỉ gọi được .loc['Mountain'] còn .loc['Arizona'] sẽ báo lỗi Để select nhiều index cùng lúc, ta truyền vào tuple(label1, label2...) theo thứ tự index có level từ cao đến thấp In [15]: df.loc[(&#39;Mountain&#39;, &#39;Colorado&#39;)] Out[15]: individuals 7607.0 family_members 3250.0 state_pop 5691287.0 Name: (Mountain, Colorado), dtype: float64 Tương tự ta cùng có select theo các column cho trước In [16]: df.loc[(&#39;Mountain&#39;, &#39;Colorado&#39;), [&#39;individuals&#39;, &#39;family_members&#39;]] Out[16]: individuals 7607.0 family_members 3250.0 Name: (Mountain, Colorado), dtype: float64 Mẹo: Có thể select index ở các level sau bằng cách dùng slice In [17]: df.loc[(slice(None), &#39;Arizona&#39;), :] Out[17]: individuals family_members state_pop region state Mountain Arizona 7259.0 2606.0 7158024 Slice cho MultiIndex Slice từ 1 tuple nhãn đến một nhãn đơn In [18]: df.loc[(&#39;Mountain&#39;, &#39;Colorado&#39;):&#39;Pacific&#39;] Out[18]: individuals family_members state_pop region state Mountain Colorado 7607.0 3250.0 5691287 Idaho 1297.0 715.0 1750536 Pacific Alaska 1434.0 582.0 735139 California 109008.0 20964.0 39461588 Hawaii 4131.0 2399.0 1420593 Lưu ý: Nhãn đơn phía sau phải có cùng level với nhãn đầu tiên trong tuple. Trong ví dụ trên nếu thay Pacific thành Hawaii sẽ trả về rỗng. Nhưng khi truyền nhãn không nằm trong các nhãn của index thì vẫn có kết quả trả về In [19]: df.loc[(&#39;Mountain&#39;, &#39;Colorado&#39;): &#39;meow&#39;] Out[19]: individuals family_members state_pop region state Mountain Colorado 7607.0 3250.0 5691287 Idaho 1297.0 715.0 1750536 Pacific Alaska 1434.0 582.0 735139 California 109008.0 20964.0 39461588 Hawaii 4131.0 2399.0 1420593 Slice từ 1 tuple nhãn đến một tuple nhãn In [20]: df.loc[(&#39;Mountain&#39;, &#39;Colorado&#39;):(&#39;Pacific&#39;, &#39;California&#39;)] Out[20]: individuals family_members state_pop region state Mountain Colorado 7607.0 3250.0 5691287 Idaho 1297.0 715.0 1750536 Pacific Alaska 1434.0 582.0 735139 California 109008.0 20964.0 39461588 4.2.2 .iloc Phương thức .iloc dùng để lấy dữ liệu theo cột hoặc hàng dựa theo index của nó, ngoài ra .iloc còn nhận các giá trị boolean. Đầu vào của .iloc có thể gồm: Nhãn đơn: là 1 số 3 Danh sách các số : [1, 2, 3] Đối tượng dạng slice ví dụ 1:5 Danh sách kiểu bool có độ dài bằng với số lượng dòng Ví dụ với DataFrame state individuals family_members state_pop region East South Central Alabama 2570.0 864.0 4887681 Pacific Alaska 1434.0 582.0 735139 Mountain Arizona 7259.0 2606.0 7158024 West South Central Arkansas 2280.0 432.0 3009733 Pacific California 109008.0 20964.0 39461588 Mountain Colorado 7607.0 3250.0 5691287 Khi truyền 1 giá trị nguyên, .iloc trả về giá trị của dòng tại vị trí truyền vào với kiểu Series In [21]: df.iloc[0] Out[21]: state Alabama individuals 2570.0 family_members 864.0 state_pop 4887681 Name: East South Central, dtype: object Lưu ý: Series trả về không chứa nhãn của index, ở đây là nhãn East South Central của index region Để lấy dữ liệu theo cột, ví dụ muốn lấy cột family_members thì sẽ truyền index cột là 2 In [22]: df.iloc[:, 2] Out[22]: region East South Central 864.0 Pacific 582.0 Mountain 2606.0 West South Central 432.0 Pacific 20964.0 Mountain 3250.0 Name: family_members, dtype: float64 Mẹo: .iloc bắt buộc truyền vào vị trí của cột, không cho phép tên cột. Sử dụng .columns.get_loc(&lt;tên cột&gt;) để lấy vị trí của cột In [23]: df.iloc[:, df.columns.get_loc(&#39;family_members&#39;)] Out[23]: region East South Central 864.0 Pacific 582.0 Mountain 2606.0 West South Central 432.0 Pacific 20964.0 Mountain 3250.0 Name: family_members, dtype: float64 Select theo danh sách, mặc định đưa vào 1 danh sách Pandas sẽ hiểu là lấy theo các dòng In [24]: df.iloc[[1, 3 ,5]] Out[24]: individuals family_members state_pop region state Mountain Colorado 7607.0 3250.0 5691287 Pacific Alaska 1434.0 582.0 735139 Hawaii 4131.0 2399.0 1420593 Mẹo: Dòng lệnh trên cũng tương đương với df.iloc[[1, 3 ,5], :], trong đó : dùng để lấy toàn bộ Tương tự để lấy theo danh sách index các cột In [25]: df.iloc[:, [0, 2]] Out[25]: individuals state_pop region state Mountain Arizona 7259.0 7158024 Colorado 7607.0 5691287 Idaho 1297.0 1750536 Pacific Alaska 1434.0 735139 California 109008.0 39461588 Hawaii 4131.0 1420593 Slice cả 2 chiều In [26]: df.iloc[2:4, 0:2] Out[26]: individuals family_members region state Mountain Idaho 1297.0 715.0 Pacific Alaska 1434.0 582.0 Sử dụng danh sách các boolean # Theo dòng In [27]: df.iloc[[True, False, True, False, False, True], :] Out[27]: individuals family_members state_pop region state Mountain Arizona 7259.0 2606.0 7158024 Idaho 1297.0 715.0 1750536 Pacific Hawaii 4131.0 2399.0 1420593 #Theo cột In [28]: df.iloc[:, [False, True,False]] Out[28]: family_members region state Mountain Arizona 2606.0 Colorado 3250.0 Idaho 715.0 Pacific Alaska 582.0 California 20964.0 Hawaii 2399.0 4.3 Lọc theo điều kiện Các phương thức [], .loc hay .iloc ngoài việc lấy dữ liệu theo hàng và cột còn có thể lấy ra những bảng con theo các điều kiện cho trước. Bản chất các câu điều kiện sẽ trả về một danh sách dạng bolean và các hàm trên thực hiện lọc theo danh sách đó. Trước hết ta cần biết câu điều kiện trong Pandas như thế nào. Ví dụ ta có 1 DataFrame như sau state individuals family_members state_pop region Mountain Arizona 7259.0 2606.0 7158024 Mountain Colorado 7607.0 3250.0 5691287 Mountain Idaho 1297.0 715.0 1750536 Pacific Alaska 1434.0 582.0 735139 Pacific California 109008.0 20964.0 39461588 Pacific Hawaii 4131.0 2399.0 1420593 4.3.1 Toán tử điều kiện Giả sử ta có một điều kiện rằng df['individuals'] &gt; 5000. Kết quả trả về là 1 Series In [28]: df[&#39;individuals&#39;] &gt; 5000 Out[28]: region Mountain True Mountain True Mountain False Pacific False Pacific True Pacific False Name: individuals, dtype: bool Để lọc theo điều kiện này ta có các cách như sau ## Dùng [] In [29]: df[df[&#39;individuals&#39;] &gt; 5000] Out[29]: state individuals family_members state_pop region Mountain Arizona 7259.0 2606.0 7158024 Mountain Colorado 7607.0 3250.0 5691287 Pacific California 109008.0 20964.0 39461588 ## Dùng .loc In [30]: df.loc[df[&#39;individuals&#39;] &gt; 5000] Out[30]: state individuals family_members state_pop region Mountain Arizona 7259.0 2606.0 7158024 Mountain Colorado 7607.0 3250.0 5691287 Pacific California 109008.0 20964.0 39461588 Lưu ý: .iloc không nhận Series boolean nhưng array thì có thể. Do đó ta có thể dùng .values để lấy kết quả của Câu điều kiện ## Dùng .iloc In [31]: df.iloc[(df[&#39;individuals&#39;] &gt; 5000).values] Out[31]: state individuals family_members state_pop region Mountain Arizona 7259.0 2606.0 7158024 Mountain Colorado 7607.0 3250.0 5691287 Pacific California 109008.0 20964.0 39461588 Ta cũng có thể áp nhiều điều kiện cùng lúc, mỗi điều kiện phải nằm trong dấu ngoặc đơn () và giữa các kiều kiện là toán tử &amp; hoặc | ## Nhiều câu điều kiện trên một cột In [32]: df.loc[(df[&#39;individuals&#39;] &gt; 5000) &amp; (df[&#39;individuals&#39;] &lt; 10000)] Out[32]: state individuals family_members state_pop region Mountain Arizona 7259.0 2606.0 7158024 Mountain Colorado 7607.0 3250.0 5691287 ## Nhiều câu điều kiện ở nhiều cột In [33]: df.loc[(df[&#39;individuals&#39;] &gt; 5000) &amp; (df[&#39;family_members&#39;] &lt; 10000) Out[33]: state individuals family_members state_pop region Mountain Arizona 7259.0 2606.0 7158024 Mountain Colorado 7607.0 3250.0 5691287 ## Một câu điều kiện trên nhiều cột In [34]: df[df[&#39;individuals&#39;] &gt; 5 * df[&#39;family_members&#39;]] Out[34]: state individuals family_members state_pop region Pacific California 109008.0 20964.0 39461588 Mẹo: Bạn cũng có thể dùng loc để vừa lọc các dòng thỏa điều kiện, vừa chọn các cột muốn lấy In []: df.loc[df[&#39;individuals&#39;] &gt; 5 * df[&#39;family_members&#39;], [&#39;individuals&#39;, &#39;family_members&#39;]] Out[]: individuals family_members region Pacific 109008.0 20964.0 Ngoài ra, pandas còn cho phép bạn lọc với cấu trúc câu truy vấn bằng .query theo cú pháp DataFrame.query(expr, inplace=False, **kwargs) Trong đó: expr: là câu truy vấn inplace: thực hiện trên chính DataFrame đó hay tạo 1 bảng sao **kwargs: keyword arguments Theo ví dụ trên, để thực hiện lọc theo điều kiện df['individuals'] &gt; 5000 và df['family_members'] &lt; 10000 ta có thể làm như sau In [34]: df.query(&#39;individuals &gt; 500 and family_members &lt; 10000&#39;) Out[34]: state individuals family_members state_pop region Mountain Arizona 7259.0 2606.0 7158024 Mountain Colorado 7607.0 3250.0 5691287 4.3.2 .isin() Phương thức .isin(values) để kiểm tra các phần tử trong DataFrame hoặc Series có nằm trong values hay không. Ví dụ: In [35]: df.isin([&#39;Alaska&#39;, &#39;Oklahoma&#39;, &#39;Illinois&#39;, &#39;Arizona&#39;, 7259, 582, 300]) Out[35]: state individuals family_members state_pop region Mountain True True False False Mountain False False False False Mountain False False False False Pacific True False True False Pacific False False False False Pacific False False False False In [36]: df[&#39;state&#39;].isin([&#39;Alaska&#39;, &#39;Oklahoma&#39;, &#39;Illinois&#39;, &#39;Arizona&#39;]) Out[36]: region Mountain True Mountain False Mountain False Pacific True Pacific False Pacific False Name: state, dtype: bool Ngoài ra bạn có thể truyền values là một dictionary để kiểm tra cho từng cột theo từng tập giá trị In [37]: df.isin({&#39;state&#39;: [&#39;Alaska&#39;, &#39;Oklahoma&#39;, &#39;Illinois&#39;, &#39;Arizona&#39;], &#39;individuals&#39;: [7259, 582, 300]}) Out[37]: state individuals family_members state_pop region Mountain True True False False Mountain False False False False Mountain False False False False Pacific True False False False Pacific False False False False Pacific False False False False Lọc với .isin() In [38]: df[df[&#39;state&#39;].isin([&#39;Alaska&#39;, &#39;Oklahoma&#39;, &#39;Illinois&#39;, &#39;Arizona&#39;])] Out[38]: state individuals family_members state_pop region Mountain Arizona 7259.0 2606.0 7158024 Pacific Alaska 1434.0 582.0 735139 trong trường hợp sự dụng .isin với DataFrame, kết quả của lọc sẽ trả về một DataFrame với giá trị các phần tử mà phép isin trả về True, các phần tử còn lại trả giá trị NaN In [39]: df[df.isin([&#39;Alaska&#39;, &#39;Oklahoma&#39;, &#39;Illinois&#39;, &#39;Arizona&#39;, 7259, 582, 300])] Out[39]: state individuals family_members state_pop region Mountain Arizona 7259.0 NaN NaN Mountain NaN NaN NaN NaN Mountain NaN NaN NaN NaN Pacific Alaska NaN 582.0 NaN Pacific NaN NaN NaN NaN Pacific NaN NaN NaN NaN Mẹo: Bạn có dùng .any() để tổng hợp điều kiện của 1 DataFrame với các phần tử boolean .any(axis=1) : Chỉ cần tồn tại 1 cột giá trị True, trả về giá trị True cho dòng .any(axis=0): Chỉ cần tồn tại 1 dòng có giá trị True, trả về giá trị True cho cột. Phương thức .any() thường dùng để kiểm tra các dòng tồn tại 1 cột giá trị NaN Lọc với .isin() và any(axis=1) In [40]: df.isin([&#39;Alaska&#39;, &#39;Oklahoma&#39;, &#39;Illinois&#39;, &#39;Arizona&#39;, 7259, 582, 300]).any(axis=1) Out[40]: region Mountain True Mountain False Mountain False Pacific True Pacific False Pacific False dtype: bool In [41]: df[df.isin([&#39;Alaska&#39;, &#39;Oklahoma&#39;, &#39;Illinois&#39;, &#39;Arizona&#39;, 7259, 582, 300]).any(axis=1)] Out[41]: state individuals family_members state_pop region Mountain Arizona 7259.0 2606.0 7158024 Pacific Alaska 1434.0 582.0 735139 Lọc với isin() và any(axis=0) In [42]: df.isin([&#39;Alaska&#39;, &#39;Oklahoma&#39;, &#39;Illinois&#39;, &#39;Arizona&#39;, 7259, 582, 300]).any(axis=0) Out[42]: state True individuals True family_members True state_pop False dtype: bool In [43]: df.loc[:,df.isin([&#39;Alaska&#39;, &#39;Oklahoma&#39;, &#39;Illinois&#39;, &#39;Arizona&#39;, 7259, 582, 300]).any(axis=0)] Out[43]: state individuals family_members region Mountain Arizona 7259.0 2606.0 Mountain Colorado 7607.0 3250.0 Mountain Idaho 1297.0 715.0 Pacific Alaska 1434.0 582.0 Pacific California 109008.0 20964.0 Pacific Hawaii 4131.0 2399.0 Lọc với isin() và any(axis=0) và any(axis=1) In []: bool_df = df.isin([&#39;Alaska&#39;, &#39;Oklahoma&#39;, &#39;Illinois&#39;, &#39;Arizona&#39;, 7259, 582, 300]) In []: df.loc[bool_df.any(axis=1), bool_df.any(axis=0)] Out[]: state individuals family_members region Mountain Arizona 7259.0 2606.0 Pacific Alaska 1434.0 582.0 4.3.3 Lọc missing value với .dropna() Trong quá trình xử lý dữ liệu, chúng ta thường gặp những bảng có chứa giá trị missing value. Ví dụ bảng missing_df state individuals family_members state_pop region Mountain Arizona 7259.0 NaN NaN Mountain Colorado NaN 3250.0 5691287.0 Mountain Idaho 1297.0 715.0 1750536.0 Pacific Alaska 1434.0 NaN 735139.0 Pacific California 109008.0 20964.0 39461588.0 Pacific Hawaii 4131.0 2399.0 NaN Để lọc dữ liệu chứa NaN ta dùng phương thức .dropna() DataFrame.dropna(axis=0, how=&#39;any&#39;, thresh=None, subset=None, inplace=False) Trong đó: axis: Nhận diện lọc theo dòng 0, index, hay cột 1, column how: Chỉ định cách lọc any: Nếu có bất kì NA, loại bỏ dòng hoặc cột all: Nếu tất cả là NA, loại bỏ dòng hoặc cột thresh: Số lượng non-NA yêu cầu subset: Chỉ định các cột cần lọc inplace: Thực hiện trên chính DataFrame hay tạo bản sao. Lọc bỏ các hàng nếu ít nhất một phần tử NA In []: missing_df.dropna(axis=0) Out[]: state individuals family_members state_pop region Mountain Idaho 1297.0 715.0 1750536.0 Pacific California 109008.0 20964.0 39461588.0 Lọc bỏ các cột nếu ít nhất một phần tử NA In []: missing_df.dropna(axis=&#39;columns&#39;) Out[]: state region Mountain Arizona Mountain Colorado Mountain Idaho Pacific Alaska Pacific California Pacific Hawaii Lọc bỏ các dòng nếu tất cả phần tử trong các cột ['family_members', 'state_pop'] là NA In []: missing_df.dropna(axis=&#39;index&#39;, how=&#39;all&#39;, subset=[&#39;family_members&#39;, &#39;state_pop&#39;]) Out[]: state individuals family_members state_pop region Mountain Colorado NaN 3250.0 5691287.0 Mountain Idaho 1297.0 715.0 1750536.0 Pacific Alaska 1434.0 NaN 735139.0 Pacific California 109008.0 20964.0 39461588.0 Pacific Hawaii 4131.0 2399.0 NaN Giữ lại các dòng có ít nhất 3 phần tử non-NA In []: missing_df.dropna(thresh=3) Out[]: state individuals family_members state_pop region Mountain Colorado NaN 3250.0 5691287.0 Mountain Idaho 1297.0 715.0 1750536.0 Pacific Alaska 1434.0 NaN 735139.0 Pacific California 109008.0 20964.0 39461588.0 Pacific Hawaii 4131.0 2399.0 NaN "],["tính-toán-trên-các-phần-tử-trong-pandas.html", "Chương 5 Tính toán trên các phần tử trong Pandas 5.1 Sử dụng Vectorization 5.2 Sử dụng apply 5.3 Sử dụng iterator 5.4 So sánh các phương pháp lặp 5.5 Xử lý song song trong pandas", " Chương 5 Tính toán trên các phần tử trong Pandas df = pd.read_csv(&#39;data/big_mart_sales.csv&#39;) 5.1 Sử dụng Vectorization Giả sử như muốn tạo cột price= Item_Outlet_Sales * 5% In []: df[&#39;price&#39;] = df[&#39;Item_Outlet_Sales&#39;] * 0.05 In []: df[[&#39;Item_Outlet_Sales&#39;, &#39;price&#39;]] Out[]: Item_Outlet_Sales price 0 3735.1380 186.75690 1 443.4228 22.17114 2 2097.2700 104.86350 3 732.3800 36.61900 4 994.7052 49.73526 ... ... ... 8518 2778.3834 138.91917 8519 549.2850 27.46425 8520 1193.1136 59.65568 8521 1845.5976 92.27988 8522 765.6700 38.28350 Nối hai cột lại với nhau, Ví dụ nối Item_type và Item_Fat_Content thành Item_Type_Fat_Content nối Outlet_Identifier và Outlet_Establishment_Year thành Outlet_Identifier_Establishment_Year. Trong trường hợp hợp này Outlet_Establishment_Year thuộc dạng số nên để nối dạng text và số ta ép kiểu dạng số về text sử dụng astype() df[&#39;Item_Type_Fat_Content&#39;] = df[&#39;Item_Type&#39;] + &#39;_&#39; + df[&#39;Item_Fat_Content&#39;] df[&#39;Outlet_Identifier_Establishment_Year&#39;] = df[&#39;Outlet_Identifier&#39;] + &#39;_&#39; +df[&#39;Outlet_Establishment_Year&#39;].astype(&#39;str&#39;) df[[&#39;Item_Type_Fat_Content&#39;, &#39;Outlet_Identifier_Establishment_Year&#39;]] Item_Type_Fat_Content Outlet_Identifier_Establishment_Year 0 Dairy_Low Fat OUT049_1999 1 Soft Drinks_Regular OUT018_2009 2 Meat_Low Fat OUT049_1999 3 Fruits and Vegetables_Regular OUT010_1998 4 Household_Low Fat OUT013_1987 ... ... ... 8518 Snack Foods_Low Fat OUT013_1987 8519 Baking Goods_Regular OUT045_2002 8520 Health and Hygiene_Low Fat OUT035_2004 8521 Snack Foods_Regular OUT018_2009 8522 Soft Drinks_Low Fat OUT046_1997 5.2 Sử dụng apply Phương thức apply để thực thi một hàm theo dòng hoặc cột Đối với Series Series.apply(func, convert_dtype=True, args=(), **kwargs) Trong đó: func: là hàm cần thực thi convert_dtype: Giá trị kiểu boolean. Nếu nó được đặt thành True (mặc định), xử lý dữ liệu sẽ cố gắng tìm dtype tốt hơn cho các kết quả của hàm func. Nếu False, thì dtype sẽ là type(object) args: Các đối số của hàm Ví dụ, thao tác Item_Outlet_Sales * 5% Sử dụng lambda function In []: df[&#39;Item_Outlet_Sales&#39;].apply(lambda x: x * 0.05) Out[]: 0 186.75690 1 22.17114 2 104.86350 3 36.61900 4 49.73526 ... 8518 138.91917 8519 27.46425 8520 59.65568 8521 92.27988 8522 38.28350 Name: Item_Outlet_Sales, Length: 8523, dtype: float64 Sử dụng hàm tự định nghĩa def set_price(x, k=0.05): return x * k In []: df[&#39;Item_Outlet_Sales&#39;].apply(set_price) Out[]: 0 186.75690 1 22.17114 2 104.86350 3 36.61900 4 49.73526 ... 8518 138.91917 8519 27.46425 8520 59.65568 8521 92.27988 8522 38.28350 Name: Item_Outlet_Sales, Length: 8523, dtype: float64 Có thể truyền tham số k vào hàm set_price bằng hai cách # Cách 1 - Dùng lambda In []: df[&#39;Item_Outlet_Sales&#39;].apply(lambda x: set_price(x, 0.1)) # Cách 2 - Dùng `arg` In []: df[&#39;Item_Outlet_Sales&#39;].apply(set_price, k=0.1) Đối với DataFrame Ta dùng cú pháp DataFrame.apply(func, axis=0, raw=False, result_type=None, args=(), **kwargs) Trong đó: func: là hàm cần thực thi axis: thực thi theo dòng 0 hoặc cột 1 raw: Xác định xem dòng hoặc cột có thể chuyển về Series hoặc ndarray result_type: Chỉ áp dụng cho axis=1 args: Các đối số của hàm Ví dụ: In []: sample_df = sample_df = pd.DataFrame([[1, 2, &#39;A&#39;], [3, 6, &#39;B&#39;], [5, 10, &#39;C&#39;]], columns=[&#39;A&#39;, &#39;B&#39;, &#39;C&#39;]) In []: sample_df Out[]: A B C 0 1 2 A 1 3 6 B 2 5 10 C Áp dụng trên toàn DataFrame In []: sample_df.apply(lambda x: x * 2) Out[]: A B C 0 2 4 AA 1 6 12 BB 2 10 20 CC Lưu ý: Khi áp dụng cho toàn DataFrame hãy cẩn thận hàm func truyền vào, nếu func không áp dụng được cho toàn bộ các phần tử sẽ báo lỗi. Ví dụ ở trên với x * 2 vẫn áp dụng được cho cột C dạng str, nhưng khi thay bằng x ** 2 sẽ báo lỗi vì toán tử ** không áp dụng cho str Áp dụng trên một số cột trong DataFrame ## Theo cột In []: sample_df[[&#39;A&#39;, &#39;B&#39;]].apply(np.sum, axis=1) Out[]: 0 13 1 13 2 13 dtype: int64 ## Theo dòng In []: df[[&#39;A&#39;, &#39;B&#39;]].apply(lambda x: np.sum(x), axis=0) Out[]: A 12 B 27 dtype: int64 Một cách khác áp dụng trên một số cột trong DataFrame Sử dụng lambda In []: sample_df.apply(lambda x: x[&#39;A&#39;] + 2 * x[&#39;B&#39;], axis=1) Out[]: 0 5 1 15 2 25 dtype: int64 Dùng hàm định nghĩa def dsum(row): return row[&#39;A&#39;] + 2 * row[&#39;B&#39;] In []: sample_df.apply(dsum, axis=1) Out[]: 0 5 1 15 2 25 dtype: int64 Mẹo: Không nhất thiết giá trị trả về của hàm là giá trị đơn, giá trị trả về có thể dưới dạng list, tuple hoặc dict Dùng result_type để thay đổi cách trả về Ví dụ ta có 1 hàm trả về nhiều giá trị cùng lúc như sau def dsum_2(row): return [row[&#39;A&#39;] + 2 * row[&#39;B&#39;], row[&#39;A&#39;] - 2 * row[&#39;B&#39;]] ## Khi không sử dụng `result_type` In []: sample_df.apply(dsum_2, axis=1) Out[]: 0 [5, -3] 1 [15, -9] 2 [25, -15] dtype: object Kết quả trả về của phương pháp trên là Series với các giá trị của nó là dạng list. Để chuyển Series này thành DataFrame với các cột chứa các giá trị của list theo thứ tự, ta dùng result_type='expand' In []: sample_df.apply(dsum_2, axis=1, result_type=&#39;expand&#39;) 0 1 0 5 -3 1 15 -9 2 25 -15 Mẹo: Có thể cấu trúc trả về dưới dạng DataFrame cho ví dụ trên mà không cần dùng result_type bằng cách sử dụng pd.Series của một dictionary. Lúc này các cột của DataFrame sẽ được đánh nhãn theo key của dictionary def dsum_3(row): return pd.Series({&#39;X&#39;: row[&#39;A&#39;] + 2 * row[&#39;B&#39;], &#39;Y&#39;:row[&#39;A&#39;] - 2 * row[&#39;B&#39;]}) In []: sample_df.apply(dsum_3, axis=1) Out[]: X Y 0 5 -3 1 15 -9 2 25 -15 5.3 Sử dụng iterator df = pd.read_csv(&#39;data/big_mart_sales.csv&#39;, usecols=[&#39;Item_Identifier&#39;, &#39;Item_Fat_Content&#39;, &#39;Item_Type&#39;, &#39;Outlet_Size&#39;, &#39;Item_Outlet_Sales&#39;, &#39;Outlet_Establishment_Year&#39;]) 5.3.1 Iterrows DataFrame.iterrows() In []: row = next(df.iterrows()) Out[]: row (0, Item_Identifier FDA15 Item_Fat_Content Low Fat Item_Type Dairy Outlet_Establishment_Year 1999 Outlet_Size Medium Item_Outlet_Sales 3735.138 Name: 0, dtype: object) Kết quả trả về cho row là 1 tuple gồm index và Series chứa các giá trị tại index đó. Cách dùng vòng lặp trong iterrows Để duyệt từng dòng ta dùng for như bình thường prices = [] for i, row in df.iterrows(): prices.append(row[&#39;Item_Outlet_Sales&#39;] * 0.5) print(prices[:5]) [1867.569, 221.7114, 1048.635, 366.19, 497.3526] 5.3.2 Itertuple DataFrame.itertuples(index=True, name=&#39;Pandas&#39;) Trong đó: index: True trả về kết quả kèm theo index và False lược bỏ index name: Quy định kiểu trả về Pandas: trả về namedtuple None: trả về tuple namedtuple: trả về namedtuple Trả về namedtuple In []: next(df.itertuples(index=True)) Out[]: Pandas(Index=0, Item_Identifier=&#39;FDA15&#39;, Item_Fat_Content=&#39;Low Fat&#39;, Item_Type=&#39;Dairy&#39;, Outlet_Establishment_Year=1999, Outlet_Size=&#39;Medium&#39;, Item_Outlet_Sales=3735.138) Trả về tuple In []: next(df.itertuples(index=False, name=None)) Out[]: (&#39;FDA15&#39;, &#39;Low Fat&#39;, &#39;Dairy&#39;, 1999, &#39;Medium&#39;, 3735.138) Cách dùng vòng lặp trong itertuples name=default prices = [] for row in df.itertuples(): prices.append(row.Item_Outlet_Sales * 0.5) print(prices[:5]) name=None prices = [] for row in df.itertuples(index=False, name=None): prices.append(row[5] * 0.5) print(prices[:5]) 5.4 So sánh các phương pháp lặp def vectorizer(df): prices = df[&#39;Item_Outlet_Sales&#39;] * 0.5 def applyer(df): prices = df[&#39;Item_Outlet_Sales&#39;].apply(lambda x: x * 0.5) def iterrows(df): prices = [] for i, row in df.iterrows(): prices.append(row[&#39;Item_Outlet_Sales&#39;] * 0.5) def itertuples1(df): prices = [] for row in df.itertuples(): prices.append(row.Item_Outlet_Sales * 0.5) def itertuples2(df): prices = [] for row in df.itertuples(index=False, name=None): prices.append(row[5] * 0.5) In []: %timeit -n 10 vectorizer(df) Out[]: 80.1 µs ± 42.8 µs per loop (mean ± std. dev. of 7 runs, 10 loops each) In[ ]: %timeit -n 10 applyer(df) Out[]: 1.37 ms ± 112 µs per loop (mean ± std. dev. of 7 runs, 10 loops each) In []: %timeit -n 10 iterrows(df) Out[]: 256 ms ± 2.48 ms per loop (mean ± std. dev. of 7 runs, 10 loops each) In []: %timeit -n 10 itertuples1(df) Out[]: 6.61 ms ± 200 µs per loop (mean ± std. dev. of 7 runs, 10 loops each) In []: %timeit -n 10 itertuples2(df) Out[]: 3.91 ms ± 132 µs per loop (mean ± std. dev. of 7 runs, 10 loops each) 5.5 Xử lý song song trong pandas Xử lý song song là phương pháp tận dụng số lượng core của CPU để giải quyết vấn đề trong thời gian ngắn hơn. 5.5.1 pandarallel Để cài đặt pandarallel bằng pip pip install pandarallel Cách sử dụng from pandarallel import pandarallel pandarallel.initialize(progress_bar=True, n_workers=4) Để thiết lập cho pandarallel ta dùng .initialize. Trong đó: n_workers: là số lượng cores của CPU progress_bar: show tiến trình Để áp dụng pandarallel ta chỉ việc thay thế .apply bằng .parallel_apply # df.apply(func) df.parallel_apply(func) "],["các-cách-phối-hợp-nhiều-bảng-với-nhau.html", "Chương 6 Các cách phối hợp nhiều bảng với nhau 6.1 Join 6.2 Merge 6.3 Concat", " Chương 6 Các cách phối hợp nhiều bảng với nhau 6.1 Join 6.2 Merge 6.3 Concat "],["groupby.html", "Chương 7 Groupby 7.1 Groupby 7.2 Các hàm Filtering trong Groupby 7.3 Aggregate trong Groupby", " Chương 7 Groupby 7.1 Groupby Phương thức .groupby sẽ gom các dòng hoặc các cột thành các nhóm khác nhau. Cú pháp cơ bản của .groupby như sau DataFrame.groupby(by=None, axis=0, dropna=True) Trong đó by: có thể là dạng mapping, nhãn, danh sách nhãn hoặc một hàm trả về danh sách các index axis: Tùy chọn group theo dòng {0 hoặc index} hoặc cột {1 hoặc columns}, mặc định là dòng. dropna: Mặc định là True sẽ bỏ qua những dòng chứa NA và False sẽ thêm NA là một khóa trong nhóm, tương tự như .value_counts() Ví dụ với dữ liệu Big Mart Salses In [1]: df.head() Out[1]: Item_Identifier Item_Type Outlet_Size Item_Outlet_Sales 0 FDA15 Dairy Medium 3735.1380 1 DRC01 Soft Drinks Medium 443.4228 2 FDN15 Meat Medium 2097.2700 3 FDX07 Fruits and Vegetables NaN 732.3800 4 NCD19 Household High 994.7052 In [2]: grouped = df.groupby(&#39;Item_Type&#39;) In [3]: type(grouped) Out[3]: pandas.core.groupby.generic.DataFrameGroupBy Để xem từng nhóm trong group, ta có thể sử dụng .get_groups() và truyền key vào đó. Ví dụ với key Dairy In [4]: grouped.get_group(&#39;Dairy&#39;).head() Out[4]: Item_Identifier Item_Type Outlet_Size Item_Outlet_Sales 0 FDA15 Dairy Medium 3735.1380 11 FDA03 Dairy Small 2187.1530 19 FDU02 Dairy Small 2748.4224 28 FDE51 Dairy NaN 178.4344 30 FDV38 Dairy NaN 163.7868 Khi chọn 1 column sau khi .groupby sẽ trả về kiểu pandas.core.groupby.generic.SeriesGroupBy 7.2 Các hàm Filtering trong Groupby .head(n=5) Trả về n dòng đầu của mỗi group. In [4]: df.groupby([&#39;Item_Type&#39;]).head(n=2) Out[4]: Item_Identifier Item_Type Outlet_Size Item_Outlet_Sales 0 FDA15 Dairy Medium 3735.1380 1 DRC01 Soft Drinks Medium 443.4228 2 FDN15 Meat Medium 2097.2700 3 FDX07 Fruits and Vegetables NaN 732.3800 4 NCD19 Household High 994.7052 5 FDP36 Baking Goods Medium 556.6088 6 FDO10 Snack Foods High 343.5528 7 FDP10 Snack Foods Medium 4022.7636 8 FDH17 Frozen Foods NaN 1076.5986 9 FDU28 Frozen Foods NaN 4710.5350 10 FDY07 Fruits and Vegetables Medium 1516.0266 11 FDA03 Dairy Small 2187.1530 15 FDP49 Breakfast Small 1547.3192 16 NCB42 Health and Hygiene Medium 1621.8888 17 FDP49 Breakfast Medium 718.3982 18 DRI11 Hard Drinks Medium 2303.6680 21 FDW12 Baking Goods Medium 4064.0432 22 NCB30 Household Small 1587.2672 27 DRJ59 Hard Drinks High 308.9312 29 FDC14 Canned Small 125.8362 31 NCS17 Health and Hygiene Medium 2741.7644 33 FDO23 Breads NaN 2174.5028 34 DRH01 Soft Drinks Small 2085.2856 41 FDK43 Meat High 2150.5340 43 FDC02 Canned Medium 6768.5228 72 FDH35 Starchy Foods NaN 4604.6728 114 FDV11 Breads NaN 3151.8972 136 FDH35 Starchy Foods Medium 5262.4832 139 NCN07 Others NaN 263.6568 142 NCO55 Others NaN 2143.8760 231 FDG33 Seafood Medium 3435.5280 713 FDH21 Seafood Medium 1267.6832 .tail(n=5) Trả về n dòng cuối của mỗi group In [5]: df.groupby([&#39;Item_Type&#39;]).tail(n=2) Out[5]: Item_Identifier Item_Type Outlet_Size Item_Outlet_Sales 8317 FDN13 Breakfast NaN 1306.9654 8335 FDO49 Breakfast Medium 708.4112 8370 FDV23 Breads Small 871.5322 8413 FDW59 Breads Small 1691.1320 8423 FDJ57 Seafood Medium 2600.6148 8426 FDA22 Starchy Foods Small 4512.1266 8457 FDY50 Dairy Small 1516.6924 8463 FDG59 Starchy Foods Medium 810.9444 8473 DRI47 Hard Drinks NaN 431.4384 8483 DRI11 Hard Drinks NaN 1612.5676 8488 NCN14 Others Medium 2756.4120 8489 FDV13 Canned Medium 2109.2544 8491 FDO03 Meat Medium 4809.7392 8496 FDJ57 Seafood NaN 3715.1640 8499 NCK53 Health and Hygiene Small 2976.1260 8502 NCH43 Household NaN 3020.0688 8504 NCN18 Household Medium 4138.6128 8506 DRF37 Soft Drinks Medium 3944.8650 8508 FDW31 Fruits and Vegetables NaN 2587.9646 8509 FDG45 Fruits and Vegetables NaN 424.7804 8511 FDF05 Frozen Foods Medium 4207.8560 8512 FDR26 Dairy High 2479.4392 8513 FDH31 Meat Small 595.2252 8514 FDA01 Canned NaN 468.7232 8515 FDH24 Baking Goods Medium 1571.2880 8516 NCJ19 Others Medium 858.8820 8517 FDF53 Frozen Foods Small 3608.6360 8518 FDF22 Snack Foods High 2778.3834 8519 FDS36 Baking Goods NaN 549.2850 8520 NCJ29 Health and Hygiene Small 1193.1136 8521 FDN46 Snack Foods Medium 1845.5976 8522 DRG01 Soft Drinks Small 765.6700 Lưu ý: .head() và .tail() trả về các dòng theo thứ tự index của chúng, không trả về theo thứ tự sắp xếp theo key 7.3 Aggregate trong Groupby ======= .count() Đếm số lượng phần tử cho từng cột trong từng nhóm, không đếm các phần tử NA In [6]: df.groupby([&#39;Item_Type&#39;]).count() Out[6]: Item_Identifier Outlet_Size Item_Outlet_Sales Item_Type Baking Goods 648 463 648 Breads 251 179 251 Breakfast 110 79 110 Canned 649 471 649 Dairy 682 496 682 Frozen Foods 856 615 856 Fruits and Vegetables 1232 883 1232 Hard Drinks 214 148 214 Health and Hygiene 520 367 520 Household 910 649 910 Meat 425 309 425 Others 169 123 169 Seafood 64 46 64 Snack Foods 1200 868 1200 Soft Drinks 445 312 445 Starchy Foods 148 105 148 .size() Đếm số lượng dòng cho từng nhóm In [7]: df.groupby([&#39;Item_Type&#39;]).size() Out[7]: Item_Type Baking Goods 648 Breads 251 Breakfast 110 Canned 649 Dairy 682 Frozen Foods 856 Fruits and Vegetables 1232 Hard Drinks 214 Health and Hygiene 520 Household 910 Meat 425 Others 169 Seafood 64 Snack Foods 1200 Soft Drinks 445 Starchy Foods 148 dtype: int64 SeriesGroupBy.nlargest(n=5) Trả về n dòng lớn nhất của từng nhóm Series In []: df.groupby([&#39;Item_Type&#39;])[&#39;Item_Outlet_Sales&#39;].nlargest(n=2) Out[]: Item_Type Baking Goods 2776 7931.6754 809 7759.8990 Breads 3757 8958.3390 7737 7158.6816 Breakfast 7343 8209.3140 7690 7943.6598 Canned 6541 10306.5840 6886 8217.3036 Dairy 4888 10256.6490 1009 10236.6750 Frozen Foods 7752 9678.0688 997 9275.9256 Fruits and Vegetables 5223 12117.5600 1450 11445.1020 Hard Drinks 3087 7843.1240 1043 7152.0236 Health and Hygiene 4289 9779.9362 4991 8508.9240 Household 7188 13086.9648 7191 10072.8882 Meat 8201 9390.4432 7930 9227.9880 Others 197 6008.8450 3529 5546.1140 Seafood 2528 6503.5344 5042 5992.2000 Snack Foods 4349 10993.6896 333 9267.9360 Soft Drinks 6606 9554.2300 5619 8868.4560 Starchy Foods 1254 8132.0812 661 7443.6440 Name: Item_Outlet_Sales, dtype: float64 SeriesGroupBy.nsmallest(n=5) Trả về n dòng nhỏ nhất của từng nhóm Series In []: df.groupby([&#39;Item_Type&#39;])[&#39;Item_Outlet_Sales&#39;].nsmallest(n=2) Out[]: Item_Type Baking Goods 2055 37.2848 430 38.6164 Breads 7388 35.2874 417 83.8908 Breakfast 4350 39.9480 920 50.6008 Canned 5670 37.9506 4297 41.9454 Dairy 3940 40.6138 5427 44.6086 Frozen Foods 4265 36.6190 7612 36.6190 Fruits and Vegetables 8486 45.2744 540 56.5930 Hard Drinks 574 37.9506 8116 71.9064 Health and Hygiene 3053 34.6216 4280 37.9506 Household 6950 33.2900 7861 41.2796 Meat 5374 47.9376 2407 71.9064 Others 6139 39.9480 2394 55.2614 Seafood 6903 149.8050 4502 158.4604 Snack Foods 2571 33.9558 6871 42.6112 Soft Drinks 906 33.2900 1913 40.6138 Starchy Foods 828 58.5904 5445 97.2068 Name: Item_Outlet_Sales, dtype: float64 aggregate .aggregate(func=None, *args, engine=None, engine_kwargs=None) Trong đó: func: một hàm hoặc danh sách hàm hàm dạng string dictionary chứa nhãn và hàm cho từng nhãn *args: Đối số truyền vào hàm func engine: Engine tính toán có thể là cython, numba Danh sách hàm In []: df.groupby(&#39;Item_Type&#39;).agg([&#39;min&#39;,&#39;max&#39;]) Out[]: Item_Identifier Item_Outlet_Sales min max min max Item_Type Baking Goods FDA11 FDZ60 37.2848 7931.6754 Breads FDN23 FDZ35 35.2874 8958.3390 Breakfast FDK25 FDR37 39.9480 8209.3140 Canned FDA01 FDZ49 37.9506 10306.5840 Dairy DRC27 FDZ50 40.6138 10256.6490 Frozen Foods FDA04 FDZ52 36.6190 9678.0688 Fruits and Vegetables FDA07 FDZ56 45.2744 12117.5600 Hard Drinks DRF23 DRQ35 37.9506 7843.1240 Health and Hygiene NCA05 NCZ53 34.6216 9779.9362 Household NCA06 NCZ54 33.2900 13086.9648 Meat FDA39 FDZ51 47.9376 9390.4432 Others NCI31 NCQ43 39.9480 6008.8450 Seafood FDF33 FDK45 149.8050 6503.5344 Snack Foods FDA09 FDZ58 33.9558 10993.6896 Soft Drinks DRA12 DRZ24 33.2900 9554.2300 Starchy Foods FDA22 FDZ34 58.5904 8132.0812 Lưu ý: min, max không áp dụng được cho các cột có NaN value. Lúc này pandas sẽ báo Warning FutureWarning: ['Outlet_Size'] did not aggregate successfully. Dictionary chứa nhãn và hàm In []: df.groupby(&#39;Item_Type&#39;).agg({&#39;Item_Identifier&#39;: np.max, &#39;Item_Outlet_Sales&#39;: [np.std, np.mean]}) Out[]: Item_Identifier Item_Outlet_Sales amax std mean Item_Type Baking Goods FDZ60 1546.788045 1952.971207 Breads FDZ35 1644.235914 2204.132226 Breakfast FDR37 1911.693586 2111.808651 Canned FDZ49 1645.235638 2225.194904 Dairy FDZ50 1884.404698 2232.542597 Frozen Foods FDZ52 1724.777720 2132.867744 Fruits and Vegetables FDZ56 1799.503459 2289.009592 Hard Drinks DRQ35 1606.191587 2139.221622 Health and Hygiene NCZ53 1553.633063 2010.000265 Household NCZ54 1692.245757 2258.784300 Meat FDZ51 1695.231081 2158.977911 Others NCQ43 1431.860471 1926.139702 Seafood FDK45 1842.988719 2326.065928 Snack Foods FDZ58 1705.121755 2277.321739 Soft Drinks DRZ24 1674.249752 2006.511735 Starchy Foods FDZ34 1773.945328 2374.332773 Sử dụng hàm tự định nghĩa trong Aggregate Ta có 2 function sau def foo(item_outlet_sales, alpha=1): mean = np.mean(item_outlet_sales) return np.sum(item_outlet_sales[item_outlet_sales &lt; alpha * mean]) def bar(item_identifier): return len(set(item_identifier)) In []: df.groupby(&#39;Item_Type&#39;).agg({&#39;Item_Identifier&#39;: [np.max, bar], &#39;Item_Outlet_Sales&#39;: [np.mean, foo]}) Out[]: Item_Identifier Item_Outlet_Sales amax bar mean foo Item_Type Baking Goods FDZ60 119 1952.971207 348230.7108 Breads FDZ35 45 2204.132226 152370.9932 Breakfast FDR37 20 2111.808651 64478.7352 Canned FDZ49 120 2225.194904 414387.2620 Dairy FDZ50 125 2232.542597 440485.2904 Frozen Foods FDZ52 155 2132.867744 514843.8318 Fruits and Vegetables FDZ56 220 2289.009592 783023.4112 Hard Drinks DRQ35 40 2139.221622 126412.1170 Health and Hygiene NCZ53 95 2010.000265 272449.3548 Household NCZ54 170 2258.784300 538634.1974 Meat FDZ51 80 2158.977911 263468.3786 Others NCQ43 30 1926.139702 81071.1370 Seafood FDK45 10 2326.065928 31677.4324 Snack Foods FDZ58 220 2277.321739 762663.2472 Soft Drinks DRZ24 80 2006.511735 257134.6232 Starchy Foods FDZ34 30 2374.332773 94087.5270 bạn có thể truyền vào tham số alpha bằng cách dùng lambda In []: df.groupby(&#39;Item_Type&#39;).agg({&#39;Item_Outlet_Sales&#39;: [np.mean, lambda x: foo(x, alpha=0.1)]}) Out[]: Item_Outlet_Sales mean &lt;lambda_0&gt; Item_Type Baking Goods 1952.971207 5035.4454 Breads 2204.132226 1557.3062 Breakfast 2111.808651 1440.7912 Canned 2225.194904 5354.3636 Dairy 2232.542597 5992.8658 Frozen Foods 2132.867744 7111.4098 Fruits and Vegetables 2289.009592 12268.0308 Hard Drinks 2139.221622 1625.2178 Health and Hygiene 2010.000265 3723.8194 Household 2258.784300 8425.0332 Meat 2158.977911 4526.1084 Others 1926.139702 1445.4518 Seafood 2326.065928 1404.1722 Snack Foods 2277.321739 9573.5382 Soft Drinks 2006.511735 3207.1586 Starchy Foods 2374.332773 1151.1682 Apply trên nhiều cột và sử dụng function tự định nghĩa Giả sử muốn lấy top_2 item có số lượng Outlet_Sales cao nhất và cao nhì trong từng nhóm. Ta định nghĩa function sau def get_top_ex1(g): top_1, top_2 = sorted(list(zip(g[&#39;Item_Identifier&#39;], g[&#39;Item_Outlet_Sales&#39;])), key=lambda x: -x[1])[:2] return pd.Series({&#39;top_1_Item_Identifier&#39;: top_1[0], &#39;top_1_Item_Outlet_Sales&#39;: top_1[1], &#39;top_2_Item_Identifier&#39;: top_2[0], &#39;top_2_Item_Outlet_Sales&#39;: top_2[1]}) Trong đó g là DataFrame của từng nhóm chia theo key của groupby In []: df.groupby(&#39;Item_Type&#39;).apply(get_top_ex1) Out[]: top_1_Item_Identifier top_1_Item_Outlet_Sales \\ Item_Type Baking Goods FDB37 7931.6754 Breads FDR35 8958.3390 Breakfast FDR37 8209.3140 Canned FDI50 10306.5840 Dairy FDF39 10256.6490 Frozen Foods FDC17 9678.0688 Fruits and Vegetables FDQ19 12117.5600 Hard Drinks DRK23 7843.1240 Health and Hygiene NCM05 9779.9362 Household NCE42 13086.9648 Meat FDO03 9390.4432 Others NCN55 6008.8450 Seafood FDI57 6503.5344 Snack Foods FDP33 10993.6896 Soft Drinks DRF36 9554.2300 Starchy Foods FDG47 8132.0812 top_2_Item_Identifier top_2_Item_Outlet_Sales Item_Type Baking Goods FDL24 7759.8990 Breads FDS11 7158.6816 Breakfast FDQ37 7943.6598 Canned FDX13 8217.3036 Dairy FDU14 10236.6750 Frozen Foods FDK28 9275.9256 Fruits and Vegetables FDZ20 11445.1020 Hard Drinks DRF23 7152.0236 Health and Hygiene NCQ53 8508.9240 Household NCH18 10072.8882 Meat FDP15 9227.9880 Others NCM43 5546.1140 Seafood FDI09 5992.2000 Snack Foods FDN58 9267.9360 Soft Drinks DRE48 8868.4560 Starchy Foods FDA34 7443.6440 "],["làm-việc-với-1-số-kiểu-dữ-liệu.html", "Chương 8 Làm việc với 1 số kiểu dữ liệu 8.1 Xử lý dữ liệu dạng text 8.2 Xử lý dữ liệu dạng timestamp 8.3 Category trong pandas 8.4 Xử lý Missing data", " Chương 8 Làm việc với 1 số kiểu dữ liệu 8.1 Xử lý dữ liệu dạng text Chúng ta có thể lưu dữ liệu text trong Pandas dưới hai dạng dữ liệu : object hoặc string​ s = pd.Series( [&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;Aaba&quot;, &quot;Baca&quot;, np.nan, &quot;CABA&quot;, &quot;dog&quot;, &quot;cat&quot;], dtype=&quot;string&quot;)​ Để thực hiện các thao tác cho dữ liệu dạng text ta hay dùng s.str.&lt;phương thức&gt;. lower() Chúng ta có thể chuyển text về các kí tự viết thường bằng phương thức lower() s.str.lower() 0 a 1 b 2 c 3 aaba 4 baca 5 &lt;NA&gt; 6 caba 7 dog 8 cat upper() Chúng ta có thể chuyển text về các kí tự viết hoa bằng phương thức upper() s.str.upper() 0 A 1 B 2 C 3 AABA 4 BACA 5 &lt;NA&gt; 6 CABA 7 DOG 8 CAT 8.2 Xử lý dữ liệu dạng timestamp 8.3 Category trong pandas 8.4 Xử lý Missing data "],["một-số-kiến-thức-nâng-cao.html", "Chương 9 Một số kiến thức nâng cao 9.1 MultiIndex 9.2 Pivot và Merge 9.3 Resample 9.4 Window", " Chương 9 Một số kiến thức nâng cao 9.1 MultiIndex 9.2 Pivot và Merge 9.3 Resample 9.4 Window "],["anomaly-detection-project.html", "Chương 10 Anomaly Detection Project", " Chương 10 Anomaly Detection Project "],["visualize-với-matplotlib.html", "Chương 11 Visualize với Matplotlib", " Chương 11 Visualize với Matplotlib "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
